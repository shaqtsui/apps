#+STARTUP: indent
#+STARTUP: hidestars
#+STARTUP: showstars

* All about: COGNITION OF 心 AND THE WORLD
心不着相

一颗心，只是观与不观和起不起意的区别

昏沉 － 不观

七情六欲 － 起意

观而不起意 － 目标

观则不起意 － 使目标简单化

起意之时还需意来灭

念佛是谁 － 要参是灭意之意，参他就是抱他、看他，正在参时就是观而不起意

心神不宁 － 心总是起意

有两种心：意识心 非意识心，两者都见闻觉知

不同心理状态生不同东西

心行恒一，无所不达

i.e. 制心一处无事不办

调整到某个状态（或动或静）后，制心一处即便有尘而不去识，感，欲，情以保持这个状态（如守门猫）。如不制心一处心中有个习惯去识别尘，感受尘，生欲，生情让自己忙碌“充实”

开觉而不识不动

心定在这不做任何事

心不起意时不需额外的意，心起意时要新意来除旧意

心做某事，六根只是去帮他

心专注于不动

观一是把心绑在一个地方的方法使心不动

用心绑，不管外尘，绑在一个地方等都是制心一处的方法对应不同情况

意识心不可知非意识心为什么这样

所以伤害自己就是影响自己正常心行，呵护正常心行就是呵护自己
对别人也一样

制心于观生见，制心于止生？，制心于愿生？...

Note: 这句话只是观生之见，重要但他局限在观。这句话的所指才是全面的，他不是见是心行。

心行之时已在收获中

关注心行本身，他才会生所获，关注所获不会生所获

基本心行：观（只有观一刻不离，是为本心？观之见变，但观不变），身，口，情，欲
欲 － 这个欲是有根本目标的：离苦即乐
观 － 好象一个时间点只能看一个或两个东西，没法同时看到三个或以上的东西
      观是指有效的观，无效的观不是观，如：睡着观不能集中，老被打断的观不能集中
      观之见被直接用来解决问题看似很重要，但是生见之观才更重要，不要为了求更多的见而忘了提高观，生见之时同时提高观
      觉得自己牛会影响观：减少甚至不观
      观影子生的是影子见，不是真物的见，如：学习书本为观影子
      可观的东西越来越多因为你的记忆在增加，所以现在观的可能比以前更广
      

想做的方法对否时已非一心（方法自心知道，意识心想的方法很可能是错的），急于做成时已非一心（一心之时已是最快的速度了），监督时已非一心（心散之后自然会知，因为一心在散前已在记忆中）
用力去集中注意力，精神赴物时已非一心（集中注意力，精神赴物是意识心，真心时精神内敛，物入心而非神赴物，e.g. 大一下午背单词入定时）
多心 -> 二心（欲/意＋一心） -> 一心？
二心 -> 一心 靠久习而成自然

发心 -> 知识（管道）-> 身口意 -> 境 -> 发心

顺逆境只是你之前自己把自己推过来的，你的反应发心才是推动你前进后退的力

当你受到压力时，是因为你正要跨过外面的边界，跨过边界可能是好事但更可能是坏事

你拿掉了别人的一个借口或遮羞布没有拿掉他的欲他还会找其他的借口和遮羞布

有两种富有，外在的和内心的，看你目标是什么了，如果你只看到外在的穷富带来的苦乐，你可能就去要去求外在的富

统一意识形态就是把某个东西关联到苦乐，以用人之欲（根本目标是离苦即乐）向这个东西推进

承诺是关联违反的苦到相应的事上，以用人之欲

苦乐：欲之所，欲之所向是为乐，欲这所离是为苦

欲关于取，愿关于予；取而不成为失，予而不成无失


非亲行无以亲见（证）


制心于练心力？

真心起欲，放下意识心

止观 - 止意（心意识）而观（觉照）

观而不起意

观与意皆心行

心行单一为定，三昧？

入心行单一有如立于钢丝

心行单一要有欲力，无则不能行单一，过大则不能久，中途可能有其他心行或休息插入，过后可以续继

在心行单一上用力，不是在身体行单一上用力



观：
聚精会神不象是意，是观的力度


意：
意：意识，情意，欲意，思
一意
多意
无意 - 眠

法尘非意

止意不象是意, 如果止意是意那么就无法止意, 就象想(意)睡觉就无法睡觉

意的背后是欲，欲的背后是我执？

放下不是告诉自己不关我的事我不管因为这背后是我只要我要的，真正的放下是无我要（我执？）

无我要不是我要我不要，我要我不要本身也是一个要

回头看无我之时所为才是纯奉献

用这来看：无为而无不为。无为是无我要，无不为是没有办不成的事。

用这来看：非以其无私邪，故能成其私。纯奉献的果是回报

意影响观

意引苦

意会引起周边人生更多的意


一意，多意：
当你有一意的是候, 他有利有弊, 他带你去一个地方就会影响你去另一个地方

所谓的控制自己就是让自己放下某一个意吧

一个意被另一个意打断了再找回来很花精力

所以三心二意这第二意本身会花你的精力，打断再找回又花你的精力

象专注，放下，类似的很多能力是本来就具足的，不是后天学习来的

我们往往忽略了用本具的，去只用后天学的

比学习更重要的是学习的状态，专注的状态是天生就会的不要学的

学习就是观尘？ 
学习就是心行观

Root -> Generate Pattern -> Solution, a instance of Pattern

Practice ia 1, change yourself to behave with looking into these Roots & Patterns. 2, Connect daily Instances of its Pattern & Root, so that the tree is complete

学习是一层基于一层的。你的底层不清楚上层就不一定对，你也会因为怀疑而被上下两层拉扯。

How to see > What u see about the real > What u see about the reference(language/notation)

How to see:
BD - Be DING
HIC - How it comes
SFDD - See from different dimension
OHKFS - Only hold key for simplicity


Scientist are those guys who:
Distill the world, express the result with their language
Mathematics focus on material independent property(quantity, shape/structure, relation/operation)
Note:
  Distill is Abstract
  Normally Distill via front view & side view
  Function can model: transform, link, relationship ...
  18.01, 18.02, 18.03
    front view is modeled by original Function
    side view is modeled by original Function's derivative Function
  18.06
    Directed Line modeled by Vector, Transform modeled by a Function
  18.062J
    Induction - About Equal Function. Iteratively apply Equal Function to get induct proof
    Number Theory - About Divide Function. Interleavly apply Divide Function to get gcd
    Graph Theory - About Add Function. Iteratively apply Add Function on 1-Node & *-Edge to exsting Graph to get new Graph
    Sums - About Multiple Function. Iteratively apply Multiple Function to get a serial
    Divide and conquer Recurrence - About Divide Function. Iteratively apply Divide Function to get Recurrence
    Linear Recurrence - About Substract Function. Iteratively apply Substract Function to get Recurrence
    Counting rules I - About Perspective Function. Apply Perspective Function to map Perspectives
    Counting rules II - About Add Function. Iteratively apply Add Function on new layer to exsting layers create new layers with overlaps
    Probability introduction - About Group Function. Group Sample Points to form an Event
    Conditional probability - About Add Function. Add new Event to existing Events
    Independence - About Equal Function. The new added Event have same ratio in existing Events
    Random variable - About Link Function. Sample point Linked to a Value
    Expection - About Add Function. Add Values in Sample Point Unit or Event Unit
    Large deviation - About Perspective Function. View Sample Point from the Perspective of distance from mean
    Random walks -
  18.703
    elements recurse(+ or *) to another element
    every element have its value, so value equal(=) exist

World(Thing) is - Container with Things & Relations
                  Primes + Recursions:
                    Recursion is recursive composition, and all composition are recursive, so simply name it Recursion
                    Relation is the recursion contains multiple elements, such that element A -> recursion -> element B
                    Transform it self can be Prime or Recursion

Clear Logic Induction is also: Primes + Recursions.

Language is: Primes + Recursions
  Syntax - Recursion structure
  Word - Prime

Recursion - A Structure can used to build/decompose all complex

Biggest miss understanding about math is that we take language as real target, but actually language itself is not what author want to refer.
+ - add, put together
x - multiply, duplicate

Language: Compose Symbols to refer to Stuff.
Context + Symbol ----> Stuff
E.g.
3 x 3 - first 3 refer to 3 meter, second 3 refer to 3 times, x refer to duplicate
A transform, strength something 3 times then 3 times, as these two 3s can change position, so first 3 can not be meter any more
a+bi x c+di - x refer to a sequences of operations:
a+bi x c, a+bi x di, combine them
a duplicate c, b duplicate d, combine them as real part, a duplicate d, b duplicate c, combine them as img part.
Corresponding real stuff: strength c times, strength d times & rotate 90 degree, add together
a+bi x i - counter clockwise rotate 90 degree



Just see the real stuff
Visual Understanding, i.e. Insight not Numbers
NOT the language, as language is just a reference to the real Stuff
You can NOT see the whole stuff which contains anything you not see
So, do NOT guess, decompose & compose until you see it
E.g. if you want to see the change of a stuff, you need to see how the stuff created
Abstract:
You can see one or two stuff at single time, If more than 2 stuffs, pls iteratly group to one or two stuff to make them a 2 forks tree shape
数字这个符号指的是某物之数，所以见数字不是真见，要见他所指的物
So don't just reply on math language(e.g. operations & equations), you need to see the stuff first then use math language
不要乱看到顺着从下往上看
外界现在看到都是树状的，东西真看清这后应当也是树状的，任何东西（叶）都有生他的枝，枝又有生他的干
知识从广度和深度上讲都是无穷的，现在我所知的真的只是海中一滴水
知识只是工具，是混饭吃的工具

你学了很多专业知识后并使用，不是你牛，是知识这个工具牛，你只是观而后搬到你心中

看这个世界的方法：少意
  专注 － 只看一个东西
  系统 － 形成一个东西（connected together avoid forget, avoid duplicate）
  Abstract － 看少一点东西(limited sight see large stuff)
  Hold Root Remove Derivatives - Generally in a system, one Root generate many Derivatives, so Root is generally simple Derivatives is generally complex

起意之别：
能力本无差别，只有意的多少(体现为别人所说的学习“能力”，真正的能力在圣不增在凡不减？)
  想其他事只会让你分心
    一直想快时属于下等的多意，不但让你分心更严重的是还会让你跳过一些基础
  一意之时看一个东西自然是在一这个范围内，就是系统
  看清一个东西后自然他不会占用你的sight了，就是在抽象


世界包括：Things & Transforms

Algebra研究：Things & Transforms(Operators, Functions)
Analysis研究：changes of Things on one side(input/output) of Transforms

Relation/Mapping - Transform from one's postiton to the other's
Language/Information - Mapping from symbol to stuff
Space - A set of stuff

Prime - Can NOT perform decompose Transform in a Context
Composite - Can perform decompose Transform in a Context

Isomorphic - Stuffs from same Composite Transform on different stuff
Recursion - Stuff from Composite Transform on Isomorphic stuff
  benifit: 1, inner stuff & other stuff are isomorphic 2, changes are isomorphic


Transform:
  Prime Transform
    e.g.
      Transform by positon: a -> A, b -> B, ... ,  #t -> True, #f -> False, G -> GREEN, - R -> RED, B -> BLUE
      Transform by composition: (wrape x []) -> [x]
      Transform by decomposition: (decomp [x]) -> x & []
  Composite Transform - Decompose -> Transform -> Compose: e.g. book -> BOOK
    This need it's Inputs to be isomorphic


Structure
  Space structure
  Time structure

在学习的某些阶断，对目标认识的还很肤浅，这时要求深入条件不一定成熟，因为：1, 未来在条件具足时深层就显而易见。2, 大量的精力去求深入会影响不起意
人对于不知道的东西会有畏惧感，从而让你远离这个东西，清楚的知道边界可以去除这种畏惧感

两百万让我懂得了：在非我专业领域我的水平远远低于平均水平

清官可能心是善的，但是这善的欲望太强及有关的情绪太强，会影响观，如：观的少了，只观期望的不观当下

知识分子用大量的时间去提前积累一些影子知见或有限视野下的知见，本身没有错但是易犯其他的错：
用的时候把这些影子知见和有限视野下的知见看的太重觉得自己知见很多了，看当下的很多事都觉得自己见过相似的而不去细观当下

智者知心行，如：去情欲以增遍观，书中观见的永远只是影子，过去的知见是过去有限视野下之所观所以有或小或大的局限性


e.g. 
观此影响观彼
sigmoid derivative contains S, high order function of sigmoid derivative also contains S
plot high order function from component function's shape

分别一切事不起分别心 － 前一个分别是了知，属于心行观（观一事的世俗分组标签），后一分别心是喜厌，属于心行意（七情）

心行意时影响心行观，喜则多观，厌则少观

心行意就是止心行观然后心行意

意都依赖于尘



根合尘生相，不起意则不识

学习是多意可以得识

多意之识（知识）有他的作用，但是是有限的，无法到达一意之生的定，平和，不造业，无善无恶

多意之识可以见指月指

人活在名利物旁边容易生欲意

事后的原谅是宽容

不据理力争留有余地是自知一山还有一山高

做好自己才有无限可能

为了那最伟大的能力：一意，多意之时无恶

有目标等于放弃其他

当有不相关目标出现时就是对前一目标的阻碍

没有决对的好坏，好坏只是某一标准下的概念，往往这一标准是你的目标

很多的识是为了认识恶意并对制他

环境生情意，跟着心情走就是被境所转

对相（境）起一意以去多意/不起意(为眠？)
心根合尘生相，心执相生意语身行，意生意尘
七情六欲，思考中的动即属意

观不执相而生定
观执多相而生知(Cognition)

Never arbitrary add stuff into a system
E.g.
add case to macbook pro harm: cooling, damange original case during install & uninstall
add keyboard mo harm: screen as by design there is no gap between screen & keyboard
add screen protector will cause it not closely closed

** 心

*** 一意（欲）
即：有照，不住万相归于住一，万法归一，抱一，放下万缘，不思善恶，不造业，无想无思，挂念，无分别妄想执着于妄想，不动心
Power for all
Gain:
  无恶无善是为至善，正确的方向，无烦恼
  做好自己去己之恶是为真善大善，非去己恶之善为小善伪善？
  清晰的大脑（可以观无法一眼见之物，一眼见之物为简单之物，观一眼见之物只要时间，观无法一眼见之物时更重要的是清晰的大脑）
  轻松的身体

*** 多意（欲）
观执多个相

**** 意识
	心生知

	Details:
		所以万物皆有菩提心？
		
		是不是要更感谢天地生心呢？
		    问题如同父母生我，爷爷生父母是不是更感谢爷爷呢？
		
		其实我追求的是根，是谁产生了牛


心中有不断增长的互相连接的东西，心可观他们。

## Details

### 东西

东西由多个面组成  
声色香味触?

### 连接

只有一阴一阳可以放到一起成为一个整体, 这两部分我们称之为连接着的.  
如果两个东西同时和一个东西形成两个整体, 那么这两个东西是间接连接着的.  
E.g.    (a b)

    a 和 （） 一阴一阳成为一个整体
    b 和 （） 一阴一阳成为一个整体

连接很多的东西 - 熟悉的东西  
连接很少的东西 - 陌生的东西


### Application Example

E.g. 怎么把某一断桥连上？

1. 这一"断桥"是新的东西，我心中没有东西和他相连
2. 观察"断桥"
3. 连接到"断点长度"，连接到"一米"，连接到"一米长的煤气罐"
4. 得出答案："断桥"可以被"一米长的煤气罐"连接
5. "断桥"通过这一答案直接连接到"一米长的煤气罐"


E.g. 比较两个椅子的异同


1. "椅子A"和"椅子B"是新的东西，我心中没有东西和他相连
2. 观察"椅子A"和"椅子B"
3. "椅子A"，连接到"椅子A的外形"，连接到"四只脚"
4. "椅子B"，连接到"椅子B的外形"，也连接到"四只脚"
5. 得出答案："椅子A"和"椅子B"相同点是："四只脚"
6. "椅子A"和"椅子B"通过这一答案直接连接到"四只脚"

**** learn
Observe original target then jump to related stuff e.g. language expresson of the original stuff, stuff's different attributes, relationships
All learning's goal: to shape the target via observation.




** WORLD



*** Physics

**** circuit
Hydraulic Analysis
	1, Charges are pushed from high potential to low
	2, The resistance is accumulated all the road from high to low
	

Element Law:
	Resistor have conductance, have NO EPT
	VS/CS have EPT, have NO conductance
	
	VS behave like a short circuit
	CS behave like a open circuit
		set VS to 0 = short circuit
		set CS to 0 = open circuit
	
	VS create potential difference(increase/decrease potential) not absolute potential
	
	
Details:
	Resistor network topology determine the EPT distribution
	KVL & KCL derived from LMD


Circuit Analysis:
	Steps:
		1, Apply KVL to create Voltage connection
		2, Apply KCL to create Current connection
		3, Apply Element Law to create Voltage & Current connection
		4, Solve Equation
	
	Note:
		Non-resistor element (E.g. Floating Independent VS) in node method analysis:
			Have no Element Law, so can not create Voltage & Current connection
			Workaround:
				use another same current element/branch instead
	
	Superposition:
		Why stand:
			target node voltage is determined by 2 reference node voltage
			second VS/CS will change one of the 2 reference node voltage
		


**** electric
Refer to shijie.txt

EC - Electric Charge
	physical property of matter that causes it to experience a force when placed in an electromagnetic field
	two types of ECs: PEC (Positive EC) and NEC (Negative EC)
		An object is Negatively Charged if it has an excess of electrons, and is otherwise Positively Charged or uncharged. 
		
		
ECO - Electric Charged Object
	Object have physical property: EC


EP - Electric Potential
	ECO's relative position to other ECO
	

EPE - Electric Potential Energy
	 ECO have EPE by virtue of two key elements: its own EC and EP.


EF - Electric Field


EPT - Electric Potential Tension (Voltage)
	ECO's EPE difference in EF
	

Electrical Conductance/Electrical Resistance 
	Like a channel to transport ECO from one position of EF to another position of EF
	This size of Electrical Conductance/Resistance is like the channel's length



**** energy
Energy = ∫ F=as ds


**** force
Interaction which tends to change the motion of an object


**** matter discipline

Matter Discipline
	ECO not disappear
	EP not disappear
	
	
Lumped Matter Discipline
	ECO & EP into & out of Lumped Matter only via terminal
		Lumped Matter ECO number not change
			ECO not accumulate
		Lumped Matter magnetic flux not change
			EP only release/accumulate on Lumped Matter in circuit
	Propagation delay of electromagnetic waves must be much smaller than the signal timescale
	
		
*** 易经
（万物皆）一阴一阳之谓道
	天人合一
	一阴一阳
	
江河乃点滴汇聚，圣人乃岁月之功。

Cow can not stronger than elephant, but the cow who want to be the strongest surely will stronger than others. 
What only this cow need is will & do & time.

A cow is thinking whether it can be the strongest cow in the herd. Pls give the answer!

I am better than other in IT, it's only because: 1, I like it. 2, I spent time on it. 

If today I want to be expert in Yijin than I only need to : 1, Like it. 2, Spend time on it?




-----------------------------------------------------------------------
每卦有其卦象，每爻亦有其爻象，总释一卦称之大象，分释每卦各爻称之小象，象使卦及爻暗示事物之性质及发展之阶段。

王船山《周易内外传》、《周易大象解》乃拟汉易象数与程氏义理不可偏废，更不可拘泥为占卜之书，亦不限定其为思维之书，象数与义理，应当一致，占卜与思维，更复一理，此种易学一元论回复而至文王演易之本义，即退回周易原解矣


贵州 周易玄



一阴一阳之谓道

阴阳运动状态称为五行。


*** BPM
BPM - Business process management
	Refer to OperationsManagement.txt
	
	a field in operations management that focuses on improving corporate performance by managing and optimising a company's business processes.
	
	life-cycle
		Design
		Modeling
		Execution
		Monitoring
		Optimization


*** Federal Goverment
Federal Government
	Consist of:
		DoD(Department of Defense)
			In charge of National Security & US Armed Forces
			headed by the Secretary of Defense
			Consist of:
				OSD(Office of the Secretary of Defense)
				DA(Department of the Army)
				DoN(Department of the Navy)
				DAF(Department of the Air Force)
				JCS(Joint Chiefs of Staff)
				UCC(Unified Combatant Command)


*** first priciple
First principle
一个系统研究中的基本原理、规则或法则；
该系统或体系的其他原理、规则或法则都是从它那里推导出来或从它那里得到解释，
而它本身却不是从那个体系或系统中的任何其他原理或规则推导出来或得到解释的。
数学公理和逻辑原理被认为具有第一原理的资格。
第一原理被认为是自明的、先天的，只能通过直观来领会。
传统的看法是，没有第一原理的体系不可能是连贯的或前后一致的。
有些哲学家论证说，第一原理不是要说明从属的规则，而是第一原理本身需要通过在组织或推导一套适当的从属规则方面的成功而得到说明。
他们还认为，在某些情况中或在原则上我们可以选择确定某一系统中的第一原理。对第一原理的研究通常属于形而上学的领域。
亚里士多德认为原理是事物由之而存在或生成或被认识的起点。


*** knowlege
Knowledge
	Declarative
	Imperative


*** OE
OE
	Operational Environment
	
	Data can exist in different State


*** Operations management
Operations management
	an area of management concerned with overseeing, designing, and controlling the process of production and redesigning business operations in the production of goods or services.



*** science engineering
Scientists and engineers are both interested in the nature of things, in understanding how ideas and objects in the world fit together. 
But in general, they seek to understand the nature of reality with different ends in mind: the scientist seeks this understanding as an end in itself, the engineer in order to build things. 

Engineering
	purpersful use of Science
	
Science deals with fundamental laws of nature 


*** semantic
static semantic
   meaning derived from non-runtime
semantic
   meaning derived from runtime


*** syntac
syntax
	symbols structure 


*** word
岁功
	岁月 的 功劳

帝载
	帝王 的 记载　-> 帝王 的 事情
	
系辞
	连接 辞。　辞，分争辩讼谓之辞
	
贞
	从卜，貝以爲贄。

参天两地 (sān tiān liǎng dì) 而倚（yǐ）数
	三天二地，依照立数。　倚，依也。-> 依照而立。　
	
发挥
	发，射发也。挥，奋也　-> 举起。
	
理
	治玉也。 -> 剖析
	
义
	己之威仪也
	
己
	中宫也。
	
宫
	室也。
		
性
	生之质也。
	
甄
	匋也。匋者，作瓦器也。

取义说

取象说

爻位说

一是察言，二是观变，三是制器，四才是卜占


天地之大德曰生

生生之谓易

顺乎天而应乎人

保合太和

与天地准



读《易传》，较好的古注本是孔颖达的《周易正义》，收在《十三经注疏》中，今人徐志锐《周易大传新注》齐鲁书社，1986年版，黄寿祺、张善文《周易译注》上海古籍出版社，1989 年版，都是较好的参考书。重点读《系辞》上下篇。 ——廖名春 撰文



*** 合作
合作就是各司其职， 整体到达的高度由团队最弱环节决定。
你可以换掉最弱环节，但不能因为别人做的不好就自己做。


*** 波
波的传播速度和频率没有关系。和媒介有关系。


*** 三之谓的衍生
No need to worry that u can not remember, u just put ur attention. 


Brain is like a DB.
U can easy add things to DB, the most hardest thing is that u can search them in DB.

How to search:
Normally people search it in spec context, if this context have a link to the thing then u can find it, else... 

So put link in spec context is very important.



Container(现实的，Refer to shijie.txt)
Context
All beings/existence should inside Context
Group

具体的技术不牛B，技术背后的idea才真牛B。Language:
Stuffs(Sign, Voice, Movement...) to express infoYour Leader is higher than you, but you should have the potential to bypass in future.
性决定一切

First and foremost is thoughts.
contains:
your thoughts
team's thoughts
team member's thoughts

So:
How to make their tasks seriously?
They need to have the thoughts of it's important, than ...
How to make them have the thoughts?
 Put them in specific position
 What position?
 The same position as yours
 
 
 
 
 

U can lead a team only if u are that kind of person.
what kind:
Serious
Prestige
Righteous


It's an exchange, if you need to get control from them, you need to give them sth. in return. 
All being/existence have its reasonprinciple
principle bound changes
direction is a principle
Project Elements:
Project
Work
Resource
Execution
Method
E.g.  Prescriptive Method, Adaptive Method
Plan
Status


Project develop steps:

Project Planning:
Find Req
Define Req Scope
Create WBS
Create Activities
Sequence Activities
Estimate Activity Resource
Estimate Activity Duration
Generate Schedule

Project Executing:
Setup Team
Impl Project

Project Closing:
Deliver Project
Update Info
Dismiss Team

Prototype
A relationship (refer to world.txt) : derive from

Relationship between Objects. 
If C Object derive from P Object, then P Object is C Object's Prototype Object.
Object should contains its Prototype Object's traits 
psyche

structural model
Id
uncoordinated instinctual trends
ego
organized, realistic part that mediates between the desires of the id and the super-ego
super-ego
plays the critical and moralizing role

The super-ego can stop you from doing certain things that your id may want you to do.
Id can be changed, e.g. instinctual reaction in some env. 所有的学科到达最高点时会合为一点， 所以博士叫做：Ph.D. (Doctor of Philosophy)
软件设计到高一定高度时就会遇到普遍适用的简洁该经历的必须经历，无论好坏得失。舍才有得，舍得同在。
刘备第一任县令时打官被通缉，才使得第二任时官不敢为难于他。

无威仪不可以奉宗庙，承社稷


有伊尹之志则可，无伊尹之志则为篡逆也

人不可逆势，但可造势
董桌操之过急，逆势下未造势而为

孙策之死：
弱身不议虎

多年无成因阴阳不全，有武无文这个世界的一切都不是完美的。也许这就是道。
所有事情都有瑕疵。世界
世界由存在组成
其他关于世界组成的问题只是分类的问题了
E.g.
阴阳，物质和非物质，感知的和未知的

世界就是阴阳变化(Refer to 3ZW.txt)

阴阳变化分类:
现实的和镜像的
Individual & Connection
Note:
Both Individual & Connection are YingYang, but they have different role.
E.g.
A rope can be an Individual, but when it bind to other Individuals it turns to be a Connection

解读一：
阴阳变化的某一时刻状态(物)
万事万物同时含有阴阳(对与错，好与坏，顺与逆)
    顺势有好处也有坏处
    
    阴阳变化的过程(动作?事?)
    这一过程需要特定的时间，特定的环境
    每个过程这一特定的时间不一样，所以改变象是一种缘分
    
    解读二(Now I prefer this one)：
    阴阳 - 物
    变化 - 事
    
    
    Derives:
    there is no same thing in this world
    
    变化越多, data越多, 越多活力
    E.g.
    政府对市场是管还是不管？
    我觉得是个度的问题。
    正如政府对社会出台法律进行管理。
    如果没有法律，社会阴阳运动会过大引起混乱。
    如果法律太严，社会阴阳运动会过小引起缺乏活力。
    
    物中包含量
    量 = 数 + 单位
    
    镜像的
    心
    信息
    知识
    软件
    
    Details of 解读二
    物和事处于同等位置。
    
    物中有事，因为阴阳一直关联着变化。事中有物，因为变化一直关联着主体：阴阳。
    
    事，物有多个面（事物的状态/属性）
    
    Entity Model base on 解读二:
    State
    Describe 阴阳变化
    Behavior
    Describe 变化三之谓的世界观
天 - 世间(存在)

整个世界由存在组成，存在由元存在创造。
元存在由元元存在创造…

世界由存在组成。
有没有一个存在主宰其他的存在？


定义类问题
很多问题的答案存在于定义里。
问题也是定义出来的

可以做某事，归根在于你有相关资源。

不知道有没有天，但是感觉有天命。天命回去促使世界整体进步。个人不用操心这一问题，个人没有这个能力。个人所能做的只是做好自己该做的事情，就像细胞只要好好活着并好好死去生命就会进步。交易这个过程本身就会产生价值
宽容，感恩， 行动，养生，珍惜，满足 - 付出
合作 - 付出和收获的渠道人真的太渺小了。人在世上，就像原子在人身上。
强者强势，弱者弱势力。
人 -> 事
人 - 因
事 - 果
处理人际关系：
1. 首先回答你要什么样的关系
   E.g.  你要和小气的人保持好的人际关系吗？
   2. 向内求个体代表整体。
      有时，一个人觉得你很狂可能表示世界觉得你很狂。一个人觉得你应当承担更大的责任可能表示世界觉得你应当承担更大的责任。很多事情归宿应该以人为本。价值：产出和成本差系统依言而行，其实是请言者运营系统。修身
      提高自己以便更好的活着
      所以修身包含修技有些时候你想通了但没有做到是因为惯性（惯性往往没有经过思考）U can not do everything urself. Maybe you need to catch the core 20 percents. The rest non-core 80 percents should rely on other.
So that u can better catch the core.

At one time u can only do ONE thing.

When u thinking I need to read this book, u are not reading, you are thinking.
When u thinking I need to do something carefully, u are not carefully, u already half hearted.

准则:
利己还是损己

往往，利人同时也利己，损人同时也损己。
向内求以使自己和其他东西合，因为你不能改变别人时，你只能改变自己努力可以使很多人受益，但核心的，主导的是使自己收益。协作就是各司其职， 整体到达的高度由团队最弱环节决定。
你可以换掉最弱环节，但不能因为别人做的不好就自己做。这个世界人生来各异，你不要强求别人变成自己期望的那样。两物在一起势必趋于同化
要么A同化B，要么B同化A.
E.g.
枕头整齐和床乱在一起，要么枕头也乱，要么床也整齐。不要去改变你的性格，去把它用在正确的地方。
E.g. 斤斤计较用在大事上。很多果是因为之前长期的因

有些果是不可承受的分层
一个系统的基础元素由另外一个系统提供

一个系统包含：
基础元素：
独立元素
连接元素
组合元素
由基础元素组成
抽象后成为上层系统的基础元素

天命
上天注定这个世界有太多的不确定和危险。
上天注定世界难以改变，只能改变自己。
上天注定修身可以部分保护自己。
上天注定一切皆有其道。人需要独自对自己负责。独自选择，生活，面对，探索，发现，思考一切。
所以你不知道你可以活多久，可以不可以活到明天。
每一天都应当做好这是最后一天的准备，思考你这一生应该做什么（自己生命的意义）。                                      
如果醒来自己还活着请感谢上天的赠与。

人生的意义/目标 -> 率性 -> 从天命
     活着，好好的活着，做自己喜欢的
          你的性决定你生命的内容
               性是天给你的
                    
               在最后一天的方法下对生命的意义的思考：
               如果意义是指结果那么：
               生命的意义不在于获得因为你终将一无所有。什么的意义在于给与，给与的东西一直存在。事本身无好环
               你可以从中学到东西，对你就好
               反之则不好


没有决对的害，也没有决对的益。敌人只是你反对的人。

好事和坏事从两个角度都让人成长。

没有对与错只有利与弊学习是对这个世界的理解，包括自己本身。
学习的意义是学以致用（率性）

把新知识加入现有的知识体系中，使之不再是孤立的知识片段。

The more you learn about something, you should have deeper understanding on the Foundation Knowlege (Refer to zhishi.txt).

Approaches to speed up reading:
     skip sth
     put more time
     enhance read ability
害怕是因为没自信，没自信是因为没知识工作产生了产品，产品解决了问题（公司的，客户的）平衡：
平衡不是均衡，是权重
任何的问题都是失衡引起的。
失衡越严重，修复越贵。

E.g.
因为心上放了太多的事，以致耽误了更重要的
我是弱者我的能力不匹配我做的这么多事
知满足（要与得的平衡）
根与枝的平衡
选择需要平衡，你可以学很多东西，但是你需要考虑这些是不是可以带来经济价值。幽默之源：
不伤人的笨，人性弱/缺点暴露度量
是不是为了理想而无声的吞下无奈的痛苦？影响力
你对别人的影响力=对别人影响的量
=你的牛逼 * 你对事情的重视度
心 = 性（天命在人） (Refer to Shijie.txt)
性
决定静生慧的速度和最大值（智力）

严谨
严谨决定了修得的道的准确性
可能是人和人区别的非常重要因素


智慧
可能是人和人后天差别的根本
很多问题都是因为愚昧，缺少智慧。


鬼谷子讲天命在心
志克怯 -> 无志不往

情绪
情绪是天生的，存在有他的意义。
e.g. 
可以带来深刻记忆

平静
平静是一种情绪的状态，这种情绪状态源于智慧（大度 ...）

诚
勿自欺
做真实的自己

大度
不是压制情绪。
是着眼于大局，有大志。
为了理想而无声的吞下无奈的痛苦？

静
静而后能安，安而后能虑，虑而后能得。
静生定，定生慧.
U need to give up all, if u want to empty/peace

U can not give up all is due to:
too many stuffs in ur heart
compare to current thing u are doing the stuff in ur heat is more attractive.

谦虚
看到天命的人一般都谦虚，因为看到了自己的渺小。
谦虚不是把能的说成不能，那是欺骗。谦虚是认识到自己的渺小。

痛苦
痛苦、烦恼、失眠源于在乎，它值得你用生命去在乎吗？
没有选择很痛苦。当你把所有的一切都压在一个地方时你就失去了选择.
面对痛苦，势必会痛和想逃避，否则不是真的痛苦(就像咖啡的苦不算真的苦)，但最后请勇敢面对，经过后痛苦会为你所用(习惯辣后你可以享受辣)。

我
意识的集合。
这些意识寄存于身体，所以你要感谢身体，尊重身体，珍惜身体。
Refer to psyche.txt

小气
小气就是气小，就像格局小，目光短小，着眼于小的地方。
这是由于你的习惯（生于性）引起的，当你习惯的思考着眼于小的地方或事情就是小气，目光就短小。
你可以改变你的习惯（性）吗？
如果可以那么系统的平衡可能会被破坏并重构，所以只能在状态好的时候才可以？

自私
自私是人性的一部分。
公平（双赢）的交易才是顺着大部分人的性的，才是容易发生的。
E.g.
医生给你建议，你给医生什么？

恨
你理所当然的应该恨你的敌人，但是你要谢谢安排你的敌人出现的人


欲望
付出最少化，利益最大化
Approaches:
简
Approaches:
Taxology
Approaches:
Group
Vertical Group
E.g. 
MOF 4 Layers, Program 4 Layers, Abstract Item & Concrete Item
Concrete/Conceptual
Concrete Items
Conceptual Items

Horizontal Group
E.g.
Group in Abstraction
Group natural & non-natural
Many other groups are base on part of this group result

OO(Object Oriented)
Group Object into groups
Group Attributes into groups:
Group Attributes
Individual Attributes

HCLC (High Cohesion & Loose Coupling)
Common properties only need one copy
Narrow relationship search scope
Note: 
this introduce new complexity but reduce over all complexity




就重避轻
Approaches:
Abstraction
Hide part of the whole
Most Abstraction base on Group(Separate Open part with Hide part)
E.g.
开放功能隐藏实现（把功能的描述放在名字上，实现描述放在内部，暴露名字隐藏内部）
Keep Essential Elements remove all other Elements
Essential Elements
Elements which make Object XXX an Object XXX
is to hide complexity

Combination
is to increase complexity


整体到局部
把握整体就可以把握方向
为了不迷失，进入细节时还应该同时抓住整体
没有整体的局部往往是没有意义的
E.g. 
解决不是基于大问题的小问题是没有意义的
闭眼，象树一样组织相关思考以便track所有相关思考。
思考可以处理的只是知（Refer to zhishi.txt）因为小聪超过了大智（思考放在了小地方所以有些顾此失彼）感知
存在于大脑中的某种东西(类似于胶卷)。

这东西一般都是现实的镜像（Refer to 镜像.txt）。
我被天宽容原谅了，我何以报答？
我为什么不能宽容？
我是来回报的，这一目标决定我不应该在乎得失与和他人的比较。
我出生只有4斤8两。
我身体素质很差。背部受凉
发火
动作过大
疲劳关于技术我总是被动的跟随着。我希望是个创造者。描 + 述
描
Description
Note:
Seems similar to Modeling
述
Representation of Description


很多知识和概念是对世界的描述
E.g.
数是对量的描述
Domain Model - Model of a target Domain攀比-希望别人不好，会孤立联系
赢了使你骄傲
输了是你嫉妒你可以接受（用）一个人或者鄙视（不用）一个人，但是你不可以改变一个人，只有他自己可以改变自己。当你从事一件新的事情，你要放下以前做事的方式，因为惯性可能让你跳过对事情的分析判断。很多牛逼的东西只是暂时的
E.g. G1X, D100物有本末，事有终始，知所先后，则近道矣。

本：
修身(内)
修身有圆满
末：
修技(外)，做事
修技修不完


本：
方向
末：
具体问题根
事情做不好根不在于技，而在于心，心生技
智慧之根 - 教
和谐之根 - 率性
行为之根 - 心
理之根 - 天命

三之谓是根，但是我们生存在枝叶之中所以也要了解枝叶。

买东西应该看本（血统）格物
就是要去观心正心
是一种平静，不愤怒，不恐惧...
愤怒，恐惧... 是对人的一种强大的束缚

正心分内外
内
消除自我相关的愤怒恐惧...  
内往往会更容易忽视。

E.g.
下属是同事，不巴结
老板是同事，不巴结和凡人的沟通桥梁是言语
和聪明人的沟通桥梁是心里

沟通传递两种信息：内容本身，感觉（姿态，认真…）

沟通需要一个共同的基础
团队沟通需要以团队目标为共同的基础越是牛责任越大。外界对你的要求越高

做一个牛人何必在乎做技术还是其他呢？物竞天择使得这个世界得以进步
只竟（低头努力）不比朝自己的目标（自己的感觉）走，不要被别人牵着走，更不要被恶意的言论牵着走。人不可避免的一直犯错，所以要一直做些什么(包容，好事)去弥补(平衡)
这就像是交易。
犯错后第一件事应该是承认犯错了，这样才能促使弥补的发生。率性
一切存在与发生都是合乎道（率性）的（道也者 不可须臾离也）

性
昨天和今天决定明天
命运就是你过去的总和
做你喜欢的事情就是顺
用较少的精力做较多的事情。
目标要明确才能不管过程
E.g.
打的从A到B，可能会走最远的路。潜在正确的目的是A到B且最省钱

过程很多时候是和目标不一致的，这也是必然的，但是只要总体上在接近这一过程就没有问题。因为性，有些东西相互合，有些东西相互不合
所以当你不可以获得某些东西时，你只能帮别的个体（比如你的公司）去获得。
这就像母公司开子公司去做一些事情。知识
现实的镜像。
存在形式可以是：感知，书，视频...

只是工具。

人再牛逼也只是有一些不属于自己的牛逼的镜像。

分类：
Approach A:
切身感受到的知识
非切身感受到的知识
Approach B:
Foundation Knowlege
Can deduce Derivative Knowlege
Derivative Knowlege
Derived from Foundation Knowlege
管理就是借势树立规则，并保证被执行。

项目管理方法(Process)存在于人和事中
而不是软件中
软件只是做了自动化
人最宝贵的是时间精力。
管好你自己，你没有时间和必要管别人每一种人都有他的精彩/美好，孤独者的奋斗，领导者的大气，智者的淡定，波澜起伏，平静...

人往往只看到别人的精彩而没看到自己的精彩。
经典的东西好像没有一点多余的东西。
e.g. 辉腾没有一点多余的线条。能
你能只是因为你是那种能的人。
所以万事向内求。

天命已经让你有很多的能，对一些不能不必强求能，放弃一些能可以得到别的能。（refer 舍得）有舍才有得，有舍必有得。对一个普通人要求高不但不能帮助成长反而是一种折磨解决问题本身不重要，最重要的是解决问题的方法。
因为有方法你可以解决所有的问题。讲究成性真的很美。诚意 
E.g. 自己享受。用多少资源生多少资源，不是有多少资源生多少资源。很多条路都可以到达目标，率性的这条最有力。越是看似不重要的越重要。
如：健康时候的健康，拥有时候的拥有。镜像
是某些东西，他连接着另一个东西并和他有一定的相似性你有产品可以让所有的动物变得好看，
但是一只公狗需要的只是一只漂亮的母狗，
你需要告诉狗的是产品可以给他漂亮的母狗。面试就像考试，检测你的水平
考试前的准备是为了改正缺点提高自己。
不是为了欺骗作弊。

真实才最重要因为他决定了你和新公司的匹配度。太多的顾忌也许是因为精力放错地方了，精力应该放在目标上.顿悟，就是突然明白有件事之前做的不对是因为一个想法或惯性不对，修复他只要修复这个想法。
例如：
练字
摩擦点没有痕迹
E.g.
D100: 电池盒，只有侧面槽里有新的摩擦痕迹，电池仓卡子有新的摩擦痕迹。
孔没有灰尘
E.g.
D100: 各种耳机电源孔没有灰尘。




*** 撮机
"Cuo Ji" is the core of stock deal.

1, Put buy & sell order in two Q.

2, Sort these orders by price & time
Buy Q is descending, Sell Q is ascending.

3, Match & Deal them from the top down.
During the match & deal , big order will be split to small orders to do match & deal with small one, 
median price will be the price.




Stock Table & Chart relations
Table -> Chart
timeshare closing details is the base table, all other table/char is base on data in this table


*** zipinzhenjie
天命之谓性

天命（在天）=性（在人）=理（在物）=？道=？气禀

气禀 =？ 五行之气禀赋

--------------------------

天人合一 contains 天人同构 & 天人同演

动物禀天之气，植物禀地之气，人禀天地之气。人方可与天地相参并列三才之一。

八字算命，依天地之道推人之命

岁功 means 日月轮回，春夏秋冬之“造化”过程

天人合一			同构					同演
大天地（大人）	历法（纪年月日时）	岁功
人（小天地）		四柱					大运

--------------------------

本原 & 现象

阴阳五行，万事万物不同的现象的本原，其在不同的事物上表现出不同的现象。

万事万物的组成与演化都是由阴阳五行组合着来推动的

五行，在天的现象为五星，在地的现象为五岳，在岁功的现象为昼夜、四季循环，
在人的现象为五脏、五官，在人事上的现象为五常、五志、五事

天地之间，一气而己。惟有动静，遂分阴阳；有老少遂分四象。

五行之态，旺相休囚死


*** 感觉
我感觉一切都是感觉
	感觉是什么？他不能由感觉来描述，我不知道他用什么系统来描述。
	感觉所有的系统都需要基于一些抽象（隔离另外一个底层系统，这一底层系统由不同于上层系统的元素组成）
		个人的能力是有限的，不能知道无限（所有的层），所以必须也必然使用抽象去隔离其他的层。
		抽象自身还是需要明确的（开放和隐藏的界限）

	感觉世界上有物质
	感觉感觉是由心产生
	感觉感觉是有触发者的（也定义为感觉的标的）
	感觉感觉本事是真的，感觉的内容不知道真假
	感觉很多概念是感觉的概念，也可能是感觉的触发者
	感觉感觉的触发者独立于感觉存在（也被定义为存在）
	感觉感觉的整体模型（世界观）
	感觉人的出发点都是感觉
	感觉感觉有巨大的力量
	感觉提高自我学习进步的能力可以更好的学习进步
	感觉屁股（立场，要做什么）决定脑袋
	感觉很多事情不行是因为自己太low
	感觉做事情当中去做人
	感觉思想和外界决定行为，行为改变思想
	感觉：
		心里强大的人会影响心里弱的人
		心里强大 - 自信
		把强大藏在内心
	感觉一切的标准应该是目标导向
	感觉只有感觉确定是真实的
	感觉：
		碰到问题先自己思考（以自己的世界观为基础）。不要一开始就看书而不从自己的世界观出发，这样容易被误导和迷惑。因为任何书上的描述都是片面的，他是基于很多没有写出的东西之上的。
	感觉：
		探索这一活动产生智慧
		生命轮回，探索不止
		生命是探索的载体
		
	感觉：
		关注过程，一个过程会达到多个目标。
		获取知识的方式的知识比其他普通知识更重要，方法的知识只能在学习普通知识过程中学习。学习的过程中学习。学习学习。
		
		世界观是这个人感觉的集合
		每天从感觉出发
		吃苦只有用在自治（对抗自己）上才是伟大的
		真正牛的人很少问其他人的想法，他更多在实践自己的想法（感觉）
		
		感觉对人的影响大小取决于他是刻骨铭心还是一闪而过
		实践可以将感觉的内容细化从而推动他从一闪而过向刻骨铭心迈进一步
	
	感觉有外界
		因为感觉会变化
		如果有，外界和感觉的一致（感觉由外界出发）可以让心更顺。
		
	
	感觉意识层面的个体是感觉的集合
		个人的成长是感觉的堆积
	
	目前感觉外界的牛永远不属于（溶于）自己，只有感觉可以溶于自己
	
	感觉只有感觉可以驾驭（其他一切可以驾驭的牛）。
	
	感觉一半的牛可以被感觉驾驭，一半不可以被驾驭
	
	感觉真正属于自己是溶于自己，是自己身体的一部分。
	
	感觉沟通的量/深度决定感情的量/深度。
	
	感觉一个念可以观其他的念，但不能观自己。
	
	感觉节奏很重要
	
	感觉个人的世界是感觉的集合
	
	感觉世界的结构由感觉的交叠组成。

	感觉一个想可以描述另外一个想
	
	对世界的理解就是从我感觉开始
	
	我是不是应该把世界是什么抽象掉，做好当前这一层（手头的事）？
	
	我不知道什么是对什么是错。
	
	思可解疑
	
	我不知道世界观，我只有某些系统的观。e.g. 软件
	宁愿不做事情休息也不要做不该做的事情。
	抽象在日常生活中：
	隐藏掉原因，开放结果
	
	悟道 - 用心感受世界
	
	外部现象容易感受到，内部原因不一定可以感受到
	
	狂就是没有畏惧感
	
	灵是用，心是体
	最大化灵的用
	可观，可感，可知，可思，可记忆叫做灵
	灵是一切的本？
	这一模型是否正确需要未来实践中验证
	观不到观自己。
	感觉产生了记忆，记忆又可以被感觉。记忆是镜子。
	看是一种能力没有主体。所以不存在看不到主体这样的问题。
	
	
	
	思考的目标不可以是思考本身，但是可以是记忆（包括思考的记忆）
	
	
	世界的模型是用，他无所谓体是什么。
	所以感觉可以建模感觉就像
	java 实现的jvm 可以执行 java
	
	
	
	有些结论是根据之前发生的体用关系推导而来的。

	一切都是感觉，包括这句话本身。感觉没有对错所以不用证明，但是有全面和片面之分。
	Most "Why" is about "What's the root"

	触发感觉生成的东西是什么？物质？

	我们用觉表示触发感的东西。

	探索问题的答案

	心的探索会有发现

	知识的根是探索（探索产生知识）
	这句话由探索而来
	探索后发现有所得
	怎么证明这句话是对的？
	答：经探索得到：探索是去发现存在的东西，不存在对与错。



	探索到：
	人不能长期处于疲劳状态中。
	高风险高收益人也是一样。
	勇敢不是不害怕（害怕是天性）而是明明害怕还去面对。
	


*** 根
天赋 + 修身
	天赋
		This is what comes alone with the birth
		I don't know this is material or spirit

	修身
		包含：探索，思考...

	“知”不是根：
		有些事情你知道也是这样，不知道也是这样
		“知”本身也是有来源的
	
	“天赋 + 修身”这句话所描述的东西不是知
	“天赋 + 修身”这句话本身是知
	
	“天赋 + 修身”这句话所描述的东西    --生成-->    “天赋 + 修身”这句话本身
	
	一切认识是依靠天赋感受世界而来，包括这句话本身。

*** 知识
知识让我看到了更多的东西
	这句话是我的亲身经历
	这句话是我回到最初（小时候）之后看到的
	所有的问题都可以被知识回答
	看到更多的东西后可以更好的做更多的事情
	
	知识改变命运
		在没有知识的情况下人走的路是一种命运，在有知识的情况下因为站的高看清了方向所以会改变之前的路。
	
	知让我看到，认识，尊敬，获得牛。
	知是唯一的让我站的更高的东西。
	知可以也只能让人站得高看得远。
	知识可以让我站的更高看清方向
	看得多以后你会发现你有很多可以做还有更多做不了。
	人很渺小，世界上有很多很牛的东西
	
	看世界方式：
		从问题出发
		从最初现实出发
	
	看到路可行，看不到路也可行，看到路行的更好
		有多少知才可以做多少事。
		没有知我什么事也不能做。
		知是人一切可能的可以的基础
		知是人行的基础。

	知让我看到：
		知是人的一切的基础
		人所能达到的最高境界可能也就是知
		知只是象
		知很牛，但不是最牛（比如天命比知更牛）；但是知的牛是唯一的人可以直接获得的牛。
		是知给了人力量
		
		如果牛是随心所欲那么：牛的东西有很多，有些不能被获得，有些能，但只有知可以直接被人获得。
		知是获得其他的牛的基础。
		是身体和知让我强大的。
		我的牛的边界
        我的牛的渺小
		
	格物致知
		践行到达知
		
		Details:
			格物 - 亲自践行，感悟
			致 - 到达
			知 - 可以存在于任何地方包括书上
		
			读书只能看到知，读书不能到达知，格物才能到达知
			格物致知本身也是知，可以从书上看到，但也需要践行才能到达
			
			
			
	书上讲的别人讲的都不是自己体悟到的
	关键要体悟。
	
	书上有的是别人对世界的体悟
	
	很多东西是镜像
	镜像和镜像对应的实体经常混淆。
	
	忘掉书上讲的，想想你体验的世界是什么样的？
	
	忘掉书上讲的，用你的体验建造你的世界观
	书用来指导你怎么去体验。
	
	只有悟道没有学道

*** 佛学
八识心王:
 眼、耳、鼻、舌、身、意、末那、阿赖耶

前五识是感识，认识具体对象, 如果区别这个什么那已经动用意识了。



法的意義，一般通指「任持自性」與「軌生物解」二義：

　　一、任持自性：指「法」能保任執持自體性相而不變不失，例如，一個人有一個人的自體性相，花草樹木有花草樹木的自體性相，一切萬法都各自具有「任持自性」的特點，不會混淆不清。

　　二、軌生物解：指「法」皆有一定的規則，能夠使我們對事物生起了解、認識。就軌生物解的意義來說，「法」乃指認識的標準、規範、法則、道理、教理、真理、善行等。



安住 安住是止，一种定境。心能安住才会看到事物的真相。即在定中才能生慧，才能见到我们的本来面目，见到佛性。



*** 道德经
道: 路，引申动作、变化之路，引申法则（像路一样用来被顺着，遵守）
德：准则，人为事之准则。


*** 大学
至知在格物 ，格物在性（天命之谓性, 赋命自然, 生之质）
	五行各禀其性，人亦然。人性有灵可观物思索，可格物。
	
	至：极
	物：内物（心），外物（在心为象）
	格外物至外物知，格内物（心）至内物（心）知 
	从旧本大学
	It's a Perception Seed. Seed -> Perception -> Seed. 



E.g.
	Everything, we talk/think about, is just Perception:
		Think about Substance, to know that any explanation on Substance is just Perception.
		Maybe Perception similar to Substance, but they are not the same. 
	
	
	U need to start from BEN:
		JS ScopeChain:
			From JS perspective, every thing is object. 
				So Scope Chain must be some other's object's field. 
					So it will initialized when parent object be created. 
					There parent object can be Execution and Function. 
		DOJO:
			Check what's exposed, so that you will know what dojo is, start from define & require, so that u will have a hole pic.
		 
		 
	Everything want to last, it need to be a cycle
		Derived from Seed -> Plant -> Seed
		
		
	With earth, GWZZ -> other Perception -> GWZZ
		Derived from Seed -> Plant -> Seed
		
	
	How u know it's a seed?
		Put it into the earth. U will know. So do the same to GWZZ. 
		
	How u know other Perception can generate GWZZ?
		Just like I don't know why plant can generate seed, but it just did. So the same for GWZZ. 



*** elements of the theory of computation
Practical successes of computer science build on its ELEGANT AND SOLID FOUDATION.

	Computer science has its own set of fundamental questions: 
		What is an algorithm? 
		What can and what cannot be computed?
		When should an algorithm be considered practically feasible?
	
	These ideas and models are mathematical in nature.
		The most useful abstractions of a computer are clearly mathematical.
		Practical computational tasks require the ironclad guarantees that only mathematics provides.
		Mathematics employed in theory of computation is generally discrete, in that the emphasis is not on real numbers and continuous variables, but on finite sets and sequences.
	
	It is based on VERY FEW and ELEMENTARY concepts, and draws its power and depth from the careful, patient, extensive, layer-by-layer manipulation of these concepts.
	
	

*** English
音节是语音的基本结构单位
	分为：
		元音音节
		辅音音节
		
		
		开音节
		闭音节
		衍生音节
		
		
Syllable:
	V
	CV
	CVC

	
When a word consist of more than 3 syllables, one of these syllables will be stressed syllable.


重读：
	1, [ ?i? ] 前一个Syllable要重读
		E.g.
			ic, ison ([ ʃ ] 包含 [ i ] )
	2, 倒数，每第三个Syllable要重读


记单词要顺着词性记，要和谐。

words can be remembered, if u think it will occurs again sometime late

任何人类语言发音应该以音节为单位，单词包含多个音节，所以应该分开读


连读
把独立的单词首尾相连成一个音节
	辅音 + 元音 － 直接连
	辅音 + 辅音 （辅音连缀） － 不好连的（相同，爆破）去除或弱化前一个再连


Details: 
	一般不重读
	同一个意群(即短语或从句)中
	辅音 + 元音
	
    I’m~an~English boy. 

    It~is~an~old book. 

    Let me have~a look~at~it. 

    Ms Black worked in~an~office last~yesterday. 

    I called~you half~an~hour~ago. 

    Put~it~on, please. 

    Not~at~all. 

    Please pick~it~up. 
		
		前面的单词以r或re结尾,后面的单词以元音音素开头,则r或re要发/r/音,并与其后的元音音素相拼。
			They’re my father~and mother. 

      I looked for~it here~and there. 

      There~is a football under~it. 

      There~are some books on the desk. 

      Here~is a letter for you. 

      Here~are four~eggs. 

      But where~is my cup? 

      Where~are your brother~and sister? 
		如果一个音节的前后都有字母r，即使后面的词以元音开头，也不能连读。 
		
		辅音+半元音 （/j/和/w/）
       Thank~you. 

       Nice to meet~you. 

       Did~you get there late~again? 

       Would~you like~a cup~of tea？ 

       Could~you help me, please? 

	辅音 + 辅音 （辅音连缀）
		
		不完全（失去）爆破 
			辅音爆破音或摩擦音后面跟的是爆破音、破擦音和摩擦音等，前面的辅音要失去爆破。
			/p/， /b/， /t/， /d/，/k/, /g/
			
		两个相同的发音只发一个音，但是音更靠向后一个单词
		


*** currency
Money is ownership certificate.
	It denotes you own: (amount/m2)*GMV
		GMV - Gross Merchandise Volume

Money:
	M0 = Cash in Market
	M1 = M0 + Cash in Bank
	M2 = M1 + Credit (Bank can arbitrary create Credit, Credit can in place in Deposit formatter)

RRR (Reserve Requirment Ratio) can limit Bank's Credit creation ability. 
M2 = M1 / RRR



*** 古文
分为：
	上古汉语（先秦秦汉）
	中古汉语（至于唐）
	近古汉语（唐至新文化运动）
		


白話文


*** 黄帝内经
前言：
	天地万物由一气（元气，具体分为阴气和阳气）所化。
	气为本质，阴阳五行为外在形态表现。
	
上古天真论
	上古之人，其知道者法于阴阳
	提挈天地，把握阴阳
	
四气调神大论
	顺四气之变化运行
	天明则日月不明
	夫四时阴阳者，万物之根本也
	故阴阳四时者，万物之终始也，死生之本也。
	逆之则灾害生，从之则苛疾不起，是谓得道。
	从阴阳刚生，逆之则死，从之则冶，逆之则乱。
	
生气通天论
	夫自古通天者，生之本，本于阴阳
	苍天之气，清净则志意冶，顺之则阳气固
	阳气者，精则养神，柔则养筋
	故风者，百病之始也，清静则肉腠闭，阳气拒，虽有大风苛毒，弗之能害
	
金匮真言
	？
	
阴阳应象大论
	阴阳者，天地之道也，万物之纲纪，变化之父母，生杀之本始，神明之府也
	阴静阳躁，阳生阴长，阳杀阴藏
	天有四时五行，以生长收藏
	故重阴必阳，重阳必阴
	天地者，万物之上下也，阴阳者，血气之男女也，左右者，阴阳之道路也，水火者，阴阳之征兆也，阴阳者万物之能始也
	


*** 三之谓
天命之谓性，率性之谓道，修道之谓教
	
	解读：
		我不能给出准确的对这句话的解释，以下是我的解读和猜测。
		
		整句解读0:
			天是一切的一切的主宰
			天让三之谓(知识)表现于外，让人可以感受
				天生三之谓，然后三之谓带我认识了更强大的天
			Everything is Tianming, include life, Tianli ...
			
			
		整句解读1:
			自然万物所组成的整体系统的命令叫作性，顺着性叫作道，修正道/修身而得道 叫作教
				自然万物整体系统对个体的命令，类似生命对细胞的命令
				天命，
					天命在人之谓性（心生），天命在物之谓理
				率性，
					率性应该不是已经必然存在的，否则就不需要修了。
						那么：
							有很多行为是不率性（道）的
								那么：
									以下之前的推论是不正确的：
										率性是顺着自己的欲望，癖好（做自已喜欢的事）？
				道，最高道德准则
				修道
					修身而得道，就像修仙？
					研究道，就像主修某某专业一样？
				之谓，
					他在讲（他讲的内容是）
					Note:
						谓之
							称他为

		
		对天命的探索：
			天命不是简单的结果，他是复杂的算法(因果)。
			对于每个个体天命内容都是不一样的，所以要向内和向外探索学习去了解天命内容（即性）。
				向内：
					自己的性，自己知道，所以要问自己。格除虚假才能看到真心。
					明心见性。
			天命内容：
				知识存在于外界，思考只是去感受知识
					被感受的知识才可以被自己所用，就像抓在手里的武器才可以被用。
				静生定，定生慧
				天行健，君子以自强不息；地势坤，君子以厚德载物
				平衡?
				物有本末，事有终始，知所先后，则近道矣？
				率性？ Should be NO, if: 率性（道），是人的最高行为准则？
				修道？ Should be NO, if: 率性（道），是人的最高行为准则？
				物竞天择？
				癖好？
				欲望？
				人性（利的和弊的）？
				社会的性？
				自然的性？
				人类追求圆满的智慧？
				一阴一阳？
				物格 知至 意诚 心正 身修？
					
				



*** SICP
List presentation
    node
        element
        ?link to sub list

Tree representation
    node
        element
        ?links to sub tree
        
        
图片信息表示
    像素相对位置关系

2015/8/2

We control complexity by building abstractions that hide details when appropriate.
  These skills are by no means unique to computer programming. The techniques we teach and draw upon are common to all of engineering design.
 principles of engineering design
 one should avoid complexities of control and concentrate on organizing the data to reflect the real structure of the world being modeled.


Computational processes are abstract beings that inhabit computers. As they evolve, processes manipulate other abstract things called data.

The evolution of a process is directed by a pattern of rules called a program. People create programs to direct processes. In effect, we conjure the spirits of the computer with our spells.

A computational process is indeed much like a sorcerer’s idea of a spirit.
The programs we use to conjure processes are like a sorcerer’sA spells
They are carefully composed from symbolic expressions in arcane and esoteric programming languages that prescribe the tasks we want our processes to perform.


A Lisp interpreter is a machine that carries out processes described in the Lisp language

Because the language possesses unique features that make it an excellent medium for studying important programming constructs and data structures and for relating them to the linguistic features that support them. The most significant of these features is the fact that Lisp descriptions of processes, called procedures, can themselves be represented and manipulated as Lisp data.
The importance of this is that there are powerful program-design techniques that rely on the ability to blur the traditional distinction between ‘‘passive’’ data and ‘‘active’’ processes.
 The ability to represent procedures as data also makes Lisp an excellent language for writing programs that must manipulate other programs as data, such as the interpreters and compilers that support computer languages.

A powerful programming language is more than just a means for instructing a computer to perform tasks. The language also serves as a framework within which we organize our ideas about processes.

 Thus, when we describe a language, we should pay particular attention to the means that the language provides for combining simple ideas to form more complex ideas.
 Every powerful language has three mechanisms for accomplishing this:
 primitive expressions, which represent the simplest entities the language is concerned with,
means of combination, by which compound elements are built from simpler ones, and
means of abstraction, by which compound elements can be named and manipulated as units.
 Expressions representing numbers may be combined with an expression representing a primitive procedure (such as + or *) to form a compound expression that represents the application of the procedure to those numbers.

Expressions such as these, formed by delimiting a list of expressions within parentheses in order to denote procedure application, are called combinations.

The convention of placing the operator to the left of the operands is known as prefix notation, and it may be somewhat confusing at first because it departs significantly from the customary mathematical convention. Prefix notation has several advantages, however. One of them is that it can accommodate procedures that may take an arbitrary number of arguments, as in the following examples:
(+ 21 35 12 7)
75
(* 25 4 12)
1200
A second advantage of prefix notation is that it extends in a straightforward way to allow combinations to be nested, that is, to have combinations whose elements are themselves combinations:
(+ (* 3 5) (- 10 6))
19

following a formatting convention known as pretty-printing
 Even with complex expressions, the interpreter always operates in the same basic cycle: It reads an expression from the terminal, evaluates the expression, and prints the result. This mode of operation is often expressed by saying that the interpreter runs in a read-eval-print loop.
 following a formatting convention known as pretty-printing
 A critical aspect of a programming language is the means it provides for using names to refer to computational objects. We say that the name identifies a variable whose value is the object.
 Define is our language’s simplest means of abstraction, for it allows us to use simple names to refer to the results of compound operations
 Indeed, complex programs are constructed by building, step by step, computational objects of increasing complexity.
 The interpreter makes this step-by-step program construction particularly convenient because name-object associations can be created incrementally in successive interactions. This feature encourages the incremental development and testing of programs and is largely responsible for the fact that a Lisp program usually consists of a large number of relatively simple procedures.
 It should be clear that the possibility of associating values with symbols and later retrieving them means that the interpreter must maintain some sort of memory that keeps track of the name-object pairs. This memory is called the environment
 naming mechanism is used to support abstraction?

As a case in point, let us consider that, in evaluating combinations, the interpreter is itself following a procedure.
 To evaluate a combination, do the following:
 1. Evaluate the subexpressions of the combination.
 2. Apply the procedure that is the value of the leftmost subexpression (the operator) to the arguments that are the values of the other subexpressions (the operands).
Thus, the evaluation rule is recursive in nature; that is, it includes, as one of its steps, the need to invoke the rule itself
 Notice how succinctly the idea of recursion can be used to express what, in the case of a deeply nested combination, would otherwise be viewed as a rather complicated process
 In general, we shall see that recursion is a very powerful technique for dealing with hierarchical, treelike objects. In fact, the ‘‘percolate values upward’’ form of the evaluation rule is an example of a general kind of process known as tree accumulation.
observe that the repeated application of the first step brings us to the point where we need to evaluate, not combinations, but primitive expressions such as numerals, built-in operators, or other names

 We take care of the primitive cases by stipulating that
 the values of numerals are the numbers that they name,
the values of built-in operators are the machine instruction sequences that carry out the corresponding operations, and
the values of other names are the objects associated with those names in the environment.
We may regard the second rule as a special case of the third one by stipulating that symbols such as + and * are also included in the global environment, and are associated with the sequences of machine instructions that are their ‘‘values.’’
The key point to notice is the role of the environment in determining the meaning of the symbols in expressions.
 the general notion of the environment as providing a context in which evaluation takes place will play an important role in our understanding of program execution.
 Notice that the evaluation rule given above does not handle definitions. For instance, evaluating (define x 3) does not apply define to two arguments, one of which is the value of the symbol x and the other of which is 3, since the purpose of the define is precisely to associate x with a value. (That is, (define x 3) is not a combination.)
 Such exceptions to the general evaluation rule are called special forms
 Each special form has its own evaluation rule.
The various kinds of expressions (each with its associated evaluation rule) constitute the syntax of the programming language.
 Lisp has a very simple syntax; that is, the evaluation rule for expressions can be described by a simple general rule together with specialized rules for a small number of special forms.

Numbers and arithmetic operations are primitive data and procedures.
Nesting of combinations provides a means of combining operations.
Definitions that associate names with values provide a limited means of abstraction.
 Compound procedures are used in exactly the same way as primitive procedures
 To evaluate a combination whose operator names a compound procedure, the interpreter follows much the same process as for combinations whose operators name primitive procedures
That is, the interpreter evaluates the elements of the combination and applies the procedure (which is the value of the operator of the combination) to the arguments (which are the values of the operands of the combination).
We can assume that the mechanism for applying primitive procedures to arguments is built into the interpreter.
For compound procedures, the application process is as follows:
 To apply a compound procedure to arguments, evaluate the body of the procedure with each formal parameter replaced by the corresponding argument.
 The process we have just described is called the substitution model for procedure application
 sequence of increasingly elaborate models of how interpreters work
The substitution model is only the first of these models -- a way to get started thinking formally about the evaluation process.
In general, when modeling phenomena in science and engineering, we begin with simplified, incomplete models. As we examine things in greater detail, these simple models become inadequate and must be replaced by more refined models.

 In particular, when we address in chapter 3 the use of procedures with ‘‘mutable data,’’ we will see that the substitution model breaks down and must be replaced by a more complicated model of procedure application. 15

An alternative evaluation model would not evaluate the operands until their values were needed. Instead it would first substitute operand expressions for parameters until it obtained an expression involving only primitive operators, and would then perform the evaluation.
This alternative ‘‘fully expand and then reduce’’ evaluation method is known as normal-order evaluation, in contrast to the ‘‘evaluate the arguments and then apply’’ method that the interpreter actually uses, which is called applicative-order evaluation

 But there is an important difference between mathematical functions and computer procedures. Procedures must be effective.

 The contrast between function and procedure is a reflection of the general distinction between describing properties of things and describing how to do things, or, as it is sometimes referred to, the distinction between declarative knowledge and imperative knowledge.

 In mathematics we are usually concerned with declarative (what is) descriptions, whereas in computer science we are usually concerned with imperative (how to) descriptions.
 declarative - noun
imperative - verb

evaluation of "special form if" different to procedure
   one of then clause / else clause will not be executed.


sqrt of x
guess y
find y's related position to solution z
x/y compare to x.
 it is crucial that each procedure accomplishes an identifiable task that can be used as a module in defining other procedures.
 We are not at that moment concerned with how the procedure computes its result, only with the fact that it computes the square.
The details of how the square is computed can be suppressed, to be considered at a later time.
Indeed, as far as the good-enough? procedure is concerned, square is not quite a procedure but rather an abstraction of a procedure, a so-called procedural abstraction. At this level of abstraction, any procedure that computes the square is equally good.

So a procedure definition should be able to suppress detail.

  formal parameter of a procedure has a very special role in the procedure definition, in that it doesn’t matter what name the formal parameter has.
 Such a name is called a bound variable, and we say that the procedure definition binds its formal parameters.
 Such nesting of definitions, called block structure, is basically the right solution to the simplest name-packaging problem.

The contrast between function and procedure is a reflection of the general distinction between describing properties of things and describing how to do things, or, as it is sometimes referred to, the distinction between declarative knowledge and imperative knowledge. In mathematics we are usually concerned with declarative (what is) descriptions, whereas in computer science we are usually concerned with imperative (how to) descriptions.20

The expansion occurs as the process builds up a chain of deferred operations (in this case, a chain of multiplications). The contraction occurs as the operations are actually performed.
This type of process, characterized by a chain of deferred operations, is called a recursive process.
 In the computation of n!, the length of the chain of deferred multiplications, and hence the amount of information needed to keep track of it, grows linearly with n (is proportional to n), just like the number of steps. Such a process is called a linear recursive process.
 In general, an iterative process is one whose state can be summarized by a fixed number of state variables, together with a fixed rule that describes how the state variables should be updated as the process moves from state to state and an (optional) end test that specifies conditions under which the process should terminate. In computing n!, the number of steps required grows linearly with n. Such a process is called a linear iterative process.
 It will execute an iterative process in constant space, even if the iterative process is described by a recursive procedure. An implementation with this property is called tail-recursive.
With a tail-recursive implementation, iteration can be expressed using the ordinary procedure call mechanism, so that special iteration constructs are useful only as syntactic sugar.31
 One convenient way to describe this difference is to use the notion of order of growth to obtain a gross measure of the resources required by a process as the inputs become larger.



Codes such as ASCII and the A-through-H code above are known as fixed-length codes


In this section, we will learn how to cope with data that may be represented in different ways by different parts of a program. This requires constructing generic procedures -- procedures that can operate on data that may be represented in more than one way. Our main technique for building generic procedures will be to work in terms of data objects that have type tags, that is, data objects that include explicit information about how they are to be processed. We will also discuss data-directed programming, a powerful and convenient implementation strategy for additively assembling systems with generic operations.

One way to view data abstraction is as an application of the ‘‘principle of least commitment.’’
This discipline of stripping off and attaching tags as data objects are passed from level to level can be an important organizational strategy, as we shall see in section 2.5.

The general strategy of checking the type of a datum and calling an appropriate procedure is called dispatching on type.
The issue underlying both of these weaknesses is that the technique for implementing generic interfaces is not additive.
What we need is a means for modularizing the system design even further. This is provided by the programming technique known as data-directed programming.
The key idea of data-directed programming is to handle generic operations in programs by dealing explicitly with operation-and-type tables

The style of programming we used in section 2.4.2 organized the required dispatching on type by having each operation take care of its own dispatching. In effect, this decomposes the operation-and-type table into rows, with each generic operation procedure representing a row of the table.
  An alternative implementation strategy is to decompose the table into columns and, instead of using ‘‘intelligent operations’’ that dispatch on data types, to work with ‘‘intelligent data objects’’ that dispatch on operation names.

This style of programming is called message passing.  The name comes from the image that a data object is an entity that receives the requested operation name as a ‘‘message.’’
 chapter 3 we will return to message passing, and we will see that it can be a powerful tool for structuring simulation programs.
 Formulating coherent policies on the division of responsibility among packages can be an overwhelming task in designing systems with many packages and many cross-type operations.
 Often the different data types are not completely independent, and there may be ways by which objects of one type may be viewed as being of another type. This process is called coercion.
 What we actually have is a so-called hierarchy of types
 The particular hierarchy we have here is of a very simple kind, in which each type has at most one supertype and at most one subtype. Such a structure, called a tower
 The manipulation of symbolic algebraic expressions is a complex process that illustrates many of the hardest problems that occur in the design of large-scale systems.

Indeed, it is fair to say that we do not yet completely understand coercion. In fact, we do not yet completely understand the concept of a data type.

Developing a useful, general framework for expressing the relations among different types of entities (what philosophers call ‘‘ontology’’) seems intractably difficult.

For example, much of the complexity of object-oriented programming languages -- and the subtle and confusing differences among contemporary object-oriented languages -- centers on the treatment of generic operations on interrelated types.
 We saw how primitive procedures and primitive data are combined to construct compound entities
 Effective program synthesis also requires organizational principles that can guide us in formulating the overall design of a program.
 In particular, we need strategies to help us structure large systems so that they will be modular, that is, so that they can be divided ‘‘naturally’’ into coherent parts that can be separately developed and maintained.
One powerful design strategy, which is particularly appropriate to the construction of programs for modeling physical systems, is to base the structure of our programs on the structure of the system being modeled.

To a large extent, then, the way we organize a large program is dictated by our perception of the system to be modeled.
The difficulties of dealing with objects, change, and identity are a fundamental consequence of the need to grapple with time in our computational models. These difficulties become even greater when we allow the possibility of concurrent execution of programs.
We ordinarily view the world as populated by independent objects, each of which has a state that changes over time.
An object is said to ‘‘have state’’ if its behavior is influenced by its history.
  We can characterize an object’s state by one or more state variables, which among them maintain enough information about history to determine the object’s current behavior.

 Each computational object must have its own local state variables describing the actual object’s state.
 If we choose to model the flow of time in the system by the elapsed time in the computer
 we must have a way to construct computational objects whose behaviors change as our programs run
 if we wish to model state variables by ordinary symbolic names in the programming language
 Observe that the expression (withdraw 25), evaluated twice, yields different values. This is a new kind of behavior for a procedure.
 Until now, all our procedures could be viewed as specifications for computing mathematical functions.
 as soon as we introduce assignment into our language, substitution is no longer an adequate model of procedure application.
 We model state with local state variables, and we model the changes of state with assignments to those variables.
 So long as we do not use assignments, two evaluations of the same procedure with the same arguments will produce the same result, so that procedures can be viewed as computing mathematical functions.
 Programming without any use of assignments, as we did throughout the first two chapters of this book, is accordingly known as functional programming.
 symbols in our language are essentially names for values
  Now a variable somehow refers to a place where a value can be stored, and the value stored at this place can change.
 environments play this role of ‘‘place’’ in our computational model.del
 A language that supports the concept that ‘‘equals can be substituted for equals’’ in an expresssion without changing the value of the expression is said to be referentially transparent.
 Once we forgo referential transparency, the notion of what it means for computational objects to be ‘‘the same’’ becomes difficult to capture in a formal way.
 Indeed, the meaning of ‘‘same’’ in the real world that our programs model is hardly clear in itself. I
 Thus, we cannot determine ‘‘change’’ without some a priori notion of ‘‘sameness,’’ and we cannot determine sameness without observing the effects of change.
 In general, so long as we never modify data objects, we can regard a compound data object to be precisely the totality of its pieces.
 But this view is no longer valid in the presence of change, where a compound data object has an ‘‘identity’’ that is something different from the pieces of which it is composed.
 A bank account is still ‘‘the same’’ bank account even if we change the balance by making a withdrawal; conversely, we could have two different bank accounts with the same state information.
 This complication is a consequence, not of our programming language, but of our perception of a bank account as an object
 We do not, for example, ordinarily regard a rational number as a changeable object with identity, such that change the numerator and still have ‘‘the same’’ rational number.
 In contrast to functional programming, programming that makes extensive use of assignment is known as imperative programming.
 In general, programming with assignment forces us to carefully consider the relative orders of the assignments to make sure that each statement is using the correct version of the variables that have been changed.
 Encapsulation reflects the general system-design principle known as the hiding principle: One can make a system more modular and robust by protecting parts of the system from each other; that is, by providing information access only to those parts of the system that have a ‘‘need to know.’’
 Notice that the rand-update procedure computes a mathematical function: Given the same input twice, it produces the same output. Therefore, the number sequence produced by rand-update certainly is not ‘‘random,’’ if by ‘‘random’’ we insist that each number in the sequence is unrelated to the preceding number.

Bugs can occur in our programs if we forget that a change to an object may also, as a ‘‘side effect,’’ change a ‘‘different’’ object because the two ‘‘different’’ objects are actually a single object appearing under different aliases.
Rather, a variable must somehow designate a ‘‘place’’ in which values can be stored.
 In our new model of evaluation, these places will be maintained in structures called environments.
 An environment is a sequence of frames. Each frame is a table (possibly empty) of bindings, which associate variable names with their corresponding values. (A single frame may contain at most one binding for any variable.) Each frame also has a pointer to its enclosing environment, unless, for the purposes of discussion, the frame is considered to be global. The value of a variable with respect to an environment is the value given by the binding of the variable in the first frame in the environment that contains a binding for that variable. If no frame in the sequence specifies a binding for the variable, then the variable is said to be unbound in the environment.
 With respect to environment A, the binding of x to 7 in frame II is said to shadow the binding of xto 3 in frame I.
 Indeed, one could say that expressions in a programming language do not, in themselves, have any meaning. Rather, an expression acquires a meaning only with respect to some environment in which it is evaluated.
 To evaluate a combination:
1. Evaluate the subexpressions of the combination. 12
2. Apply the value of the operator subexpression to the values of the operand subexpressions.
In the environment model of evaluation, a procedure is always a pair consisting of some code and a pointer to an environment.
 Procedures are created in one way only: by evaluating a lambda expression. This produces a procedure whose code is obtained from the text of the lambda expression and whose environment is the environment in which the lambda expression was evaluated to produce the procedure.
 In general, define creates definitions by adding bindings to frame
 The environment model specifies: To apply a procedure to arguments, create a new environment containing a frame that binds the parameters to the values of the arguments. The enclosing environment of this frame is the environment specified by the procedure. Now, within this new environment, evaluate the procedure body.
 The environment model of procedure application can be summarized by two rules:
A procedure object is applied to a set of arguments by constructing a frame, binding the formal parameters of the procedure to the arguments of the call, and then evaluating the body of the procedure in the context of the new environment constructed. The new frame has as its enclosing environment the environment part of the procedure object being applied.
A procedure is created by evaluating a lambda expression relative to a given environment. The resulting procedure object is a pair consisting of the text of the lambda expression and a pointer to the environment in which the procedure was created.
Evaluating the expression (set! <variable> <value>) in some environment locates the binding of the variable in the environment and changes that binding to indicate the new value.
Moreover, the evaluation model, though abstract, provides a correct description of how the interpreter evaluates expressions.



2015/8/4
We can see from the figure that, because of the delays involved, the outputs may be generated at different times. Many of the difficulties in the design of digital circuits arise from this fact.

 The agenda is made up of time segments.

 Computer programs are traditionally organized as one-directional computations

 On the other hand, we often model systems in terms of relations among quantities.

 Such an equation is not one-directional. Given any four of the quantities, we can use it to compute the fifth. Yet translating the equation into a traditional computer language would force us to choose one of the quantities to be computed in terms of the other four. Thus, a procedure for computing the area A could not be used to compute the deflection d, even though the computations of A and d arise from the same equation.

 we sketch the design of a language that enables us to work in terms of relations themselves.

 The primitive elements of the language are primitive constraints，which state that certain relations hold between quantities.

 We combine constraints by constructing constraint networks, in which constraints are joined by connectors.



A connector is an object that ‘‘holds’’ a value that may participate in one or more constraints.

Notice that the very same network is being used to compute C given F and to compute F given C. This nondirectionality of computation is the distinguishing feature of constraint-based systems.

#############################################
2015/8/6
allow us to use ordinary procedural syntax to access the local procedures of objects.
It is striking that we can interchange the role of ‘‘procedures’’ and ‘‘data’’ in such a simple way.
The truth of the matter is that, in a language in which we can deal with procedures as objects, there is no fundamental difference between ‘‘procedures’’ and ‘‘data,’’ and we can choose our syntactic sugar to allow us to program in whatever style we choose.
The agenda is a headed list
 Constraint propagation
 expression-oriented format
 we could work in ‘‘imperative style,’’ using procedures that set the values of designated vector arguments but do not themselves return vectors as values
 Lisp allows us to return compound objects as values of procedures
 One reason is that the non-expression-oriented constraint language provides a handle on constraint objects (e.g., the value of the adder procedure) as well as on connector objects
 The central issue lurking beneath the complexity of state, sameness, and change is that by introducing assignment we are forced to admit time into our computational models.
 The result of evaluating an expression depends not only on the expression itself, but also on whether the evaluation occurs before or after these moments.
Building models in terms of computational objects with local state forces us to confront time as an essential concept in programming.
 On the surface, time seems straightforward. It is an ordering imposed on events
 The general phenomenon illustrated here is that several processes may share a common state variable. What makes this complicated is that more than one process may be trying to manipulate the shared state at the same time.
 There are two important aspects to this requirement. First, it does not require the processes to actually run sequentially, but only to produce results that are the same as if they had run sequentially.
 We’ve seen that the difficulty in dealing with concurrent processes is rooted in the need to consider the interleaving of the order of events in the different processes.
 serialization creates distinguished sets of procedures such that only one execution of a procedure in each serialized set is permitted to happen at a time.
 If some procedure in the set is being executed, then a process that attempts to execute any procedure in the set will be forced to wait until the first execution has finished.
 We then ensure that no other procedure that assigns to the variable can run concurrently with this procedure by serializing all of these procedures with the same serializer.
 Serializers are constructed by make-serializer, whose implementation is given below. A serializer takes a procedure as argument and returns a serialized procedure that behaves like the original procedure. All calls to a given serializer return serialized procedures in the same set.
 We implement serializers in terms of a more primitive synchronization mechanism called a mutex
 The actual implementation of test-and-set! depends on the details of how our system runs concurrent processes.
For example, we might be executing concurrent processes on a sequential processor using a time-slicing mechanism that cycles through the processes, permitting each process to run for a short time before interrupting it and moving on to the next process. In that case, test-and-set! can work by disabling time slicing during the testing and setting. 46
Alternatively, multiprocessing computers provide instructions that support atomic operations directly in hardware. 47
 Each process is stalled forever, waiting for the other. This situation is called a deadlock.
 But the problems of concurrency lie deeper than this, because, from a fundamental point of view, it’s not always clear what is meant by ‘‘shared state.’’
 The complexities we encounter in dealing with time and state in our computational models may in fact mirror a fundamental complexity of the physical universe.
 Time is a device that was invented to keep everything from happening at once.
 more formal way to express this idea is to say that concurrent programs are inherently nondeterministic.
That is, they are described not by single-valued functions, but by functions whose results are sets of possible values.
 A less stringent restriction on concurrency would ensure that a concurrent system produces the same result as if the processes had run sequentially in some order.
 there may be more than one possible ‘‘correct’’ result produced by a concurrent program, because we require only that the result be the same as for some sequential order.
 One issue that arises here is to determine what happens if two processes attempt to acquire the same resource at exactly the same time by using such an instruction. This requires some mechanism for making a decision about which process gets control. Such a mechanism is called an arbiter.

2015/8/10
This definition works because, at any point, enough of the integers stream has been generated so that we can feed it back into the definition to produce the next integer.

 We know now that we can represent state as a ‘‘timeless’’ stream of values rather than as a set of variables to be updated.

2015/8/13

one of the major benefits of introducing assignment is that we can increase the modularity of our systems by encapsulating, or ‘‘hiding,’’ parts of the state of a large system within local variables.

We can model a changing quantity, such as the local state of some object, using a stream that represents the time history of successive states.

In essence, we represent time explicitly, using streams, so that we decouple time in our simulated world from the sequence of events that take place during evaluation.

time - can be absolute time(yyyy:MM:dd:hh:mm:ss) or relative time(time related to some event)

         when xxx then behavior xxx

2015/8/15
One way to resolve this paradox is to realize that it is the user’s temporal existence that imposes state on the system. If the user could step back from the interaction and think in terms of streams of balances rather than individual transactions, the system would appear stateless.



 We can describe the time-varying behavior of a quantity x as a function of time x(t). If we concentrate on x instant by instant, we think of it as a changing quantity. Yet if we concentrate on the entire time history of values, we do not emphasize change -- the function itself does not change. 52

 The memoizing optimization is also known as call-by-need

 Similarly in physics, when we observe a moving particle, we say that the position (state) of the particle is changing. However, from the perspective of the particle’s world line in space-time there is no change involved.

 An example of a place where the object viewpoint fails is quantum mechanics, where thinking of things as individual particles leads to paradoxes and confusions.

 the key to the treasure is the treasure!

 expert programmers control the complexity of their designs with the same general techniques used by designers of all complex systems.

 preserve modularity by adopting appropriate large-scale views of system structure.

 Establishing new languages is a powerful strategy for controlling complexity in engineering design

 we can often enhance our ability to deal with a complex problem by adopting a new language that enables us to describe (and hence to think about) the problem in a different way, using primitives, means of combination, and means of abstraction that are particularly well suited to the problem at hand. 1

 The evaluator, which determines the meaning of expressions in a programming language, is just another program.

 Seen from this perspective, the technology for coping with large-scale computer systems merges with the technology for building new computer languages,

 and computer science itself becomes no more (and no less) than the discipline of constructing appropriate descriptive languages.


2015/8/19
Delaying evaluation of procedure arguments until the last possible moment (e.g., until they are required by a primitive operation) is called lazy evaluation.

If the body of a procedure is entered before an argument has been evaluated we say that the procedure is non-strict in that argument. If the argument is evaluated before the body of the procedure is entered we say that the procedure is strict in that argument.

 A striking example of a procedure that can usefully be made non-strict is cons (or, in general, almost any constructor for data structures).

 The delayed arguments are not evaluated; instead, they are transformed into objects called thunks. 34 The thunk must contain the information required to produce the value of the argument when it is needed, as if it had been evaluated at the time of the application. Thus, the thunk must contain the argument expression and the environment in which the procedure application is being evaluated.

 The process of evaluating the expression in a thunk is called forcing.



2015/8/23 21:50
Just as the lazy evaluator freed the programmer from the details of how values are delayed and forced, the nondeterministic program evaluator will free the programmer from the details of how choices are made.

Stream processing uses lazy evaluation to decouple the time when the stream of possible answers is assembled from the time when the actual stream elements are produced.


``lazy'' refers to the mechanisms of particular evaluators, while ``normal-order'' refers to the semantics of languages
The ``strict'' versus ``non-strict'' terminology means essentially the same thing as ``applicative-order'' versus ``normal-order,'' except that it refers to individual procedures and arguments rather than to the language as a whole.

these choices raise issues that become both subtle and confusing in the presence of assignments.

a programming paradigm called nondeterministic computing by building into the evaluator a facility to support automatic search.

With nondeterministic evaluation, an expression represents the exploration of a set of possible worlds, each determined by a set of choices.

Abstractly, we can imagine that evaluating an amb expression causes time to split into branches, where the computation continues on each branch with one of the possible values of the expression.
We say that amb represents a nondeterministic choice point.
Execution would proceed as in a sequential machine, until an amb expression is encountered. At this point, more processors would be allocated and initialized to continue all of the parallel executions implied by the choice.
it is better to systematically search all possible execution paths.
When the evaluator encounters an application of amb, it initially selects the first alternative. This selection may itself lead to a further choice. The evaluator will always initially choose the first alternative at each choice point. If a choice results in a failure, then the evaluator automagically46 backtracks to the most recent choice point and tries the next alternative. If it runs out of alternatives at any choice point, the evaluator will back up to the previous choice point and resume from there. This process leads to a search strategy known as depth-first search or chronological backtracking.47

We also need a grammar, that is, a set of rules describing how grammatical elements are composed from simpler elements.

ordinary evaluator take one argument: the environment of execution. In contrast, the execution procedures in the amb evaluator take three arguments: the environment, and two procedures called continuation procedures.

The evaluation of an expression will finish by calling one of these two continuations: If the evaluation results in a value, thesuccess continuation is called with that value; if the evaluation results in the discovery of a dead end, the failure continuation is called.
Constructing and calling appropriate continuations is the mechanism by which the nondeterministic evaluator implements backtracking.

It is the job of the success continuation to receive a value and proceed with the computation. Along with that value, the success continuation is passed another failure continuation, which is to be called subsequently if the use of that value leads to a dead end.

A failure is triggered during evaluation (that is, a failure continuation is called) when a user program explicitly rejects the current line of attack (for example, a call to require may result in execution of (amb), an expression that always fails -- see section 4.3.1)

we need additional syntax procedures to recognize the amb special form

In actuality, the distinction between nondeterministically returning a single choice and returning all choices depends somewhat on our point of view. From the perspective of the code that uses the value, the nondeterministic choice returns a single value. From the perspective of the programmer designing the code, the nondeterministic choice potentially returns all possible values, and the computation branches so that each value is investigated separately.

dependency-directed backtracking

developing a new paradigm for formulating search that is now called truth maintenance

On the other hand, high-level languages provide, as part of the language implementation, a substantial amount of methodological knowledge that frees the user from concern with numerous details of how a specified computation will progress.

an expression that describes the value of a function may also be interpreted as a means of computing that value.

In a nondeterministic language, expressions can have more than one value, and, as a result, the computation is dealing with relations rather than with single-valued functions.

Logic programming extends this idea by combining a relational vision of programming with a powerful kind of symbolic pattern matching called unification.58

This procedure can be regarded as a translation into Lisp of the following two rules

In a logic programming language, the programmer writes an append ``procedure'' by stating the two rules about append given above.

``How to'' knowledge is provided automatically by the interpreter to allow this single pair of rules to be used to answer all three types of questions about append.60

In addition, sometimes ``what is'' information gives no clue ``how to'' compute an answer.

We call this language the query language

An interpreter for a logic programming language is considerably more complex than an interpreter for a language like Lisp.

Logic programming excels in providing interfaces to data bases for information retrieval.



2015/8/24
an expression that describes the value of a function may also be interpreted as a means of computing that value

most programming languages are strongly biased toward unidirectional computations (computations with well-defined inputs and outputs).

Part of the power comes from the fact that a single ‘‘what is’’ fact can be used to solve a number of different problems that would have different ‘‘how to’’ components.

In a logic programming language, the programmer writes an append ‘‘procedure’’ by stating the two rules about append given above. ‘‘How to’’ knowledge is provided automatically by the interpreter to allow this single pair of rules to be used to answer all three types of questions about append.


2015/8/29
The system finds all assignments to variables in the query pattern

that satisfy the pattern -- that is, all sets of values for the variables such that if the pattern variables are instantiated with (replaced by) the values, the result is in the data base.

that satisfy some requirement (instantiate pattern with it, get a instance in db)



The system responds to the query by listing all instantiations of the query pattern with the variable assignments that satisfy it.






2015/8/30 9:34
We can regard a rule as a kind of logical implication: If an assignment of values to pattern variables satisfies the body, then it satisfies the conclusion.
Consequently, we can regard the query language as having the ability to perform logical deductions based upon the rules.

rule in query vs rule in logic programing
rule find variable assignments satisfy body
rule conclusion represent the body


2015/9/2
pattern matcher is a program that tests whether some datum fits a specified pattern



 The pattern matcher used by the query system takes as inputs a pattern, a datum, and a frame that specifies bindings for various pattern variables. It checks whether the datum matches the pattern in a way that is consistent with the bindings already in the frame.

 The aim of logic programming is to provide the programmer with techniques for decomposing a computational problem into two separate problems: ‘‘what’’ is to be computed, and ‘‘how’’ this should be computed.

 In logic, we interpret the statement ‘‘not P’’ to mean that P is not true. In the query system, however, ‘‘not P’’ means that P is not deducible from the knowledge in the data base.

 In other words, the not of logic programming languages reflects the so-called closed world assumption that all relevant information has been included in the data base.

 In addition, sometimes ‘‘what is’’ information gives no clue ‘‘how to’’ compute an answer. For example, consider the problem of computing the y such that y 2 = x.

 The speed of such computers was to be measured in LIPS (Logical Inferences Per Second) rather than the usual FLOPS (FLoating-point Operations Per Second).

 Although using the same pattern variable in two parts of a query forces the same value to appear in both places, using different pattern variables does not force different values to appear.

 This is usually arranged by breaking up the process into a fast, coarse match and the final match.

 But even the metacircular evaluator leaves important questions unanswered, because it fails to elucidate the mechanisms of control in a Lisp system. For instance, the evaluator does not explain how the evaluation of a subexpression manages to return a value to the expression that uses this value, nor does the evaluator explain how some recursive procedures generate iterative processes (that is, are evaluated using constant space) whereas other recursive procedures generate recursive processes.


2015/9/8
difference between the gcd procedure, which reduces the original computation to a new GCD computation, and factorial, which requires computing another factorial as a subproblem.
In GCD, the answer to the new GCD computation is the answer to the original problem.
In the case of factorial (or any recursive process) the answer to the new factorial subproblem is not the answer to the original problem.

This dictates the use of a stack, or ``last in, first out'' data structure, to save register values.

2015/9/12 18:19
The assembler transforms the sequence of controller expressions for a machine into a corresponding list of machine instructions, each with its execution procedure.

Overall, the assembler is much like the evaluators we studied in chapter 4 -- there is an input language (in this case, the register-machine language) and we must perform an appropriate action for each type of expression in the language.
As it scans the text, it constructs both a list of instructions and a table that associates each label with a pointer into that list.
 Then the assembler augments the instruction list by inserting the execution procedure for each instruction.

2015/9/17
An argument like receive that is the next procedure to be invoked is called a ‘‘continuation.’’

Typical memory systems provide two primitive operations: one that fetches the data stored in a specified location and one that assigns new data to a specified location.

Abstractly, a vector is a compound data object whose individual elements can be accessed by means of an integer index in an amount of time that is independent of the index.

  For computer memory, this access can be implemented through the use of address arithmetic to combine a base address that specifies the beginning location of a vector in memory with an index that specifies the offset of a particular element of the vector.

 way to distinguish one kind of data from another. There are many methods of accomplishing this, but they all reduce to using typed pointers, that is, to extending the notion of ‘‘pointer’’ to include information on data type.



 To accomplish this, the reader maintains a table, traditionally called the obarray, of all the symbols it has ever encountered. When the reader encounters a character string and is about to construct a symbol, it checks the obarray to see if it has ever before seen the same character string. If it has not, it uses the characters to construct a new symbol (a typed pointer to a new character sequence) and enters this pointer in the obarray. If the reader has seen the string before, it returns the symbol pointer stored in the obarray. This process of replacing character strings by unique pointers is called interning symbols.

 Garbage collection is based on the observation that, at any moment in a Lisp interpretation, the only objects that can affect the future of the computation are those that can be reached by some succession of car and cdr operations starting from the pointers that are currently in the machine registers. 14

 There are many ways to perform garbage collection. The method we shall examine here is called stop-and-copy.

 The basic idea is to divide memory into two halves: ‘‘working memory’’ and ‘‘free memory.’’ When cons constructs pairs, it allocates these in working memory. When working memory is full, we perform garbage collection by locating all the useful pairs in working memory and copying these into consecutive locations in free memory.

 The useful pairs are located by tracing all the car and cdr pointers, starting with the machine registers.

 We will assume that there is a register called root that contains a pointer to a structure that eventually points at all accessible data.

This can be arranged by storing the contents of all the machine registers in a pre-allocated list pointed at by root just before starting garbage collection.

 explicit-control evaluator that we develop in this section shows how the underlying procedure-calling and argument-passing mechanisms used in the evaluation process can be described in terms of operations on registers and stacks.

Even though the procedure is syntactically recursive (defined in terms of itself), it is not logically necessary for an evaluator to save information in passing from one call to sqrt-iter to the next. 25

 An evaluator that can execute a procedure such as sqrt-iter without requiring increasing storage as the procedure continues to call itself is called a tail-recursive evaluator.



2015/9/19 22:12

As an alternative to saving only what is needed, we could save all the registers (except val) before each recursive call.
This is called a framed-stack discipline. This would work but might save more registers than necessary; this could be an important consideration in a system where stack operations are expensive. Saving registers whose contents will not be needed later may also hold onto useless data that could otherwise be garbage-collected, freeing space to be reused.


2015/9/20 9:19

explicit-c> register machine

explicit-control evaluator controller interprets Scheme programs.

explicit-control evaluator c>interpreter for Scheme programs.
    for a register-machine language (native language of the machine)
    is a program written in native language


2015/9/20 9:28

register machine controller interprets Scheme programs.
explicit-control evaluator of section 5.4 is a register machine

explicit-control evaluator machine is universal
evaluator's controller orchestrates the use of its data paths to perform the desired computation.

Commercial general-purpose computers are register machines organized around a collection of registers and operations that constitute an efficient and convenient universal set of data paths.

The controller for a general-purpose machine is an interpreter for a register-machine language like the one we have been using.

Programs written in machine language are sequences of instructions that use the machine's data paths.

An interpreter written in the native language of a machine

The primitive procedures of the source language are implemented as a library of subroutines written in the native language of the given machine.

A program to be interpreted (called the source program) is represented as a data structure.

The interpreter traverses this data structure, analyzing the source program. As it does so, it simulates the intended behavior of the source program by calling appropriate primitive subroutines from the library.


A compiler for a given source language and machine translates a source program into an equivalent program (called the object program) written in the machine's native language.

 an interpreter provides a more powerful environment for interactive program development and debugging


Our compiler is much like our interpreter, both in its structure and in the function it performs.

the mechanisms used by the compiler for analyzing expressions will be similar to those used by the interpreter.

we will design the compiler to generate code that obeys the same conventions of register usage as the interpreter: The environment will be kept in the env register, argument lists will be accumulated in argl, a procedure to be applied will be in proc, procedures will return their answers in val, and the location to which a procedure should return will be kept in continue.

In general, the compiler translates a source program into an object program that performs essentially the same register operations as would the interpreter in evaluating the same source program.


2015/10/5
The procedure object will be constructed at run time by combining the current environment (the environment at the point of definition) with the entry point to the compiled procedure body (a newly generated label)


Compile-lambda-body constructs the code for the body of the procedure.
This code begins with a label for the entry point.
Next come instructions that will cause the run-time evaluation environment to switch to the correct environment for evaluating the procedure body -- namely, the definition environment of the procedure, extended to include the bindings of the formal parameters to the arguments with which the procedure is called.

A compiled procedure (as constructed by compile-lambda) has an entry point, which is a label that designates where the code for the procedure starts. The code at this entry point computes a result in val and returns by executing the instruction (goto (reg continue)).


Because our language is lexically scoped, the run-time environment for any expression will have a structure that parallels the lexical structure of the program in which the expression appears.4

In order to generate such code, the compiler must be able to determine the lexical address of a variable it is about to compile a reference to.

One way for the compiler to produce code that uses lexical addressing is to maintain a data structure called a compile-time environment.

The top-level call to compile uses an empty compile-time environment. When a lambda body is compiled, compile-lambda-bodyextends the compile-time environment by a frame containing the procedure's parameters, so that the sequence making up the body is compiled with that extended environment. At each point in the compilation, compile-variable and compile-assignment use the compile-time environment in order to generate the appropriate lexical addresses.

An interpreter raises the machine to the level of the user program; a compiler lowers the user program to the level of the machine language.

The alternatives of interpretation and compilation also lead to different strategies for porting languages to new computers. Suppose that we wish to implement Lisp for a new machine. One strategy is to begin with the explicit-control evaluator of section 5.4 and translate its instructions to instructions for the new machine. A different strategy is to begin with the compiler and change the code generators so that they generate code for the new machine.

The second strategy allows us to run any Lisp program on the new machine by
first compiling it with the compiler running on our original Lisp system, and linking it with a compiled version of the run-time library.53
Better yet, we can compile the compiler itself, and run this on the new machine to compile other Lisp programs.54
Or we can compile one of the interpreters of section 4.1 to produce an interpreter that runs on the new machine.

The overhead of checking, however, can be many times the cost of the array reference itself, and a programmer should weigh speed against safety in determining whether such a check is desirable.

A good compiler should be able to produce code with such checks, should avoid redundant checks, and should allow programmers to control the extent and type of error checking in the compiled code.

As a result, it falls to programmers to explicitly provide error checking. Unfortunately, people often neglect to do this, even in critical applications where speed is not a constraint.






*** Common shapes in IT
  
 * PCA(Primitive, Combination, Abstraction)

  * Recursion  
    e.g. 
        function
          defined with itself
        data  
          s-expression

  * Group

    * Vertical Group  
      e.g. have different layers
    * Horizontal Group  
      e.g. put same in one group, different in the other group

  * Convertional Interface



Note:  
PCA is also the shape of knowlege  
Nubmer system also can follow PCA  
e.g.  
    Primitive: 1
    Combination: + 
    Get Abstraction: 2
    Now get component: 1, 2
    do the same on above to get: 1, 2, 3, 4
    do the same on above to get: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16



*** function
Relationship between independent variable and dependent variable

## Category:
 * **pure function**, all independent variable in parameters
 * **non-pure function**, at least one independent variable in closure scope


 * **normal function** relation is complete, it can directly link from independent variable to dependent variable
 * **high-order function** - relation is incomplete, missing part need to be passed in 
  before link from independent variable to dependent variable  
  E.g. (filter pred-func problem)
  
 * **static function** can only be created once(hard coded in source)
 * **dynamic function** can be created multiple times(returned from other function)

## Details
Function Application will generate value of dependent variable  
Function Name is not part of Function, it's a Reference to Function  
Function can not contains itself, but can contains a reference of itself  

### Parameter:
A symbol which will bind to independent variable

Variadic Parameter:  
A symbol which will bind to multiple independent variable
(combine multiple independent variable via collection then bind symbol to collection)

Parameter order best practice:

 * parameter for missing process comes first
 * variadic parameter comes last



*** stability
Idea > Implementation


e.g.
Idea:
code in list stucture
multiple layer process(reader, macro compiler, executor)
uniform sequence view of different data

Corresponding Impl:
lisp, scheme, clojure, chicken ...
Racket, common lisp, clojure ...
clojure(current IO don't support sequenc view, I hope it can support) ...

*** group
How to group?
	Base on Relationship(Refer to: Cognize/world)
		File and Package relationship:     
			Both extend from Item                  
			They are in same level in the OHT(Object Hierachy Tree)

*** LANGUAGE
Language is Symbols or combination of Symbols following Syntax rule refer to Stuff

**** Elements
Symbol
Syntax
  Combination of Symbols
  Combination Structure:
    tree
      can refer to layer
      e.g.
      #+BEGIN_SRC clojure
        (+ (* 2 2)
           (* 3 3))
      #+END_SRC

    sequence
      can refer to sequence
      e.g.
      #+BEGIN_SRC clojure
        (-> 2
            (* 2)
            (+ (* 3 3)))
      #+END_SRC

      #+BEGIN_SRC javascript
        var n = 2;
        n = n * 2;
        n = n + (3 * 3);
      #+END_SRC

Stuff
  Stuff is also referenced by "Semantic of Symbol"
  human being may link it to different Symbol in different context

  Link Stuff in Data (Static language)
    link to Syntax in all contexts

  Link Stuff in Function (Dynamic language)
    link to Syntax in context of a Function

Note:
  Normally Symbol not represent itself but its referenced Stuff
  If you want Symbol represent itself, quotate it

  Symbol and Stuff can change independently.
    e.g.
      change Symbole only: I love 1 -> I love one
      change Stuff: 你妹啊（你的妹妹啊） -> 你妹啊（骂人）



**** Lexical Context
In previous language location: bind Symbol to Stuff
In current language location: to find Symbol corresponding Stuff, search previous language location, find corresponding binding, find corresponding Stuff

**** Category
定名词 - 确定的某个东西, 或者东西的某个面
  普通名词
  动名词
不定名词 - 比较之下选择的东西



*** Language 2
Guanzhao Clojure
   Guanzhao Clojure is the root of afterward understandings about Clojure
   Guanzhao Clojure also the root of Memory of Guanzhao Clojure

   Futher:
       Guanzhao this Memory will generate understandings about Guanzhao
       e.g.
            Guanzhao Clojure is the top root, as it's a fact, it comes from Kong/Wu.
            Guanzhao XXX can generate understandings/insight
            放低自己是所有修身的本质和方法
                E.g. 放弃自私
                这和:厚德载物...，水居下位...,地藏...是一致的
            求学习Clojure和求快速学习Clojure是两个求。
                后一个求本质上是求压榨自己的身体。
                后一个求不会对前一个求有任何帮助，只是揠苗助长。
            Just Guanzhao Clojure, no worry you will get understanding about Clojure soon or later
            Guanzhao must have a target
            观见
                观过程也，见图像也。观见一体，不可独立存在。
                放低才会观，放低才会放弃求
            求生烦恼
            一个很神奇舒服的心境体验：没有任何的恐惧，追求只有无私的付出
                在这个体验中真实与假已经不重要了，重要的是心境
                这是解脱的心境？
            绳子上的平衡者
            一阴一阳
                看二，不看一。如果看一又缺了一半了。
                一切是二不是一（无论是现实的还是抽象的道/第一因/第一法则/本质）
            人不高兴都是自私在不能如愿下的表现



Clojure's root
    Programmers need it to convey info from their mind to other programmer's or executor
    Note: Clojure's goal is to maintain its root

Clojure's components(to support its feature):
    Executor
        Read Symbol and Symbol Compose Structure
        Get the mapped Info
        Perform actions according to Info

Clojure's features(to maintain its root):
    Evolution
        Create new Symbol
            done via def*
        Create new Symbol Compose Structure
            done via macro

	for Building Abstractions
		Class
		Macro
			A function run on compile time to generate code for runtime.
			The purpose is to create new language syntax.

    General Composed Problem Solution:
        Reduce
            Similar to Recursion, but first divide Problem to Problem Piece then pass to recursive process as input
        Map
            Similar to Recursion but:
                1, only Problem Piece pass to recursive process
                2, add Answer Piece to Answer by put them into a collection
	Pair
		sufficient to create any Complexity(e.g. list, tree)
	Lazy Data
		Data will be created when it accessed.
		Normally this is implemented via Function & Function Application
	Meta
		Description of some object
		What's the relationship with attribute?
		E.g.
			location
	Protocol/Interface
		Semantic:
			It contains service specification
			It should serve to external as proxy of implementations
				E.g.
					Interface Reflection Method in Java dispatch to implementation base on argument object
					Protocol Service Function in Clojure dispatch to implementation base on argument type(can be interface)




*** Engineering
Engineering is investigate and apply knowledge.

Software Engineering (SE) is the application of a 
	systematic, 
	disciplined, 
	quantifiable 
approach to the 
	development, 
	operation, 
	and maintenance 
of software, 
and the study of these approaches; 
that is, the application of engineering  to software.


ACM 与 IEEE Computer Society 联合修定的 SWEBOK[12]（Software Engineering Body of Knowledge）提到，软件工程领域中的核心知识包括：

    * 软件需求（Software requirements）
    * 软件设计（Software design）
    * 软件建构（Software construction）
    * 软件测试（Software test）
    * 软件维护与更新（Software maintenance）
    * 软件构型管理（Software Configuration Management, SCM）
    * 软件工程管理（Software Engineering Management）
    * 软件开发过程（Software Development Process）
    * 软件工程工具与方法（Computer-Aided Software Engineering, CASE）
    * 软件品质（Software Quality）


*** License
License
	Copyright owner grant permission

	When you license your work, you're not giving away any of your rights. You still hold the original copyright (or patent if you have one) on that work

	Steps to Apply License to software
		Put the full license text in a file called LICENSE in the top directory of your distribution
		Each original source document SHOULD include a short license header at the top
		     copyright declare
		     license apply declare
		     saying where to find the full text of the license
	

	Copyright - right to copy(distribute)
	
	Copyleft(A play on word Copyright)
		A copyright licensing scheme		
		Offer right to distribute copies and modified versions of a work and requiring that the same rights be preserved in modified versions of the work
		
	public domain
		Works in the public domain are those whose intellectual property rights have expired, have been forfeited, or are inapplicable.



*** MATH
Power for science

Math
  研究各种量和他们的关系。
	E.g. 
		频率 , 有关时间的量
		距离，距离量
		速度，速度量
		距离/速度=时间

Category:
	Calculus
		calculus of Infinitesimals(Limit)
			"calculus" comes from Latin (calculus) and refers to a small stone used for counting
			More generally, calculus (plural calculi) refers to any method or system of calculation guided by the symbolic manipulation of expressions.
	
		two major branches
			differential calculus
				concerning rates of change
			integral calculus
				concerning accumulation of quantities
	
	Geometry
		study of shape
	
	Algebra
		Letters and symbols are used to represent quantities


Components:
	Number
		A mathematical object used to count, label, and measure
		Category:
			Real Number
				A value that represents a quantity along a continuous line
				Category:
					Rational number
						number can be expressed as the quotient or fraction p/q of two integers, with the denominator q not equal to zero
		
		数的系统是一个独立的体系系统，在这个系统中每一个数字都是单例的
		
	Operation (Should be kind of Function)
		An action or procedure which produces a new value from one or more input values, called "operands"
		Category:
			unary operation
				an operation with only one operand
				
			binary operation
				an operation with only 2 operand
		Operations:
			Multiply is a special add
			Squar is a special Multiply
			Multiply need: *, base, multiplyer

	Limit
		The value that a function or sequence "approaches" as the input or index approaches some value
		It's essential to Calculus
		Used to define continuity, derivatives, and integrals
	
	Set
		Collection of distinct objects
		Conventionally denoted with capital letters
	
	
	Structure
		Mathematical Objects attached (or related) to a Set
		Category:
			Measure
				Assign a number to each suitable subset of that set
			Topology
				
			Algebraic Structure
				MOs are finitary operations				
				Category:
					Magma
						Consisting of a Set together with an binary operation
					Category
						Comprises "objects" that are linked by "arrows"
	
	
	Evolutionary Algorithm
		Genetic Algorithm
	
	Function (Refer to lianjie.txt)
		A relation between a set of Inputs and a set of permissible Outputs.
			Normally this relation is directional 
				Relation is between two things, more specific is from one thing to the other
				Relation from 'A' to 'B' is different from relation from 'B' to 'A'
					E.g. 
						me -> boss, the relation '->' is follow
						me <- boss, the relation '<-' is instruction
			
			Format:
				f - Function
				x - Input
				f(x) - Denote output of function f corresponding to input x (read "f of x")
				
			For better understanding a Function, need to build clear route from Input to Output.
			
			Normally this relation in math is about numbers (Refer to world.txt)
			
			函数关系中的数 一般可用来描述某些事物的属性。
				如坐标中的图形的长度，面积的量的数。
		
		Application
			Refer to lianjie.txt
	
	Leaner Relationship
		The coordinate chart to represent/describe relationship in is a line
	
	Morphism
		A structure-preserving mapping from one mathematical structure to another
		In category theory, Morphisms are sometimes also called arrows
		Category:
			Functor
				A type of mapping between Categories

	Monad
		An (endo-)functor, together with two natural transformations
	
	Natural Transformation
		Provides a way of transforming one functor into another while respecting the internal structure
	
	Class
		A collection of sets (or sometimes other mathematical objects) that can be unambiguously defined by a property that all its members share


**** Number
Number
	A State of world (refer to world.txt)
	
	Derive from Nature. E.g. dewdrop on lotus leaf
		1, small dew drop <-> low order bit
		2, big dew drop <-> high order bit
		3, dewdrop accumulate reach the tipping point will transit to a big dewdrop <-> add operation
			tipping point <-> N of base-N system
			
			
	base-N system
		1, one order can put N-1 numbers
		2, 
			number(Pn 1) = N * number(Pn-1 1) : n >= 2
			number(Pn 1) = 1 : n = 1
	
	
	Abstracted from Nature (Derived from Nature)
		Note:
			The addition should done one number by one number, this will help understand the addition behavior
	
		 Implementations:
		 	base-N system
		 	complement coding system
		 		Implementations:
		 			bit in PC
		 	


**** Set

FS - First Set(Research Set)
SS - Second Set(Reference Set/Base Set)


relationship = f(FS size, FS position)
	possible result: separate, overlap, contain, be contain, equal


**** Dependent equation
Dependent Equation
	Equation which can derived from other one/more Equations

**** equation
To prove some Equation, normally first need to find the connection between these variables, then do format convert to get the Equation.

Linear Equation is Affine Function
	If it have zero y-intercept then it's a Linear Function

**** subjects
Algebra and Number Theory
Applied Mathematics

Calculus - expression of curve & small lines 

Computation
Differential Equations
Discrete Mathematics

Linear Algebra - expression of geometry transform

Mathematical Analysis
Mathematical Logic
Probability and Statistics
Topology and Geometry




**** Base
function
**** 18.01
curve similar to short lines
**** 18.02
surface similar to small plane
**** 18.03
other stuff base on above 2
**** 18.06
vector is bases & coresponding factors

*** EECS
curriculum organized around topics

1. programming paradigms - 6.001 - SICP
2. circuits - 6.002 - Circuits and Electronics
3. signal processing - 6.003 - Signals and Systems
4. architecture - 6.004 - Computation Structures

Above curriculums are compulsory for EECS(4 out of 5, the other is Differential Equations - 18.03). 


now move to curriculum organized around applications:  
let's build and program a robot; let's build and program a cell phone


Refer to: Science_Engineering.txt

Thus CS is closer to the underlying theory of computation, with its roots in mathematics, and CEN is closer to the design of physical devices, with roots in physics and chemistry as well. 

Students with an urge to build things, to measure how things work in the laboratory, those attracted to physics and chemistry as well as mathematics, should seriously consider CEN. Students with an interest in the true nature of symbols, information and their manipulations, the forms and limits of algorithms and data structures, should consider CS. 
Of the three great divisions in computing, namely theory, software and hardware, to a first approximation theory goes with CS, hardware with CEN, and software with both, but mainly with CS. The more general the software, the closer to CS; the more hardware-specific, the closer to CEN. 
Thus a student interested in creating his own new general-purpose computer language would best be served by a CS degree program, while one interested in designing a software interface for a new high speed serial device by the CEN degree program. 

*** computer science
Definition from Boston University:
	Computer Science is the systematic study of the feasibility, structure, expression, and mechanization of the methodical
	processes (or algorithms) that underlie the acquisition, representation, processing, storage, communication of, and
	access to information, whether such information is encoded in bits and bytes in a computer memory or transcribed in
	genes and protein structures in a human cell. The fundamental question underlying all of computing is: what
	computational processes can be efficiently automated and implemented?
	To tackle this seemingly simple question, computer scientists work in many complementary areas. They study the very
	nature of computing to determine which problems are (or are not) computable. They compare various algorithms to
	determine if they provide a correct and efficient solution to a concrete problem. They design programming languages
	to enable the specification and expression of such algorithms. They design, evaluate, and build computer systems that
	can efficiently execute such specifications. And, they apply such algorithms to important application domains. 


Structure
	Computer Science
		Theoretical Computer Science - focuses on more abstract or mathematical aspects of computing
		Theory of Computation
			focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations.
			Category:
				computability theory
				computational complexity theory
		Information and coding theory
		Algorithms and data structures
		Programming language theory
		Formal methods
		...
		

great insights
	There are only two objects that a computer has to deal with in order to represent "anything"
		All the information about any computable problem can be represented using only 0 and 1 (or any other bistable pair that can flip-flop between two easily distinguishable states, such as "on"/"off", "magnetized/de-magnetized", "high-voltage/low-voltage", etc.).
	There are only five actions that a computer has to perform in order to do "anything"
		* move left one location
		* move right one location
		* read symbol at current location
		* print 0 at current location
		* print 1 at current location
	There are only three ways of combining these actions (into more complex ones) that are needed in order for a computer to do "anything"
		sequence:
			first do this; then do that
		selection :
			IF such-and-such is the case,
			THEN do this
			ELSE do that
		repetition:
			WHILE such-and-such is the case DO this
				
		Note:
			can be further simplified with the use of goto

		
*** IT
**** Executor Execute Program in Enveroment
Executor can be [Computer](computer.md) or another [Program](program.md)

Execute:
Also means Evaluate
Evaluate - means simplify
Just perform the explicit & impplicit semantic in language

ExecutionContext
Contains:
	LexicalEnvironment - impl of Lexical Context
	    Environment Record - Records the identifier bindings
	    Possibly null reference to an outer LexicalEnvironment
	VariableEnvironment - Same as LexicalEnviroment, but never changed.
	ThisBinding - for 'this' binding. 
                    cannot find binding when language write, it's base on language invoke enveroment(which object it invoked on)
	ClassLoader - for class name & class object binding 
                    cannot find binding when language write, it's base on language execution enveroment(only for some program like: java)

Category:
	Exclusive ExecutionContext - refered by one Execution
	Shared ExecutionContext - refered by multiple Execution

Name Binding Scope
	Where the Name Binding is valid

	Category
		Lexical Scope(Static Scope)
			lexical context, about program source text
			determined at compile time
			early binding
		Dynamic Scope
			execution context(calling context), about program execution
			determined at run time
			late binding



**** IT System
	The essence of IT System is a Solution to: External Problem (Domain Problem)
	The Solution raise its own problem: Internal Problem (System Problem)
	
	Details:
		Internal Problem can be resolved by another Solution, to this another Solution the Internal Problem is an External Problem
		
		E.g.
			Initial Domain Problem: online money transfer
			Corresponding System Problem: fail-over, cache
			
			Initial Domain Problem: cache
			Corresponding System Problem: distributed data synchronization
			
			Initial Domain Problem: distributed data synchronization
			Corresponding System Problem: io, network
			
			...
		
		So IT System Contains:
			Solution to External Problem: 
				Problem Domain Model Impl
			Solution to Internal Problem: 
				Usage of Problem Domain Model Impl
					Application Model
					View
					...
				Stable of Problem Domain Model Impl
				Performance of Problem Domain Model Impl
				...










**** Program
Expression of Process via Program Language
design goal:
  Less Code More Functionality


Expression - language which can be evaluated
  Value - an Expression which simplify no further
  Non-value Expression
    contains:
      Redex - the part changed in single-step simplication
      Continuation - the part surrounding redex
    Note:
      Most cases Redex & Continuation are lexically adjacent
      But goto, abort, call/cc ... , these Redex & Continuation are NOT
      e.g.
      for code:
      #+BEGIN_SRC scheme
        (begin (println "1")
               (prompt
                (begin (println "2.a")
                       (abort  (println "2.b"))
                       (println "2.c")))
               (println "3"))
      #+END_SRC
      When `(println "2.a")` is Redex, its Continuation is:
      #+BEGIN_SRC scheme
        (begin (prompt
                (begin []
                       (abort  (println "2.b"))
                       (println "2.c")))
               (println "3"))
      #+END_SRC
      When `(abort (println "2.b"))` is Redex, its Continuation is:
      #+BEGIN_SRC scheme
        (begin []
               (println "3"))
      #+END_SRC



Program
	Simply used to express Process
	
	Most Programs Contains 2 Part:
		Instruction Program
		Execution/Inteprete Program
	
	Program is used to resolve Problem via a process of Actions
	     Problem itself have no Size
	     Problem often have a Target (pasted to program as argument)
	     Problem Size here often refer to Target size
	
	Program Execution Type:
		call-by-name
		call-by-need
		
	Normal Computing
		Evaluator have No Control on the Execution Flow, just sequentially
	Nondeterministic Computing
		Evaluator Control the Execution Flow base on Expression Evaluation Result



**** function vs macro
function - language -> domain problem
  so function can NOT control language, e.g. modify itself & other language expression

macro - language -> language -> domain problem
  so macro is NOT controlling domain problem, its controlling language

**** ND Array (Matrix)
It is a recursion

All matrix have dimention: 0 - on which contains itself as whole, ${inner most dimention} - it could be 0 to infinity
So operations should specify which dimention they are on
Most element-wise-operation are on ${inner most dimention}

dimention:
dim-a * dim-b * dim-c * dim-d * 0-dimention element
b as base:
element b contains dim-b * c
element a contains dim-a * b
element b contains dim-b * dim-c * dim-d * 0-dimention element

select b1(c):
b1s: dim-a * b1(c)
0-d elements: dim-a * dim-c * dim-d * 0-dimention element

**** My Naming Conversion

***** Math
Number:
i, j, k - index
n - size
x, y - other number
${upcase} - matrix

Function:
f, g, h - function

***** Other
Sequence:
${thing}s - sequence

Function Name:
${nouns} - pure function name
${verbs} - function name of side effects
Note: if a word both nouns & verbs, default nouns
-fn - function as output


**** programming style
Action Sequence Oriented Programming
  have loop
  clojure related api: doto

Data Change Sequence Oriented Programming(DCSOP)
  no loop
  clojure related api: ->


Note: use `as` to operate argument
#+BEGIN_SRC clojure
  (defmacro as
    "argument operate"
    [expr name form]
    `(let [~name ~expr]
       ~form))
#+END_SRC


**** Process
Process = Logic + Redex & Continuation
Process = Logic + Time(relative)


**** Data and View
A single Data can have multiple View
Multiple Data can have a single View

E.g. (Data -> View)
map -> APersistentMap$KeySeq
vector -> PersistentVector$ChunkedSeq
map -> associative view
vector -> associative view
map + vector + ... -> LazySeq


**** Abstract Semantic over Impl Semantic
Seems this is implemented via Data and View

Abstract Semantic: Sequence corresponding Impl Semantic: LazySeq, Cons, PersistentList, PersistentVector$ChunkedSeq, PersistentArrayMap$Seq, APersistentMap$KeySeq ...
Abstract Semantic: core.matrix/wrapper corresponding Impl Semantic: NDWrapper, PersistentVector

e.g.

first - first element of Abstract Semantic: Sequence

over:

string-first - first element of Impl Semantic: String
cons-first - first element of Impl Semantic: Cons
peresistentlist-first - first element of Impl Semantic: PersistentList
...





**** AI
AI is simulation of 多欲/意识

**** program states
## Steps to create it:

 * Programmer write Program Source Code, which may contains [Problem Specification](problem-specification.md) or/and [Solution Specification](solution-specification.md) via [Programming Language](programming-language.md)
 * If there is Problem Specification in source, [Solution Generator](solution-generator.md) will generate Solution Specification from Problem Specification
 * If Executor recognized format is different from Program Source, [Compiler](compiler.md) convert it to recognized format

## Program State

 * Source
 * Artifact
 * Runtime
 

**** variable
Variable
	A storage location and an associated symbolic name

	Variable maintained in a table, variable name as key, corresponding Data address as value


Function param passing, is copy memory value & store in a new address & pass. 

literal 
	number -> represent by numbers
	string -> represent by quated strings
	
	
E.g.
var a = "test";
var b = a;

**** regex
匹配位置：
	(?=pattern) - 位置之后为pattern
	(?!pattern) - 位置之后为非pattern
	
贪婪/非贪婪：
	？ - 用在（*、+、?、{n}、{n,}、{n,m}）之后表示非贪婪
	
**** register machine
Register Machine
	Contains:
		data paths (registers and operations)
		the controller (sequences these operations)

	The Controller Instructions :
		execute operations
		branch
			conditional branch - branch
			unconditional branch - goto


	To execute Explicit-Control Evaluator
	
	Explicit-Control Evaluator seems like a Controller to execute instructions
		
	Details:
		instruction group in register machine should be reused,  so parameter should be set out side of instruction group.
		
		this parameter include flow change info(continue), as Controller need to control the flow.

		
	base on abstraction
		machine can execute simple process
		machine can combine simple process - not explicitly specified in high language
		
	


**** programing paradigm
Fundamental style of computer programming

Refer to ITSystem.txt

Category
	Imperative
		Source Code specify Problem & Solution
		Hardware execute Solution
	Declarative
		Source Code specify Problem
		Interpreter specify Solution
		Hardware execute Solution

	Note:
		Problem maybe specified in details
		Solution is Action to be taken
		Problem is NOT Action, so there should be no Change here



Declarative Category:
	FP
		specify Problem via math functions
		Note:
			math  function feature:
				independent variable only in function arguments, dependent variable only in function result


**** program language


***** DSL


****** XML

xml schema is a set of xml element used to describe other xml.
xml schema is described by xml schema schema or xml schema dtd. 


一个 XML schema 中 elementFormDefault="？" 这一属性用来指示 XML Schema 处理程序把这个 XML schema 中定义的元素或者类型放到哪个命名空间。

一个schema中声明的元素或者类型只能归到两个命名空间中的某一个去，这两个是，无名命名空间和由targetSchema属性指明的目标命名空间。而targetSchema属性只能在xs：schema的定义中声明，因而，一个schema中的定义的元素或类型只可能归属于一个有名命名空间（但是还有可能归属于无名命名空间）。

当elementFormDefault="qualified" 时，所有全局元素的子元素将被以缺省方式放到目标命名空间，但是全局元素或者类型将被放到目标命名空间；而当elementFormDefault="unqualified" 时，所有全局元素的子元素将被以缺省方式放到无名命名空间。而属性的命名空间类似地由attributeFormDefault="？"来指明。

需要明白的是，elementFormDefault="？" 是有作用域的，并且是被继承的，除非在子定义中覆盖父定义。

下面三个例子说明了elementFormDefault的使用效果。红色表示属于已命名空间的元素，蓝色表示属于未命名空间的元素。

1.定义了目标命名空间， 全局elementFormDefault=“unqualified”。这时除了全局元素或者类型将归于目标命名空间外，局部元素将归于无名命名空间。

unqualified.xsd

<?xml version="1.0" encoding="UTF-8"?>
<xs:schema xmlns:xs="http://www.w3.org/2001/XMLSchema" targetNamespace="aaaa" elementFormDefault="unqualified" attributeFormDefault="unqualified">
 <xs:element name="c">
  <xs:complexType>
   <xs:sequence>
    <xs:element name="c1" type="xs:double"/>
    <xs:element name="c2" type="xs:string"/>
   </xs:sequence>
  </xs:complexType>
 </xs:element>
</xs:schema>

unqualified.xml

<?xml version="1.0" encoding="UTF-8"?>
<n:c xmlns:n="aaaa" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="aaaa unqualified.xsd">
 <c1>3.141593E0</c1>
 <c2>String</c2>
</n:c>

2. 定义了目标命名空间， 全局elementFormDefault=“qualified”。这时全局元素或者类型将归于目标命名空间，局部元素将以缺省方式归于目标命名空间。

qualified.xsd

<?xml version="1.0" encoding="UTF-8"?>
<xs:schema xmlns:xs="http://www.w3.org/2001/XMLSchema" targetNamespace="aaaa" elementFormDefault="qualified" attributeFormDefault="unqualified">
 <xs:element name="c">
  <xs:complexType>
   <xs:sequence>
    <xs:element name="c1" type="xs:double"/>
    <xs:element name="c2" type="xs:string"/>
   </xs:sequence>
  </xs:complexType>
 </xs:element>
</xs:schema>

qualified.xml

<?xml version="1.0" encoding="UTF-8"?>
<c xmlns="aaaa" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="aaaa qualified.xsd">
 <c1>3.141593E0</c1>
 <c2>String</c2>
</c>

3. 定义了目标命名空间， 全局elementFormDefault=“unqualified”。这时全局元素（c）或者类型将归于目标命名空间。局部元素（c1，c2）以缺省方式归于无名命名空间。局部元素（c3）在局部定义中使用form=“qualified”覆盖全局设定的 unqualified，这使得c3归于目标命名空间（如果它有子元素，子元素将以缺省方式归于目标命名空间）。

qualified2.xsd

<?xml version="1.0" encoding="UTF-8"?>
<xs:schema xmlns:xs="http://www.w3.org/2001/XMLSchema" targetNamespace="aaaa" elementFormDefault="unqualified" attributeFormDefault="unqualified">
 <xs:element name="c">
  <xs:complexType>
   <xs:sequence>
    <xs:element name="c1" type="xs:double"/>
    <xs:element name="c2" type="xs:string"/>
    <xs:element name="c3" type="xs:integer" form="qualified"/>
   </xs:sequence>
  </xs:complexType>
 </xs:element>
</xs:schema>


qualified2.xml

<?xml version="1.0" encoding="UTF-8"?>
<n:c xmlns:n="aaaa" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="aaaa qualified2.xsd">
 <c1>3.141593E0</c1>
 <c2>String</c2>
 <n:c3>0</n:c3>
</n:c>


XSD
XSD:
elementFormDefault="unqualified" means defined sub element should be namespace "".

XML:
If no prefix specified, it will use default namespace.
Non-default namespace can not be "".



<xs:element />
	Define an element
	Attributes:
		name - specify element name
		minOccurs - specify element can occur times
		type - specify element contents(attributes & inner elements)


anyType:
	Support GenericProgramming
		Specific type not specified during definition(XSD)
			<xs:element minOccurs="0" name="content" type="xs:anyType"/>
			
		Specific type specified during usage (XML) via xsi:type:
			<content xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:type="ns2:listConvertor">

****** YAML
YAML
	human-friendly data serialization language

	Syntax:
		indentation - scope
		"- " - sequence
		": " - mapping
		"---" - signal start of a document
		"..." - ending of a document

		Optional Flow Style:
			natural extension of JSON
			using explicit indicators rather than indentation to denote scope
			Syntax: [] & {}



****** UML
UML - Unified Modeling Language
    Extension:
        Opt 1, Base on MOF create a new language suppose : UML+,  in UML+ you can introduce new elements
        Opt 2, Create UML Stereotype instance and apply to existing UML element to create a new element
            In RSA, a set of related Stereotypes can group into one Profile

	Diagrams:
		Structure Diagrams:
			Class Diagram, Object Diagram, 
			Component Diagram
				depicts how components are wired together to form larger components and or software systems.
				component:
					autonomous, encapsulated units within a system or subsystem that provide one or more interfaces
					larger design units that represent things that will typically be implemented using replaceable modules
					A single component could be manifested by multiple artifacts, which could be on the same or different nodes, so a single component could indirectly be implemented on multiple nodes.
			Composite Structure Diagram
				shows the internal structure of a class
			Package Diagram
			Deployment Diagram
				models the physical deployment of artifacts on nodes
				artifact:
					a physical unit, such as a file, executable, script, database, etc.
					Only artifacts live on physical nodes; classes and components do not have "location."
		Behavior Diagrams:
			Use Case Diagram (used by some methodologies during requirements gathering); Activity Diagram, and State Machine Diagram
		Interaction Diagrams (all derived from the more general Behavior Diagram):
			Sequence Diagram, Communication Diagram, Timing Diagram, and Interaction Overview Diagram
			
			
	Details:
		ports provide a way to model how a component's provided/required interfaces relate to its internal parts. 
		By using a port, our diagram is able to de-couple the internals of the Store component from external entities. 



****** EMF
EMF = MOF

The Ecore model allows to define different elements.
      EClass : represents a class, with zero or more attributes and zero or more references.
      EAttribute : represents an attribute which has a name and a type.
      EReference : represents one end of an association between two classes. It has flag to indicate if it represent a containment and a reference class to which it points.
      EDataType : represents the type of an attribute, e.g. int, float or java.util.Date


Ecore Struture:
EObject
	EGenericType
	EModelElement
		EAnnotation
		EFactory
		ENamedElement
			EClassifier
				EClass
				EDataType
					EEnum
			EEnumLiteral
			EPackage
			ETypedElement
				EStructuralFeature
					EAttribute
					EReference
				EOperation
				EParameter
			ETypeParameter


****** MOF
4 layers model structure(refer to MOF4Layers.bmp):
    MOF - meta meta model
    UML - meta model
        meta-model is model of model
    UML Instance - model
    System - Real System

****** SAML
SAML
	Security Assertion Markup Language
	Data format for exchanging authentication and authorization data between IDP & SP.

SAML 的 POST/Artifact Bindings 方式（即  SP 拉方式）

       该方式的主要特点是， SP 获得客户端的凭证 ( 是 IDP 对 Subject 的一种身份认可 ) 之后，主动请求 IDP 对 Subject 的凭证的断言。如下图所示： Subject 是根据凭证去访问 SP 的。凭证代表了 Subject 的身份，它类似于“来自 IDP 证明：我就是 Peter ，法国公民”。

现在，让我们看看 SP 拉方式是如何进行的：  

Subject 访问 SP 的受保护资源， SP 发现 Subject 的请求中没有包含任何的授权信息，于是它重定向用户访问 IDP.

       协议执行：

1， Subject 向 IDP 请求凭证 ( 方式是提交用户名 / 密码 )

2， IDP 通过验证 Subject 提供的信息，来确定是否提供凭证给 Subject

3， 假如 Subject 的验证信息正确，他将获取 IDP 的凭证以及将服务请求同时提交给 SP 。

4， SP 接受到 Subject 的凭证，它是提供服务之前必须验证次凭证，于是，它产生了一个 SAML 请求，要求 IDP 对凭证断言

5， 凭证是 IDP 产生的，它当然知道凭证的内容，于是它回应一个 SAML 断言给 SP

6， SP 信任 IDP 的 SAML 断言，它会根据断言结果确定是否为 Subject 提供服务。 







SAML 的 Redirect/POST Bindings 方式  ( 即  IDP 推方式 )

       该方式的主要特点是， IDP 交给 Subject 的不是凭证，而是断言。


       1 ， Subject 访问 SP 的授权服务， SP 重定向 Subject 到 IDP 获取断言。

       2 ， IDP 会要求 Subject 提供能够证明它自己身份的手段 (Password ， X.509 证书等 )

       3 ， Subject 向 IDP 提供了自己的帐号密码。

       4 ， IDP 验证密码之后，会重订向 Subject 到原来的 SP 。

       5 ， SP 校验 IDP 的断言 ( 注意， IDP 会对自己的断言签名， SP 信任 IDP 的证书，因此，通过校验签名，能够确信从 Subject 过来的断言确实来自 IDP 的断言 ) 。

       6 ，如果签名正确， SP 将向 Subject 提供该服务。 



WS-Security is the messaging language; SAML is the security language.  
SAML has already adopted WS-Security as the appropriate method for "binding" SAML assertions into SOAP messages

***** python
Package Management Tool
	setuptools/easy_install
		easy_install is a command from setuptools
			Install:
				sudo yum install python-setuptools
				sudo apt-get install python-setuptools
				
	pip
		Install:
			sudo easy_install pip
		
	python
		python runtime
		
	python-devel/python-dev
		python sdk?
		
		
		
***** lisp family
Lisp language source contains:
content & structure.




So editor operations can sort to 2 categories: content change & structure change.

E.g.
paredit operations sort to:
content change:
insert
delete
structure change:
depth-changing
barfage & slurpage


***** clojure

****** follow Abstract Semantic over Impl Semantic

****** 
## Symbol
Refer to [language](language.md) for Symbol definition
        
### Why clojure need to make Symbol available to program?
Clojure have macro to program on Program Source which is composed of Symbols

## evaluate = evaluate? + resolve symbol? + execute function? + direct value?

evaluate symbol = resolve symbol
evaluate list =
  first element is symbol & in special form table: base on corresponding rule
  first element is symbol & can be reolved to a macro: execute function
  others: evaluate(all sublist) + execute function
evaluate others = direct value

## Semantics will be performed in 3 layers
 * reader macro executor - Read form and execute reader macro to produce: Symbol, Literals(String, Number, Character, nil, Boolean, Keyword), List(2 implementations: Cons for list created from reader macro & PersistList for literals list), Vector, Map, Set
 * normal macro executor - Check Lists from above result, if first element is Symbol & can be resolved to a normal macro, evaluate the list
 * other executor - Evaluate List from above result

Note:
 * reader macro & normal macro is a function with meta: reader-macro, normal-macro
 * evaluate list share same execution context, so that they can refer to each other: 1, macros function refer to above vars. 2, executor can create macro definition
 * process is form by form, so that macros can refer to above vars
 * here executor means clojure runtime which accept clj code not java bytes, which means executor(clojure runtime) will translate clj code to java bytes.



## Runtime Structure
    Namespace Repo
        Namespace
            Symbol -> Var -> Value
                   -> Java Class
    Thread
        reference to namespace repo
        indicator of target namespace

Note:  
Symbol's Semantic is the Symbol's corresponding Value

Var:
Var added only to support interactive development(change symbol binding on runtime)
Symbol -> Var -> Value
              -> Metadata
Var by default bind to: object[clojure.lang.Var$Unbound 0x2ad20528 "Unbound: #'${var's symbol}"]  
Var can be invoked, which internally invoke it's corresponding Value  
Var created via: defXXX, declare, intern

Value is immutable Data. Even record, which compiled to java object, is Value  

All code executed in thread, below is code and corresponding impact:
 * create/remove namespace -> namespace repo
 * def* -> namespace
 * switch namespace -> indicator of target namespace

## API shape
    CONVERTERS:
        map
            mapcat
            keep-* - fiter answer piece
        replace

    FILTERS:
        filter
        remove
        take-*
        drop-*
        distinct
        dedupe

    OTHER:
        partition-*
        interpose
        interleave
        
    OPERATION THREADER:
        doto - target go through all operations also implicit return
        ->, ->> - target to result to target to result...
        juxt - target go through mutiple relation to get multiple result
        
        
## Collection

### Sequence Abstraction
A view of data, must rely on concrete collection data type
some data's view is it's self e.g. pair & list
coll? = true
normally no additional space required
All collections, include non-sequential(seq? = false), can have a sequence view.
Implementations can be: LazySeq, Cons, PersistentList, PersistentVector$ChunkedSeq, PersistentArrayMap$Seq, APersistentMap$KeySeq ...
Support: cons, car(first), cdr(rest)  
The base of: filter, map, for, doseq, take, partition …  
All collections provide Sequence abstraction to navigate its content  
Sequence abstraction can be exposed via seq  
e.g.  

    (class '(1 2)) ;; clojure.lang.PersistentList
    (class (seq '(1 2))) ;; clojure.lang.PersistentList
    
    (class [1 2]) ;; clojure.lang.PersistentVector
    (class (seq [1 2])) ;; clojure.lang.PersistentVector$ChunkedSeq
    
    (class {1 2}) ;; clojure.lang.PersistentArrayMap
    (class (seq {1 2})) ;; clojure.lang.PersistentArrayMap$Seq

    (class #{1 2}) ;; clojure.lang.PersistentHashSet
    (class (seq #{1 2})) ;; clojure.lang.APersistentMap$KeySeq


### Concrete Collection Data Type:
sequential(seq? = true):
 * pair - this not in official document but I think it's prominent to highlight here
          in clojure it's second element need to be a sequence view
          implementation: Cons, created by: cons
          pair can also be used to impl list, but this list is not counted?
 * list
 * vector

non-sequential:
 * map
 * set



--------------------------------------------------------------------

Syntax
	Expression evaluate rule:
		List evaluate to call
			list is s-expressions, refer to: s-expression.txt
			form: valid s-expression & can be successfully evaluated
			call syntax is consistent than most other language
		Symbol evaluate to named value
		Other evaluate to literal value


	Reader:
		Scalar Literal - reader syntax for noncollection values
			String Boolean nil Character
			“named” value:
				Keyword - identifier, evaluate to themselves
				Symbol - identifier, evaluate to values in the Clojure runtime they name
					values include:
						those held by vars (which are named storage locations used to hold functions and other values)
						Java classes
						local references
						and so on
					e.g.
						(average [1 2 3])
							average - Symbol, refer to function held in var named average
			Number Regular expression
		Comments
		Whitespace and Comma
		Collection Literal
		Reader Sugar


	Namespace:
		Clojure’s fundamental unit of code modularity.
		Fundamentally, they are dynamic mappings between symbols and either vars or imported Java classes.
		Outside of identifying locals, the semantics of symbol evaluation are tied up with namespaces.
		One of Clojure’s reference types,15 vars are mutable storage locations that can hold any value. Within the namespace where they are defined, vars are associated with a symbol that other code can use to look up the var, and therefore the value it holds.


	special form
		Clojure’s primitive building blocks of computation, on top of which all the rest of Clojure is built.
		defined a limited set of primitives that define the fundamental operations of the runtime, and are taken as sufficient to describe any possible computation.
		everything that isn’t a special form is implemented in Clojure itself by bootstrapping from that limited set of primitive operations.

		details:
			quote
				symbols evaluate to themselves
			do
			def
			let
				support destruturing
				is a syntactic sugar
					(let [x 8] ( ... )) = ((fn [x] ( ... )) 8)
			fn
				support destructuring due to internal use of let
			if
				refinements base on if: when cond if-let when-let
			loop & recur
				NOTE: these 2 form are statements(imperative)
				refinements base on recur: doseq dotimes
				recur transfers control to the local-most loop head without consuming stack space
				loop head: loop or function
			var
				NOTE: symbol name a var not evaluate to var itself but var's value
				(def x 5) & (var x) will evaluate to var itself
			java interop: . and new
			set!
			primitive locking: monitor-enter monitor-exist

			NOT SURE FOLLOWING FORM ARE SPECIAL FORM:
				delay future
				Answer: They are macros


Important Data Type(Collection, Reference, Dataflow) & Corresponding Operation Functions
	Small(Only 7) & Wildly supported Data Structure Abstraction
		Here abstraction is semantic abstraction, it can be implemented by multiple interfaces/class
			E.g.
				Seqable can be implemented by interface/class:
					clojure.lang.Seqable, java.util.*, java.lang.CharSequences, java.lang.Iterable, Arrays, nil

		Collection
			all clojure data structure participate
			Core Functions:
				conj, seq, count, empty, =
			Helper(Auxiliary) Functions:
				into

		Sequence
			As clojure data is persistent, change on data return the same type.
			So function result is sequence, means the changed data is sequence.

			Sequence Function - all functions operate on sequence whatever this sequence is from argument or calculated

			Core Functions:
				first, rest, next
			Helper Functions:
				filter, map, for


			lazy-seq will return a function with arguments as function body
				this returned function will be evaluated when access to seq elements
				this returned function will be evaluated to a normal sequence with second element a lazy-seq
			structure:
				(lazy-seq returned function
					(cons element lazy-seq returned function))
			lazy implementation:
				base on function's contain data ability (refer to Turing.txt)

		Associative
		Indexed
		Stack
		Set
		Sorted


	Data Structure Types
		List Vector Set Map


	Immutability and Persistence
		Persistence and Structure Sharing
			Persistent - reuse internal structure(normally it's about collection)
		Transient
			Once you use any of these functions on a transient collection, that collection should never be touched again—even for read-only purposes.
			Transients are intended to be used just like their persistent counterparts, with the additional restriction that prior revisions of a transient must not be used again.
			You still have to be sure that the linear use of transients is respected (that is, once modified, a transient is never used again)

			Mutable Data:
				delay object, future object, promise object(dataflow variable), reference type(var ref agent atom)

	Metadata

	Putting Clojure’s Collections to Work
		Navigate Update and Zipper


	Shifting Computation Through Time and Space
		delay future promise - control when and how computation are performed


	Parallelism on the Cheap
		pmap pcall pvalue


	State and Identity
	Clojure Reference Type
		var ref agent atom
	Classifying Concurrent Operation
	atom
		swap! - compare-and-set, if change found retry the compare-and-set base on new value
          similar to: lock, read, calculate, update, unlock
          but atom swap:
            update function: read, calculate,
            swap internally: lock, read, compare, may update, unlock

	ref
		STM
			dosync establishes the scope of a transaction.19 All modifications of refs must occur within a transaction
		in-transaction value
			value in the Clonable Exclusive ExecutionContext
			value when txn started
		alter
		commute
			will be evaluated twice, but first one will returned as the expression result
		The Sharp Corners of Software Transactional Memory
			live lock, the STM equivalent to a deadlock
			inside a transaction dereferencing a ref may trigger a transaction retry! This is because, if a new value is committed by another transaction since the beginning of the current transaction, the value of the ref as of the start of the transaction cannot be provided.
			history
				**Clojure's STM does not care about the present. By the time an observation is made, the present has already moved. Clojure's STM only cares about capturing a consistent snapshot of state.
				**We should not give sematic to time difference between 2 line code execution, as we should not care about execution impl(detailed information like: how, when) and even the execution is not controllable
				used to maintain the ref change history, used to impl isolated execution context
			write skew
				If the read ref’s state happens to change mid-transaction, that transaction’s effects on other refs may end up being inconsistent with the read ref; this state of affairs is called write skew.
				NOTE: this is due to that 2 var value at give time is not checked when no update in txn (if update there 2 var value at same time check will be performed on commit).
					2 var value itself is an inconsistent, also their derived value are inconsistent.


	Var
		top level functions and values are all stored in vars
		constant value
			reference to constant value is captured inside the function at compile-time.
			Any later modifications to constant var will have no effect upon the semantics of the function, unless the function redefined
		Dynamic Scope
			overwrite the lexical value, apply to thread-local
			Dynamic scope propagate binding conveyance, supported by agents, futures, pmap
				but not support lazy sequence, as lazy sequence's create thread & realize thread may different.
		Vars Are Not Variables
			def always defines top level vars
			it is not an assignment operation affecting some local scope
		Forward Declarations
			declare a place holder and will define its value later


	Agents
		agent action - functions to change its value
			agent actions are serialized
		send - use fixed thread pool to execute the agents
			so it should not used to queue io actions or other non-CPU-bound agent action
		send-off - use unbounded thread pool to execute the agents
		I/O, Transactions, and Nested Sends
			agent action is same in transaction(may retry), since it will put to agent queue only when submit successfully
			normally agent contains an object, agent action normally perform some state change on the value, return same object to avoid agent value change



Create New Language Syntax & Expression Problem Solution
	Protocol and Datatype
		Dynamic Expression Problem(Refer to Language:Expression Problem)
			goal:
				1, create new types implementing existing interfaces, without recompiling existing code
				2, implement of a new interface for an existing type, without recompiling existing code

	Multimethod
		Used to implement polymorphic dispatch base on things other than argument type
		Like Protocol, multi serve to external as proxy of methods



Organizing & Building
	Functional Organization
		in-ns, refer, require, use, import, ns
	Physical Organization
		Leiningen Style
		Maven Style

	Building
		default build with NO AOT compilation


JVM Interop
	Type hint may speed up 20x
	Type Hint on:
		Symbol - Indicate type of Symbol's Referent's value
		Parameter Vector - Indicate type of Function return value

	gen-class create a proxy class, its method will delegate to normal clojure function

	clojure.lang.RT is the start point for java to access clojure



***** clojurescript
 will require the clj file which may have macro definition, which will be defined in normal macro executor env.

other executor env are different from reader macro executor & normal macro executor env.
So reader macro & normal macro are written in clj not cljs.

Note: if you put "defmacro" in cljs file, it will be executed in normal macro executor, as defmacro itself is a macro, and in other executor finally compiled to a js function.

js global objects are in cljs's js ns


access property : aget, java interop: .(call) & new(construct call),  .-???(sugar)
-??? seems is the getter function for the perperty, but actually it's suger for special form .
a proerpty have 2 methods (getter & setter), I hope +??? can be the setter
js/xx.xx.xx - this is no idiomatic for clojure, I strongly recommend to avoid it.
dotted symbols mapped to java class in clj, but there is no java class in cljs, so dotted symbols also mapped to vars, and seems a lot of vars created for all nested properties. I don't like this as I didn't def these symbols but they are created without my notation.



cljs value to js value: clj->js
  set/vector/list -> Array
  map -> Object
  keyword/symbol -> String


js value to cljs value: js->clj
  Array -> vector
  Object -> map


create plain js Object: js-obj - js Object
			array/make-arry - js Array
                        #js(reader)
  Note: In cljs context, you actually can only reach cljs value. Js value can only derived(converted) from cljs value.
        So these are only syntax surger, implemented via cljs->js. 
    js-obj convert args vector to js Object
    array convert args vector to js Array


Consuming JS code:
GCL lib: same as cljs lib
plain lib:
if no optimization: normal include in html & directly assess js/globalName
if optimization: externs.js need to be provided in build


build to bundle together:
GCL lib: register in build :libs
plain lib: register in build :foreign-libs/:provides(provide fake namespace file mapping info) & require in cljs file(require fake namespace to perform bundle)


package plain js to jar:
src/deps.cljs
sr/**


Note: give plain js a fake namespace via register in  :foreign-lib, so that plain js can be located automatically.
better to put :foreign-libs, :externs in src folder, so that it can be used both by compiler & runtime.
I don't know why require will generate incorrect: "good.addDepency("xx.js", [] [])" (empty provide & require)
This means any required namespace need to be referenced by the compiled cljs during compile time to generate correct deps.js

JavaScript Modules (alpha)
:foreign-libs/:file can specify a folder & :provides will base on directory structure.



***** chicken

all .c generated from scheme code except runtime.c

I don't know why need to handcode chicken.h while checken.c is generate from chicken.scm
don't konw why build process create chicken-config.h


build-version.c
buildtag.h

Above files are chicken runtime


basic library:
library.c
eval.c
expand.c
modules.c
extras.c - ? don't know whether needed, if this included it will cause error


Don't konw what is chicken-syntax.c, but it's required by gcc -static

When gcc -static to build independt programe, only .c is used

E.g.
gcc -static -Os -fomit-frame-pointer -DHAVE_CHICKEN_CONFIG_H runtime.c chicken-syntax.c build-version.c library.c eval.c expand.c modules.c simple-hello.c -o simple-hello  -lm

gcc -static -Os -fomit-frame-pointer -DHAVE_CHICKEN_CONFIG_H runtime.c chicken-syntax.c build-version.c library.c eval.c expand.c modules.c bar.c foo.c -o foo-full  -lm




debug:
software install(provide bin:wish, witch used by feathers witch is a buit-in debugger server):
sudo apt install tk

start up debugger server(default port is 9999, which I don't feel good):
feathers -port 9922

compile with debug info:
csc -d3 bar.scm foo.scm -o foo

env variable:
export CHICKEN_DEBUGGER=localhost:9922

run program (e.g.):
./foo


I found a issue in official doc: can't directly pass programe to the feather command

***** guile
Scheme implementation,  compile to run on a VM.
The compiler can also compile Emacs Lisp & ECMAScript to run on it's VM
Also support GOOPS(OO)

***** racket
a fake scheme. 
it's more like common lisp which provide a lot of features e.g. object, contract, module, unit ... , but the most prominent is that it provide read macro(convert any code to list) & module(customize init enviroment) to create arbitrory language.
weakness:
  for/list rely on temp value
  NOT fllow explict-over-implict:
    e.g.
    custodian, contract
  NOT follow Abstract Semantic over Impl Semantic:
    e.g. 
    = & char=? 
    append & string-append
    string-ref & list-ref & vector-ref & hash-ref
    mcar & car, mcdr & cdr, mcons & cons
    *-set!



( & [ are interchangable


definition
expression:
function application
conditionals: if, and, or, cond

list primitives:
empty, first, rest, cons

number:
exact
inexac

character corresponds to a unicode scalar value

value binding
transformer binding

function call - for function
procedure application - for syntax transformer (e.g. if, define)

by-position argument
keyword argument

keyword is not expression

and, or is syntactic form not a function

datum - anything that read function parse as a single element
can be: symbol, literal(boolean, number, string, character, keyword), list, pair, vector, hash table, box

parameterize install a value to parameter

parameter vs set!
scoped in current thread, each thread have it's own copy of value
auto reset

mechanism to create new data type:
struct, class

require collection module, search installed collections, not the relative path to current file

package - a set of libs 

programe don't refer to pkg directly

one pkg can supply multiple libs in multiple collection

project module -> collection module
just copy files to collection search path
or make a pkg:
raco pkg install --link /home/shark/folder-contains-file


module
#lang shorthand for module
not work in repl as: 
#lang must be terminated by EOF
#lang expansion depends on the file name

f: any -> boolean, regular expression, function contruct, values can be a contruct checker

function contruct: (-> xx xx)


port - source or sink of data

print - expression layer
write - reader layer
display - character layer

exception apis are implemented via prompt & abort

delimited continuation - partial continuation, continuation frame, continuation up to a delimiter(prompt), invoke it will preppend target continuation to current continuation
undelimited continuation - whole continuation, invoke it will change current continuation to target continuation


macro can define new syntax, but:
can NOT restrict syntax available in a context
extend of syntax within the parameters of the language's lexical convention(parentheses around macro name)

module initial import is module language

implicit stuff:
#%module-begin - wrap the module body. e.g. (println 1) (println 2) -> (#%module-begin (println 1) (println 2))
#%app - wrap function call. e.g. (+ 1 2) -> (#%app + 1 2)
#%datum - wrap literals. e.g. 10 -> (#%datum 10)
#%top - ?





***** c
Build Stages: 	
	Source code → Preprocessor → Compiler → Assembler → Object code → Linker → Executables.
		Preprocessor: Include headers. Ex: stdio.h. Command: gcc -E
		Compiler: Check grammar, translate to assembly language。Command: gcc -S
		Assembler: Translate assembly language to bytes. Command: gcc -C
		Linker: Link the function definition with the impl, because there is no impl for those functions defined in included header. Command: gcc (ldd can used to check the linked lib)
			Ex: System will link it to /usr/lib/libc.so.6 for impl of func "printf" .
			It contains Static link & Dynamic link. 
				Static link: Put all lib executable code to the generated result. 
				Dynamic link: Only reference of the lib executable code will put to the generated result. 


GCC:
	GNU Compiler Collection
	GNU C Compiler
	A compiler. To compile advanced programme lauguage to executable bytes. 

编译器
	Translate Advanced Language to Manchine Language(bytes). 	

C, C++
	Only a programme language. Need GCC to compile to manchine executable bytes. 

VC
	Virtual C
	A compiler


***** css
Pixel
	2 Categories:
		CSS Pixel
		Hardware Pixel
	
	Normally, CSS Pixel should equals to Hardware Pixel. But in some browser, browser itself will rescale hardware Pixels base on CSS pixels

Shadow:
	{box-shadow:阴影类型 X轴位移 Y轴位移 阴影大小 阴影扩展 阴影颜色}
	Ex: box-shadow: 5px 5px 5px #888;


Pseudo element:
	${element selector}:before
        before the inner content of the selected element
        E.g.
            .g-bs2-bg:before {
            	content: '';
            	background: url(../images/bs-docs-masthead-pattern.png) repeat center center;
            	position: absolute;
            	top: 0;
            	right: 0;
            	bottom: 0;
            	left: 0;
            }


CSS3 animate attributes:
	transition
		Support animation(let an element gradually change from one style to another)
		grammar:
			transition: property duration timing-function delay;

	transform
	animation


CSS internal URL rebase(usually used for optimize):
	original base = original CSS path
	new base = optimized CSS path


Position:
	static - normal, located base on node position.
    relative - Move to other place, original occupied space still there
    absolute, fix - Move to other place, original occupied space not there any more.


Flex:
	Support flexi layout, new feature in CSS3
    	E.g.
    		<div id="content" style="display:flex">
    			<div id="left-sidebar" style="flex:1"></div>
    			<div id="main-content" style="flex:2"></div>
    			<div id="right-sidebar" style="flex:1"></div>
    		</div>


Block & Inline:
	block element - container element, engage full line, size can controlled
    	e.g.
    		DIV, FORM, TABLE, P, PRE, H1~H6, DL, OL, UL

    inline element - basic element, inside a line, size can not controlled
    	e.g.
    		SPAN, A, STRONG, EM, LABEL, INPUT, SELECT, TEXTAREA, IMG, BR


Align:
	text-align - apply to block element, control corresponding inline element's align.
    vertical-align - apply to inline element, control it's vertical position in the line.

    align - deprecated, pls use text-align


Overlay:
	To create Overlay, we need to put an element out of the normal html flow. This can be achieved va position:relative, absolute, fix.

***** dart
Google Program Language for structured web app engineering
	???
		Variable lookup logic:
			if there is a ThisBinding, look in it first
				object members should in ThisBinding
			look in LexicalEnvironment

	Everything you can place in a variable is an object, and every object is an instance of a class. Even numbers, functions, and null are objects. All objects inherit from the Object class.

	Uninitialized variables have an initial value of null

	dynamic vs var
	    dynamic is a type
	    var just like final is a mutabilitySpecifier

	    variable declaration convention:
	        mutabilitySpeciifer type variableName
	            here mutabilitySpeciifer or type can be omitted


	dart file - an implementation of library (constituent part of library)
		compare to normal class it can additionally accommodate class(special member)

	import - A command. Used to import library, accecpt URI as parameter
	    Every DartApp(a file that has a top-level main() function) is a library, even if it doesn’t use a library directive
	import 'dart:html' - import library's all variables into execution context
	import 'dart:html' as xxx - import library's all variables into object xxx
	dart:xxx - Dart embeded lib(start with 'dart:'). Already inside DartVM, DartVM no need to load from external. U can find the source in SDK/lib. 
	package:xxx/xx.dart - External lib(start with 'package:'). DartVM will try to load them from path: packages/xxx/xx.dart	
	
	web_ui
		1, Seprate Static Content outof Dyna Content via dwc
				Static Content maintained in generated html
				Dyna Content maintained in generated dart
		2, Load Static Content & Dyna Content to seprate DOM in runtime
		3, Merge Dyna DOM to Static DOM

	dart2js - only need to convert the main dart app(directly included via script tag)
	observable 
		@observable - customize getter & setter to notify registed observers
		Template.oneWayBind - register observer to observe observables

	customize tag - A html template & a sub-class of WebComponent. web_ui will merge the html template to the sub-class. 
	
	dart.js
		Start DartVM & Run Dart Programs
		If browser don't support DartVM, change script src from ${*.dart} to ${*.dart.js}
		
	interop.js
		Component in js side to open communicate channel with Dart
	
	
	constructor
		If you don’t declare a constructor, a default constructor is provided for you. The default constructor has no arguments and invokes the no-argument constructor in the superclass
		By default, a constructor in a subclass calls the superclass’s unnamed, no-argument constructor
		Specify the superclass constructor after a colon (:), just before the constructor body. 	E.g. Employee.fromJson(Map data) : super.fromJson(data) {...}
	
	
	factory constructor - constructor with keyword "factory" & have no access to "this"
		factory constructor might return an instance from a cache, or it might return an instance of a subtype


	implements
		A class can implements another class
		
		
	Generic type
		Type as special parameter via <>, which noramlly will be passed during initialize
		E.g. 
			abstract class Cache<T> {
			  T getByKey(String key);
			  setByKey(String key, T value);
			}
			
			
	library
		declare library
		
	
	part
		add implementation file to current library
	
	
	part of
		specify library name which included this implementation
		
		
	export
	    expose 3rd part library contents via current library
		
		
	typedef
		define function type(formatter/signiture)

		
	metadata/annotation - give meta info about code via @
		you’ll be able to retrieve metadata at runtime using reflection
		annotation definition is same as class
		
	Class Method (Static Method)
		Methods cannot operate on an instance(no access to "this")
			Factory Constructor should also matrix under this category, as it also can not operate on an instance(no access "this")
	
	Instance Method
		Methods can operate on an instance(have access to "this")
	
BUGs:
	web_ui template generate for {{xxxxxx}}:
		Target replace node index is base on origin file. But generated output will remove app dart import & insert new one at the end, so it will cause incorrect index.
		
		

dart package - in pub is a directory contains pubspec.yaml & other stuffs
	2 kinds of pkgs:
		lib package
		app package
	
layout convention:
	gplatform/
	  pubspec.yaml
	  pubspec.lock *
	  README.md
	  LICENSE
	  benchmark/
		make_lunch.dart
		packages/ **
	  bin/
		gplatform.dart
		packages/ **
	  doc/
		getting_started.md
	  example/
		lunch.dart
		packages/ **
	  lib/
		gplatform.dart
		src/
		  beans.dart
		  queso.dart
	  packages/ **
	  test/
		gplatform_test.dart
		tortilla_test.dart
		packages/ **
	  tool/
		generate_docs.dart
	  web/
		gplatform.html
		gplatform.dart
		gplatform.css
	

marvn plugin
1, Find pubspec.yaml & run "pub install" to install dependency to packages folder.
2, If web folder available in same folder as pubspec.yaml, copy packages to web folder also.
3, If dart file available under web folder, compile to js


lib
Future
    Just like Q.js
    Used to obtain not yet available Value or Error.
    Completer will create & link to Future then provide Value/Error to it.

    Future Future.then()
        new Completer will provide below(return if available) to returned new Future:
            1, current Future's Handler's Value or Error
                Here Handler refer to last executed Handler(Error Handler will triggered if exception in Success Handler)
            2, current Future's Value or Error

	Refer to Promise/Promise.txt


dart editor
DartEditor Data:
	C:\Users\Administrator\dart\
	C:\Users\Administrator\DartEditor\


***** haskell
Haskell is a purely functional programming language
	main = putStrLn "Hello World!"
	
	The trick is that main evaluates not to a simple value but to an action. The runtime then executes this action.
	
	So the program itself has no side effects, but the action does. 
	
	And this so called IO action is invoked after the Haskell program has run, so we don't break the functional nature of the program. At least that's the conceptual model -- things are a little more complicated because of Haskell's laziness (see later).
	
	
	
	
	
	Does main have to produce an IO action? Yes, it's part of the contract. But just for some cheap 
	
	
	like putStrLn or print, which return IO actions. 
	
	
	 you can also trivially convert any value into an IO action using return.
	
	
	However you can never execute an IO action inside the program -- there just isn't a function that can do it. Once created, an IO action keeps percolating up until it ends up in main and is executed by the runtime. (You can also discard an IO action, but that means it will never be evaluated.)
	
	There are several reasons why an expression would have to be evaluated -- the fundamental one being that somebody wants to display its result. So, really, without I/O nothing would ever be evaluated in Haskell.
	
	Haskell has special syntax for sequencing. It's called the do notation. 
	
	
	    str <- getLine
	
	
	creates an action that, when executed will take the input from the user
	
	
	In Haskell you never assign to a variable, instead you bind a name to a value. 
	
	When the action produced by the do block is executed, it binds the name str to the value returned by executing the action that was produced by getLine.
	
	do blocks are used for sequencing a more general set of monadic operations. IO is just one example of a monad
	
	The way the actions are glued together is the essence of the Monad. Since the glueing happens between the lines, the Monad is sometimes described as an "overloading of the semicolon." Different monads overload it differently.
	
	
	The runtime calls main, which produces a monadic action.
	This monadic action, when given the Universe as input, produces a new modified Universe.
	
	This function must evaluate to an IO monadic object. 
	
	Monad that is about actions, is not the eternal Monad.
	
	The do block glues together these actions in such a way that the Universe produced by one action becomes the input to the next action.
	
	The double colon is used to introduce a type signature.
	

	
--------------------------------------------------------------------------------------------------------------


	
	If you say that a is 5, you can't say it's something else later because you just said it was 5.
	
	
	think of programs as a series of transformations on data.

	in Haskell every expression and function must return something. 
	
	if statement in Haskell is that it is an expression.
	
	An expression is basically a piece of code that returns a value.
	
	Speaking of characters, strings are just lists of characters. "hello" is just syntactic sugar for ['h','e','l','l','o']
	
	[1,2,3] is actually just syntactic sugar for 1:2:3:[]. [] is an empty list. 
	
	List comprehensions are very similar to set comprehensions.
		[x*2 | x <- [1..10], x*2 >= 12]  
		
	tuples are like lists — they are a way to store several values into a single value. 
	
	:: is read as "has type of"
	
	Functions that have type variables are called polymorphic functions. 
		E.g. fst :: (a, b) -> a  
			a and b are different type variables
	
	Everything before the => symbol is called a class constraint
	
	Type annotations are a way of explicitly saying what the type of an expression should be. We do that by adding :: at the end of the expression and then specifying a type. 
	
	The _ means the same thing as it does in list comprehensions. It means that we really don't care what that part is, so we just write a _.
		E.g. third (_, _, z) = z  
		
	You can match with the empty list []
		
	A pattern like x:y:z will bind the head of the list to x, second of the list to y, and the rest(list) of it to z
	
	[1,2,3] is just syntactic sugar for 1:2:3:[]
	
	guards are a way of testing whether some property of a value (or several of them) are true or false.
	
	pattern match check if the input satisfies a pattern but guards check for boolean conditions
	
	 Let bindings let you bind to variables anywhere and are expressions themselves, but are very local, so they don't span across guards. 
	 	E.g.
	 		let 
				sideArea = 2 * pi * r * h
				topArea = pi * r ^ 2
			in
				sideArea + 2 * topArea
	 
	 
	 The difference is that let bindings are expressions themselves. where bindings are just syntactic constructs. Remember when we did the if statement and it was explained that an if else statement is an expression and you can cram it in almost anywhere?
	 	where bindings impact across multiple guards, so it's not expression
	 
	 We omitted the in part of the let binding when we used them in list comprehensions because the visibility of the names is already predefined there. 
	 
	 we could use a let in binding in a predicate and the names defined would only be visible to that predicate
	 
	 The in part can also be omitted when defining functions and constants directly in GHCi. If we do that, then the names will be visible throughout the entire interactive session.
	 
	 case expressions are, well, expressions, much like if else expressions and let bindings. 
	 
	 pattern matching on parameters in function definitions! Well, that's actually just syntactic sugar for case expressions. 
	 	Syntactic Sugar:
		 	head' :: [a] -> a  
			head' [] = error "No head for empty lists!"  
			head' (x:_) = x  
	 	Actually Means:
	 		head' :: [a] -> a  
			head' xs = case xs of [] -> error "No head for empty lists!"  
			                      (x:_) -> x  
	 
	 	 
	 case expression:
		 case Expression of Pattern -> result  
	                   Pattern -> result  
	                   Pattern -> result  
	                   ...  
	 
	 	Note: Pattern is another Expression which evaluate same value as Expression
	 
	 Recursion is actually a way of defining functions in which the function is applied inside its own definition.
	 
	 
	 Quicksort has become a sort of poster child for Haskell. 
	 
	 Haskell is lazy, so it will access the list element one by one, not care about/aware the list elements not yet accessed.
	 	List Elements are on fly generated, when be accessed
	 	Haskell only access List Element, never the whole List	 	
	 	So expression: length [1..] will hang there
	 	
	 	
	 
	 A fold takes a binary function, a starting value (I like to call it the accumulator) and a list to fold up. 
	 	The binary function itself takes two parameters. 
	 	The binary function is called with the accumulator and the first (or last) element and produces a new accumulator. 
	 	Then, the binary function is called again with the new accumulator and the now new first (or last) element, and so on. 
	 	
	 	Apply f on every element of list with previous result as additional input
	 	The accumulator is the result of the application on sub-list
	 	
	 
	 ($) :: (a -> b) -> a -> b  
	 f $ x = f x  
	 
	 $ has the lowest precedence of any operator
	 	So:
	 		f (g + z) equals f $ g + z
	 $ is right-associative
	 	right side $ will be executed first
	 	So:
	 		f (g (z)) equals f $ g z also f $ g $ z
	 
	 
	Function composition
	 	(.) :: (b -> c) -> (a -> b) -> a -> c  
		f . g = \x -> f (g x)  
		
		Function composition is right-associative
		
		Why:
			making functions on the fly
				can use lambdas for that, but many times, function composition is clearer and more concise
	 
	 
	point free style: 
		sum' = foldl (+) 0 is called writing it in point free style
		
		it makes you think about functions and what kind of functions composing them
		in instead of thinking about data and how it's shuffled around
		
	
	 	
	 	
	 f 1 2 = f 1 y then f 1 2 ???
	 
	 
	On:
		on :: (b -> b -> c) -> (a -> b) -> a -> a -> c  
		f `on` g = \x y -> f (g x) (g y)
		
		Similar to Function composition
		"." - left side func apply on 1 result of right side func
		on - left side func apply on 2 result of right side func

	 
	The part before the = denotes the type, which is Bool. The parts after the = are value constructors. 
	 
	 
	FP is modular in the dimension of functionality, where ObjectOrientedProgramming is modular in the dimension of different components.
	
	If fact, invoking the same method over and over again may produce different results and may alter the outside world in different ways. None of this information, however, is conveyed by the signature of the method. Most languages leave it up to the programmer to document these side effects in one way or another.
	
	
	Consider global variables, for a very long time now they have been the black sheep of the family, and for good reason. But what really makes global variables different than instance variables? Sure, instance variables have a much smaller scope, but in the context of all the code that makes up a single class don’t they essentially cause the same problems? Have you ever written a method that failed because some other method accidentally screwed up the value of an instance variable?
	
	The a here is the type parameter. And because there's a type parameter involved, we call Maybe a type constructor. 
	
	parameterizing the Car type isn't really worth it.
	
	
	it's very important to distinguish between the type constructor and the value constructor. When declaring a data type, the part before the = is the type constructor and the constructors after it (possibly separated by |'s) are value constructors. 
	
	the Int type is an instance of the Eq typeclass
	
	classes are a blueprint from which we then create objects that contain state and can do some actions. 
	
	Typeclasses are more like interfaces. We don't make data from typeclasses. Instead, we first make our data type and then we think about what it can act like. 
	
	
	make our types instances of typeclasses by implementing the functions defined by the typeclasses.
	
	values can only have types that are concrete types!
	
	Maybe is a type constructor. When I apply an extra type to Maybe, like Maybe String, then I have a concrete type. 
	
	Just like we can partially apply functions to get new functions, we can partially apply type parameters and get new type constructors from them. 
	
	we can make types whose constructors have fields that are of the same type! Using that, we can create recursive data types, where one value of some type contains values of that type, which in turn contain more values of the same type and so on.
	
	like 3:4:5:6:[] (because : is right-associative)
	
	infixr 5 :-:  
	
	pattern matching is actually about matching constructors
	
	
	all values created from value constructor
	
	types created from type constructor
		 
	constructor is implemented via function
	
	data type specify a set of data created via specific constructors



	data ${type constructor} = ${value constructor}

    typeclass -> type -> value

    typeclass created from typeclass constructor

    class Eq a where
         declare typeclass
         a is type variable, variable refer to Eq instance


    instance is for making our types instances of typeclasses.

    instance Eq TraficLight where
        create typeclass instance

    a & TraficLight are both parameters?
		Types are little labels that values carry so that we can reason about the values.
		types have their own little labels, called kinds. A kind is more or less the type of a type.


    Constructor is a function generated automatically

    Types that can act like a box can be functors.

    We used :k on a type to get its kind, just like we can use :t on a value to get its type.


    main = do
        putStrLn "Hello, what's your name?"
        name <- getLine
        putStrLn ("Hey " ++ name ++ ", you rock!")


	Once it's fetched that data for you, the only way to open the box and get the data inside it is to use the <- construct. And if we're taking data out of an I/O action, we can only take it out when we're inside another I/O action. This is how Haskell manages to neatly separate the pure and impure parts of our code.

	IO ()
		A value type

	do - glue multiple actions into one

	return is a function not keyword
	the return in Haskell is really nothing like the return in most other languages!
	In Haskell (in I/O actions specifically), it makes an I/O action out of a pure value.

	when is a normal function. It takes a boolean value and an I/O action if that boolean value is True, it returns the same I/O action that we supplied to it. However, if it's False, it returns the return (),

	
	Well, when we evaluate an I/O action in GHCI, it's performed and then its result is printed out, unless that result is (), in which case it's not printed out. 
	
	string list is lazy, the buffer size is 1 element, one element can have one char
	lazy bytestring buffer size is 64k element, one element can have one ascii char
	
	Reverse Polish notation(RPN) is another way of writing down mathematical expressions
	
	think of a stack. You go over the expression from left to right. Every time a number is encountered, push it on to the stack. When we encounter an operator, take the two numbers that are on top of the stack (we also say that we pop them), use the operator and those two and then push the resulting number back onto the stack. 
	
	
	A more correct term for what a functor is would be computational context.
	
	function type is a normal type, created by type constructor: ->
	
	normal function composition create new function to : 1, accept 1 parameter. 2 apply right func with parameter. 3, apply left function with previous result.
	
	when you make a new type from an existing type by using the newtype keyword, you can only have one value constructor and that value constructor can only have one field. But with data, you can make data types that have several value constructors and each constructor can have zero or more fields
	
	internally, Haskell can represent the values of types defined with newtype just like the original ones
	
	
	data CoolBool = CoolBool { getCoolBool :: Bool }  
	
	helloMe :: CoolBool -> String  
	helloMe (CoolBool _) = "hello"  
	
	ghci> helloMe undefined  
	"*** Exception: Prelude.undefined  
	
	Types defined with the data keyword can have multiple value constructors (even though CoolBool only has one). So in order to see if the value given to our function conforms to the (CoolBool _) pattern, Haskell has to evaluate the value just enough to see which value constructor was used when we made the value. And when we try to evaluate an undefined value, even a little, an exception is thrown.
	
	newtype CoolBool = CoolBool { getCoolBool :: Bool }  
	
	ghci> helloMe undefined  
	"hello"  
	
	Well, like we've said, when we use newtype, Haskell can internally represent the values of the new type in the same way as the original values. It doesn't have to add another box around them, it just has to be aware of the values being of different types. And because Haskell knows that types made with the newtype keyword can only have one constructor, it doesn't have to evaluate the value passed to the function to make sure that it conforms to the (CoolBool _) pattern because newtype types can only have one possible value constructor and one field!
	
	data can be used to make your own types from scratch, newtype is for making a completely new type out of an existing type. Pattern matching on newtype values isn't like taking something out of a box (like it is with data), it's more about making a direct conversion from one type to another.
	
	monoid is an algebraic structure with a single associative binary operation and an identity element. 
	
	monoid laws
	a value that acts as the identity with respect to the binary function
	binary function has to be associative
	
	different from monoid in math, in haskell, it is a type, value of this type is in math monoid's set and contains math monoid's operator info.
		



***** html
HTML tag tell browser how to execute & render the view
	Normally it will ask browser to render some view, then ask browser to execute inner tags
	But in WebComponents, Shadow Host(an element with ShadowDOM) will ask browser to render some view, then ask browser to execute its hosted ShadowDOM instead of inner tags



	data- attribute:
    	Intended to store custom data private to the page or application (Private to page or application means that browser to render the page or any other behavior should not rely on these attributes)
    	Are intended for use by the site's own scripts
    	In HTML5 compatable JS, these attributes can be accessed via dataset.


tags
<meta name=”viewport” content=”......″>
	Used to config the browser viewport(Container to show the page content. If screen size is smaller than viewport size, we can see only part of the viewport)


手机浏览器是把页面放在一个虚拟的“窗口”（viewport）中，通常这个虚拟的“窗口”（viewport）比屏幕宽，这样就不用把每个网页挤到很小的窗口中（这样会破坏没有针对手机浏览器优化的网页的布局），用户可以通过平移和缩放来看网页的不同部分。移动版的 Safari 浏览器最新引进了 viewport 这个 meta tag，让网页开发者来控制 viewport 的大小和缩放，其他手机浏览器也基本支持。
width：控制 viewport 的大小，可以指定的一个值，如果 600，或者特殊的值，如 device-width 为设备的宽度（单位为缩放为 100% 时的 CSS 的像素）。
height：和 width 相对应，指定高度。
initial-scale：初始缩放比例，也即是当页面第一次 load 的时候缩放比例。
maximum-scale：允许用户缩放到的最大比例。
minimum-scale：允许用户缩放到的最小比例。
user-scalable：用户是否可以手动缩放

***** java
compile
When compile java to class, 
it will make return type as part of the method indicator. 

E.g: 
StringUtils.concatenate(new Object[5]); 
	TO:
concatenate '([Ljava/lang/Object;)Ljava/lang/String;


java.lang.reflect.Proxy
Class proxyC = Proxy.getProxyClass(${interface}.class.getClassLoader(), ${interface}.class);

Create a class detailed below: 
	1, External Relation: Extend Proxy, Impl ${interface}
	
	2, Internal Structure: Create METHODs: ${interface}'s methods, hashCode, equals, toString, annotationType 
																& one CONSTRUCTOR
												Implemention of methods are: directly invoke Proxy.h.invoke()	
												Implemention of constructor is: InvocationHandler as param, directly invoke Proxy(InvocationHandler h)
JUL
JUL - JavaUtilLogging
	By default, the LogManager reads its initial configuration from a properties file "lib/logging.properties" in the JRE directory
	uses two optional system properties that allow more control over reading the initial configuration:
		java.util.logging.config.class
			The given class will be loaded, an object will be instantiated, and that object's constructor is responsible for reading in the initial configuration.
		java.util.logging.config.file
			The initial logging configuration will be read from

                                                                                                
***** javascript
Function:
1, function name is only a variable, its value is the code.
2, method execution is: (code)(parameters...)
	if code is code its self not function name, first round brackets can be omit.
3, In high level, only 2 fields in Function object: 1, code. 2, [[Scope]].

Unnamed function:
No global variable, to avoid variable pollution.

---------------------------------THIS-----------------------------
this is a keyword refer to function's owner, default owner is window.




		
--------------------------------------------------------------------------------
JS Pre-Compile: 
	Var declare and function declare (Not assign value) will be pre-compiled.  
	JS的预编译是以段为处理单元的
--------------------------------------------------------------------------------	

Reference 
	Is a internal JS type, 2 properties: base object & property name
--------------------------------------------------------------------------------


Cross Domain Access
	JS access attributes of Window Object  whose domain attribute is different from ExecutionContext.window.domain
	
	Normally access to these attributes are not allowed, but window.postMessage() & window.name is an exception, so they can be used to do Cross Domain Access


Events
3 event handle model:
	NN4
	IE4+ - attachEvent
	W3C/Safari - addEventListener
	
	
Events Difference:
	DOMContentLoaded vs OnLoad
		The DOMContentLoaded event is fired when the document has been completely loaded and parsed, without waiting for stylesheets, images, and subframes to finish loading
			Note: Stylesheet loads block script execution, so if you have a <script> after a <link rel="stylesheet" ...>, the page will not finish parsing - and DOMContentLoaded will not fire - until the stylesheet is loaded.
			So please put css under all scripts to speed up the load
		OnLoad will fired when all stylesheets, images, and subframes finish loading


inherit
JS inherit is achieved via setup reference between prototypes

2 inherit implementation:
	a, 
		Logic: Student -> new Person() -> Person.prototype
		Code : Student.prototype = new Person();
	
	b, 
		Logic : Student -> {} -> Person.prototype
		Code :	var TempCtr = new Function(); 
				TempCtr.prototype=Person.prototype; 
				Student.prototype = new TempCtr();
				


scope chain
Normally will be used to lookup variable in execution. 

Scope Chain - A object's field, an array like object with set of objects will expose to script execute context. 

	Execution's ScopeChain
		Creation: 
			Create empty New ScopeChain
			Create ActiveObject as New ScopeChain's first element
			Copy & Append current Function's ScopeChain to New ScopeChain

	Function's ScopeChain
		Under field: [[Scope]]
		Creation: 
			Create empty New ScopeChain
			Copy & Append current Execution's ScopeChain to New ScopeChain

	P.s. : 
		ActiveObject
			Also called Call Object
			To encapsulate the function's parameters & local variables & this
			Created when function been invoked. 
		Copy ScopeChain
			Only copy ScopeChain's elements's reference & sequence	
	

**** AMD
Asynchronous Module Definition

	Module is the core
        Create Module
        Inject Module
        Execute Module


	Reverse 2 global variables & 1 function in spec:
		define - module definer assign to this variable
		require - not specify any usage, recommend to assign Module Loader to it.
		function(id?, dependencies?, factory)
			id:
				if id is not specified, its a anonymous Module. In this case the final Module name is the name you used to load it.
				Strongly suggested that don't specify, default id will follow JS file name.
				This param designed for optimization tool to specify id so that multiple modules can be in one file, to reduce download time.


	Module Loader(require) normally only to load the Module File.
	Module File can contains arbitrary code, but it must invoke define to define Module.
	Module identifiers may be "relative" or "top-level". A module identifier is "relative" if the first term is "." or "..".
		Top-level identifiers are resolved off the conceptual module name space root.
        Relative identifiers are resolved relative to the identifier of the module in which "require" is written and called.


	Loader Plugin - Just another module to load different types of resources as dependencies
		Format:
			${plugin name}!${resource name(to be loaded by plugin)}

		Module Loader will load the plugin module first, then pass the rest of the dependency name to a load() method on the plugin.

		Example:
			define({
                load: function (name, req, onload, config) {
                    //req has the same API as require().
                    req([name], function (value) {
                        onload(value);
                    });
                }
            });
            
	define vs require
		Both define & require can load Module & wrap code
		Define wrap code into a Module, so that its dependency can be managed
		Given above reason, better to put code in define instead of require
	
**** promise
An Object represents the eventual result(normally available in future) of a function
	Several Roles here (for detailed interact, refer to Promise.png):
		Originator
			Create & fulfill/reject Promise(may produce result)
		Consumer
			Get Promise, consume Promise via Processors
		Promise

	API
		Promise.then(SuccessProcessor, ErrorProcessor) :: Promise
			Register Processors, create & return new Promise
			
			process after Promise fulfillment/reject:
				execute  SuccessProcessor/ErrorProcessor with value/reason
				if error when execute SuccessProcessor, execute ErrorProcessor
				if ErrorProcessor executed
					reject returned new Promise
				else
					fulfill returned new Promise
						if SuccessProcessor have return
							fulfill returned new Promise with SuccessProcessor return
						else
							fulfill returned new Promise with current fulfillment value

**** RDF
RDF(Resource Description Framework) - A data model, just like Atom & RSS
	Making statements about resources in the form of subject-predicate-object expressions (triples)
	A set of Vocabulary in spec to describe data (representation grammar)
	


**** referential transparency
RT (Referential Transparency)
	Expression can be safely replaced with its result
**** expression problem
How to express new semantic without existing expression change

## Details
In program it means function/data add new semantic via implement new interface

E.g.  

Previously RegExp is readable, now how to make it also invokable without existing expression change

**** input method
character conversion, convert ASCII characters to other characters

simple input method: one ASCII char convert to one other char
composition input method: sequence of ASCII char convert to one or more other char

dictionary - contains mappings of ASCII char sequence to target char


**** unicode math
not a good idea, as:
1, a lot of unicode chars are very similar to each other
e.g.
Σ vs ∑
∁ vs C
...

2, a lot of unicode char display overlaps in emacs
e.g.
∈[ ∋1

**** CSRF
Cross Site Request Forgery
	Kind of a confused deputy attack against a web browser, trick browser into sending HTTP request.
	Root Cause:
		HTTP request from the real website and the request from the evil website are exactly the same
			Non-cookie request data can be manually created by evil website
			Cookie request data can be created when the request is sent by user's browser

	
Countermeasure:
	Add random token to requests
		One token per request or session should both be ok.
		One token per session have a better support for sites with parallel requests
	
	Impl:
		CSRF as parameter:
			include csrf parameter when submit
				Can add csrf to form
			This is normally used by form submit
		CSRF as header:
			set the csrf to the header
				Can add csrf to meta tag & manually add to request header
			This is normally used by ajax reqeust
			
**** http
HTTP is a protocol.
	It define the request data format and the response data format.
	HTTP Request Process:
		Client send Header to Server via TCP/IP
		Server check Header and decide whether ask Client to go ahead to send Entity(Body)
		If yes, client go ahead to send Body
	
	Message Common Field Format:
		general-header:
			Cache-Control
			| Connection
			| Date
			| Pragma
			| Trailer
			| Transfer-Encoding
					Specify the method to transfer request Entity
						Possible value:
							chunked - divide to chunk & send
							identity - send as a whole
			| Upgrade
			| Via
			| Warning

		message-body:
			entity-body
			| <entity-body encoded as per Transfer-Encoding>

		entity-header:
			Allow
			| Content-Encoding
			| Content-Language
			| Content-Length
			| Content-Location
			| Content-MD5
			| Content-Range
			| Content-Type
			| Expires
			| Last-Modified


	Request Format:
		Request-Line
		*(( general-header
		 | request-header
		 | entity-header ) CRLF)
		CRLF
		[ message-body ]


			request-header:
				Accept
				| Accept-Charset
				| Accept-Encoding
				| Accept-Language
				| Authorization
				| Expect
				| From
				| Host
				| If-Match
				| If-Modified-Since
				| If-None-Match
				| If-Range
				| If-Unmodified-Since
				| Max-Forwards
				| Proxy-Authorization
				| Range
				| Referer
				| TE
				| User-Agent


	Http Request Resource Steps:
		1, Client check if cached copy available
			If not available, go to step 3
		2, Client check the cached copy is fresh or not
			If fresh, return
		3, Client request to server
		4, Server check resource changed or not
			If changed, return new content
			If not, return 304
		4, Client update cache



	Http Web Cache:
		Cache between Origin Server & Client


		Category:
			Browser Cache
			Proxy Cache
			Gateway Cache


		Control:
			Properties:
				Freshness Info:
					Cache-Control
						For HTTP 1.1, takes precedence over Pragma & Expires
						Values:
							max-age - the number of seconds from the time of the request you wish the representation to be fresh for
							s-maxage - similar to max-age, except that it only applies to shared (e.g., proxy) caches
							public - marks authenticated responses as cacheable; normally, if HTTP authentication is required, responses are automatically private
							private - allows caches that are specific to one user (e.g., in a browser) to store the response; shared caches (e.g., in a proxy) may not
							no-cache - forces caches to submit the request to the origin server for validation before releasing a cached copy, every time
							no-store - instructs caches not to keep a copy of the representation under any conditions
							must-revalidate - tells caches that they must obey any freshness information you give them about a representation
							proxy-revalidate - similar to must-revalidate, except that it only applies to proxy caches

					Pragma
						For HTTP 1.0, when connection is https

					Expires
						Expire when
	                    A date need to be set here, so need to sync time between server, proxy & client.
	                    Better to use Cache-Control instead

				Validate Info:
	                Last-Modified
	                    Can use it to ask the server if the representation has changed since the last time it was seen, with an If-Modified-Since request

	                ETag
	                    Unique identifiers that are generated by the server and changed every time the representation does.

			Implement Location:
				Http Header
				Meta tag:
					Only honored by a few browser caches, not proxy caches (which almost never read the HTML in the document).

					E.g.:
						<META http-equiv="Cache-Control" content="no-cache">
						<META http-equiv="Pragma" content="no-cache" />
						<META http-equiv="Expires" content="-1">


		Browser Behavior:
			Refresh:
				Click Refresh Button:
					Add Cache-Control:max-age=0 in Request header to stale cached copy, this apply to the requested URL & <link>s & <script>s in returned page

				Existing Page Enter In Address Bar:
					Add Cache-Control:max-age=0 in Request header to stale cached copy, this apply to the requested URL only

			Navigate:
				Open In New Tab (manually & automatically), Navigate Button:
					No add

**** java ee
Contains:

Servlet
JSP
JSTL
JSF - ?

JMS
JTA - ?
JavaMail
JavaBeans Activation Framework - ?

JAXP
JAXB
JAX-WS
SAAJ
JAXR - ?

JCA - ?
JDBC
JPA
JNDI
JAAS
**** URL encoding
Why need URL encoding
Can not specify char set in URL, so ISO-8859-1 is only the char set. 
Some ISO-8859-1 char will be used to represent some logic, so need to encoding to avoid confuse.

How
URL encoding of a character consists of a "%" symbol, followed by the two-digit hexadecimal representation (case-insensitive) of the ISO-Latin code point for the character.


**** cookie

Cookies have:
name, value. Property: domain, Max-Age, path, version, secure or other self defined property.

Mulitple Cookies will be passed in Reqeust or Response header
Servlet specification need cookies's JSESSIONID to track session



Java:
A cookie has a name, a single value, and optional attributes such as a comment, path and domain qualifiers, a maximum age, and a version number. Some Web browsers have bugs in how they handle the optional attributes, so use them sparingly to improve the interoperability of your servlets. 

The servlet sends cookies to the browser by using the HttpServletResponse.addCookie(javax.servlet.http.Cookie)  method, which adds fields to HTTP response headers to send cookies to the browser, one at a time. The browser is expected to support 20 cookies for each Web server, 300 cookies total, and may limit cookie size to 4 KB each. 


**** proxy
proxy server
	a server that acts as an intermediary for requests from clients seeking resources from other servers

	Types:
		forward proxy 
			acts as an intermediary for its (usually nearby) associated clients and returns to them resources accessible on the Internet
		reverse proxy
			acts as an intermediary for its (usually nearby) associated servers and only returns resources provided by those associated servers
**** https
1, Firefox send request to server.
2, Server send public certificate to Brower.
3, Firefox check the public certificate if it's not in firefox's trust certificate lib. Fire fox will show an error page.


**** session fixation
Let victim to access a site with a fixed session id

Senario:
	1, Attacker give link with fixed session id to victim
	2, Victim accessed the link with the session id & logged in
	3, Attacker use the session id to access postlogin pages

Countermeasure:
	Change the session after login.
	

**** XSS
Cross-site scripting
	A case of code injection, CM input been executed when invlid input retrieved.
	
Sinario:
	persistent:
		1, Attacker create a post, with XSS code, in forum
		2, Victim read the post & XSS code been executed in his browser
	non-persistent:
		1, Attacker send a link, with XSS code, to victim
		2, Victim access the link & XSS code been executed in his browser
		
Countermeasure:
	Do validation
		

**** Enterprise Integration Pattern
EIP - Enterprise Integration Patterns
	refer to 连接.txt

	messaging  systems  typically  follow  the  similarly  abstract "pipes-and-filters" model
	
	I prefer the name "channels-and-endpoints" over "pipes-and-filters"


**** electrical circuit
ElectricalCircuit

	Concepts:
		Coulomb
		Unit of electrical charge  
		
		Volt
		Unit of potential
		
		Joule
		Unite of energe
		
		Ampere
		Unit of electrical current

**** encoding
Parse byte to char need to consider: encoding & formatter
Normally encode, except UTF-*, will simply put encode to memory/disk, but for UTF-*, it will put unicode encode to memory/disk with different formatter.



今天中午，我突然想搞清楚Unicode和UTF-8之间的关系，于是就开始在网上查资料。

结果，这个问题比我想象的复杂，从午饭后一直看到晚上9点，才算初步搞清楚。

下面就是我的笔记，主要用来整理自己的思路。但是，我尽量试图写得通俗易懂，希望能对其他朋友有用。毕竟，字符编码是计算机技术的基石，想要熟练使用计算机，就必须懂得一点字符编码的知识。

1. ASCII码

我们知道，在计算机内部，所有的信息最终都表示为一个二进制的字符串。每一个二进制位（bit）有0和1两种状态，因此八个二进制位就可以组合出 256种状态，这被称为一个字节（byte）。也就是说，一个字节一共可以用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从 0000000到11111111。

上个世纪60年代，美国制定了一套字符编码，对英语字符与二进制位之间的关系，做了统一规定。这被称为ASCII码，一直沿用至今。

ASCII码一共规定了128个字符的编码，比如空格“SPACE”是32（二进制00100000），大写的字母A是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号），只占用了一个字节的后面7位，最前面的1位统一规定为0。

2、非ASCII编码

英语用128个符号编码就够了，但是用来表示其他语言，128个符号是不够的。比如，在法语中，字母上方有注音符号，它就无法用ASCII码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。

但是，这里又出现了新的问题。不同的国家有不同的字母，因此，哪怕它们都使用256个符号的编码方式，代表的字母却不一样。比如，130在法语编码中代表了é，在希伯来语编码中却代表了字母Gimel (?)，在俄语编码中又会代表另一个符号。但是不管怎样，所有这些编码方式中，0—127表示的符号是一样的，不一样的只是128—255的这一段。

至于亚洲国家的文字，使用的符号就更多了，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是GB2312，使用两个字节表示一个汉字，所以理论上最多可以表示256x256=65536个符号。

中文编码的问题需要专文讨论，这篇笔记不涉及。这里只指出，虽然都是用多个字节表示一个符号，但是GB类的汉字编码与后文的Unicode和UTF-8是毫无关系的。

3.Unicode

正如上一节所说，世界上存在着多种编码方式，同一个二进制数字可以被解释成不同的符号。因此，要想打开一个文本文件，就必须知道它的编码方式，否则用错误的编码方式解读，就会出现乱码。为什么电子邮件常常出现乱码？就是因为发信人和收信人使用的编码方式不一样。

可以想象，如果有一种编码，将世界上所有的符号都纳入其中。每一个符号都给予一个独一无二的编码，那么乱码问题就会消失。这就是Unicode，就像它的名字都表示的，这是一种所有符号的编码。

Unicode当然是一个很大的集合，现在的规模可以容纳100多万个符号。每个符号的编码都不一样，比如，U+0639表示阿拉伯字母Ain，U+0041表示英语的大写字母A，U+4E25表示汉字“严”。具体的符号对应表，可以查询unicode.org，或者专门的汉字对应表。

4. Unicode的问题

需要注意的是，Unicode只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。

比如，汉字“严”的unicode是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。

这里就有两个严重的问题，第一个问题是，如何才能区别unicode和ascii？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果unicode统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。

它们造成的结果是：1）出现了unicode的多种存储方式，也就是说有许多种不同的二进制格式，可以用来表示unicode。2）unicode在很长一段时间内无法推广，直到互联网的出现。

5.UTF-8

互联网的普及，强烈要求出现一种统一的编码方式。UTF-8就是在互联网上使用最广的一种unicode的实现方式。其他实现方式还包括UTF-16和UTF-32，不过在互联网上基本不用。重复一遍，这里的关系是，UTF-8是Unicode的实现方式之一。

UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。

UTF-8的编码规则很简单，只有二条：

1）对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的。

2）对于n字节的符号（n>1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码。

下表总结了编码规则，字母x表示可用编码的位。

    Unicode符号范围 | UTF-8编码方式
    (十六进制) | （二进制）
    --------------------+---------------------------------------------
    0000 0000-0000 007F | 0xxxxxxx
    0000 0080-0000 07FF | 110xxxxx 10xxxxxx
    0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx
    0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx

下面，还是以汉字“严”为例，演示如何实现UTF-8编码。

已知“严”的unicode是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800-0000 FFFF），因此“严”的UTF-8编码需要三个字节，即格式是“1110xxxx 10xxxxxx 10xxxxxx”。然后，从“严”的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。这样就得到了，“严”的UTF-8编码是 “11100100 10111000 10100101”，转换成十六进制就是E4B8A5。

6. Unicode与UTF-8之间的转换

通过上一节的例子，可以看到“严”的Unicode码是4E25，UTF-8编码是E4B8A5，两者是不一样的。它们之间的转换可以通过程序实现。

在Windows平台下，有一个最简单的转化方法，就是使用内置的记事本小程序Notepad.exe。打开文件后，点击“文件”菜单中的“另存为”命令，会跳出一个对话框，在最底部有一个“编码”的下拉条。



**** html encoding
1,
Encode "我" according to "<META http-equiv="Content-Type" content="text/html; charset=windows-8859-1">"
TO:
&#25105;

2,
&#25105;
转意：
%26%2325105%3B


**** java encoding
Brower：我 will encode to bytes according to <meta http-equiv="content-type" content="text/html; charset=UTF-8">
Server: Read stream and decode to string by using default "ISO-8859-1"











常见的JAVA程序包括以下类别：
*直接在console上运行的类(包括可视化界面的类)
*JSP代码类（注：JSP是Servlets类的变型）
*Servelets类
*EJB类
*其它不可以直接运行的支持类


这些类文件中，都有可能含有中文字符串，并且常用前三类JAVA程序和用户直接交互，用于输出和输入字符，如：在JSP和Servlet中得到客户端送来的字符，这些字符也包括中文字符。无论这些JAVA类的作用如何，这些JAVA程序的生命周期都是这样的：

*编程人员在一定的操作系统上选择一个合适的编辑软件来实现源程序代码并以.java扩展名保存在操作系统中，例如我们在中文win2k中用记事本编辑一个java源程序；
*编程人员用JDK中的javac.exe来编译这些源代码，形成.class类(JSP文件是由容器调用JDK来编译的)；
*直接运行这些类或将这些类布署到WEB容器中去运行，并输出结果。
那么，在这些过程中，JDK和JVM是如何将这些文件如何编码和解码并运行的呢？

这里，以中文win2k操作系统为例说明JAVA类是如何来编码和被解码的。

第一步，我们在中文win2k中用编辑软件如记事本编写一个Java源程序文件(包括以上五类JAVA程序)，程序文件在保存时默认采用了操作系统默认支持GBK编码格式(操作系统默认支持的格式为file.encoding格式)形成了一个.java文件，也即，java程序在被编译前，我们的JAVA源程序文件是采用操作系统默认支持的file.encoding编码格式保存的， java源程序中含有中文信息字符和英文程序代码；要查看系统的file.encoding参数，可以用以下代码：
　　public class ShowSystemDefaultEncoding {
　　public static void main(String[] args) {
　　String encoding = System.getProperty("file.encoding");
　　System.out.println(encoding);
　　}}

第二步，我们用JDK的javac.exe文件编译我们的Java源程序，由于JDK是国际版的，在编译的时候，如果我们没有用-encoding参数指定我们的JAVA源程序的编码格式，则javac.exe首先获得我们操作系统默认采用的编码格式，也即在编译java程序时，若我们不指定源程序文件的编码格式，JDK首先获得操作系统的file.encoding参数(它保存的就是操作系统默认的编码格式，如WIN2k，它的值为GBK)，然后JDK就把我们的java源程序从file.encoding编码格式转化为JAVA内部默认的UNICODE格式放入内存中。然后，javac把转换后的unicode格式的文件进行编译成.class类文件，此时.class文件是 UNICODE编码的，它暂放在内存中，紧接着，JDK将此以UNICODE编码的编译后的class文件保存到我们的操作系统中形成我们见到的. class文件。对我们来说，我们最终获得的.class文件是内容以UNICODE编码格式保存的类文件，它内部包含我们源程序中的中文字符串，只不过此时它己经由file.encoding格式转化为UNICODE格式了。

这一步中，对于JSP源程序文件是不同的，对于JSP，这个过程是这样的：即WEB容器调用JSP编译器，JSP编译器先查看JSP文件中是否设置有文件编码格式，如果JSP文件中没有设置JSP文件的编码格式，则JSP编译器调用JDK先把JSP文件用JVM默认的字符编码格式(也即WEB容器所在的操作系统的默认的file.encoding)转化为临时的Servlet类，然后再把它编译成UNICODE格式的class类，并保存在临时文件夹中。如：在中文win2k上，WEB容器就把JSP文件从GBK编码格式转化为 UNICODE格式，然后编译成临时保存的Servlet类，以响应用户的请求。

第三步，运行第二步编译出来的类，分为三种情况：

A、 直接在console上运行的类
B、 EJB类和不可以直接运行的支持类(如JavaBean类)
C、 JSP代码和Servlet类
D、 JAVA程序和数据库之间

下面分这四种情况来看。

A、直接在console上运行的类

这种情况，运行该类首先需要JVM支持，即操作系统中必须安装有JRE。运行过程是这样的：首先java启动JVM，此时JVM读出操作系统中保存的class文件并把内容读入内存中，此时内存中为UNICODE格式的class类，然后 JVM运行它，如果此时此类需要接收用户输入，则类会默认用file.encoding编码格式对用户输入的串进行编码并转化为unicode保存入内存（用户可以设置输入流的编码格式）。程序运行后，产生的字符串（UNICODE编码的）再回交给JVM，最后JRE把此字符串再转化为 file.encoding格式(用户可以设置输出流的编码格式)传递给操作系统显示接口并输出到界面上。

以上每一步的转化都需要正确的编码格式转化，才能最终不出现乱码现象。

B、EJB类和不可以直接运行的支持类(如JavaBean类)

由于EJB类和不可以直接运行的支持类，它们一般不与用户直接交互输入和输出，它们常常与其它的类进行交互输入和输出，所以它们在第二步被编译后，就形成了内容是UNICODE编码的类保存在操作系统中了，以后只要它与其它的类之间的交互在参数传递过程中没有丢失，则它就会正确的运行。

C、JSP代码和Servlet类

经过第二步后，JSP文件也被转化为Servlets类文件，只不过它不像标准的Servlets一校存在于classes目录中，它存在于WEB容器的临时目录中，故这一步中我们也把它做为Servlets来看。

对于Servlets，客户端请求它时，WEB容器调用它的JVM来运行 Servlet，首先，JVM把Servlet的class类从系统中读出并装入内存中，内存中是以UNICODE编码的Servlet类的代码，然后 JVM在内存中运行该Servlet类，如果Servlet在运行的过程中，需要接受从客户端传来的字符如：表单输入的值和URL中传入的值，此时如果程序中没有设定接受参数时采用的编码格式，则WEB容器会默认采用ISO-8859-1编码格式来接受传入的值并在JVM中转化为UNICODE格式的保存在WEB容器的内存中。Servlet运行后生成输出，输出的字符串是UNICODE格式的，紧接着，容器将Servlet运行产生的UNICODE格式的串（如html语法，用户输出的串等）直接发送到客户端浏览器上并输出给用户，如果此时指定了发送时输出的编码格式，则按指定的编码格式输出到浏览器上，如果没有指定，则默认按ISO-8859-1编码发送到客户的浏览器上。

D、Java程序和数据库之间

对于几乎所有数据库的JDBC驱动程序，默认的在JAVA程序和数据库之间传递数据都是以ISO-8859-1为默认编码格式的，所以，我们的程序在向数据库内存储包含中文的数据时，JDBC首先是把程序内部的UNICODE编码格式的数据转化为ISO-8859-1的格式，然后传递到数据库中，在数据库保存数据时，它默认即以ISO-8859-1保存，所以，这是为什么我们常常在数据库中读出的中文数据是乱码。

3、分析常见的JAVA中文问题几个必须清楚的原则

首先，经过上面的详细分析，我们可以清晰地看到，任何JAVA程序的生命期中，其编码转换的关键过程是在于：最初编译成class文件的转码和最终向用户输出的转码过程。
其次，我们必须了解JAVA在编译时支持的、常用的编码格式有以下几种：
*ISO-8859-1，8-bit, 同8859_1,ISO-8859-1,ISO_8859_1等编码
*Cp1252，美国英语编码，同ANSI标准编码
*UTF-8，同unicode编码
*GB2312，同gb2312-80,gb2312-1980等编码
*GBK , 同MS936，它是gb2312的扩充
及其它的编码，如韩文、日文、繁体中文等。同时，我们要注意这些编码间的兼容关体系如下：
unicode和UTF-8编码是一一对应的关系。GB2312可以认为是GBK的子集，即GBK编码是在gb2312上扩展来的。同时，GBK编码包含了20902个汉字，编码范围为：0x8140-0xfefe，所有的字符可以一一对应到UNICODE2.0中来。

再次，对于放在操作系统中的.java源程序文件，在编译时，我们可以指定它内容的编码格式，具体来说用-encoding来指定。注意：如果源程序中含有中文字符，而你用-encoding指定为其它的编码字符，显然是要出错的。用- encoding指定源文件的编码方式为GBK或gb2312，无论我们在什么系统上编译含有中文字符的JAVA源程序都不会有问题，它都会正确地将中文转化为UNICODE存储在class文件中。

然后，我们必须清楚，几乎所有的WEB容器在其内部默认的字符编码格式都是以ISO- 8859-1为默认值的，同时，几乎所有的浏览器在传递参数时都是默认以UTF-8的方式来传递参数的。所以，虽然我们的Java源文件在出入口的地方指定了正确的编码方式，但其在容器内部运行时还是以ISO-8859-1来处理的。

4、中文问题的分类及其建议最优解决办法

了解以上JAVA处理文件的原理之后，我们就可以提出了一套建议最优的解决汉字问题的办法。
我们的目标是：我们在中文系统中编辑的含有中文字符串或进行中文处理的JAVA源程序经编译后可以移值到任何其它的操作系统中正确运行，或拿到其它操作系统中编译后能正确运行，能正确地传递中文和英文参数，能正确地和数据库交流中英文字符串。
我们的具体思路是：在JAVA程序转码的入口和出口及JAVA程序同用户有输入输出转换的地方限制编码方法使之正确即可。

具体解决办法如下：

1、 针对直接在console上运行的类
对于这种情况，我们建议在程序编写时，如果需要从用户端接收用户的可能含有中文的输入或含有中文的输出，程序中应该采用字符流来处理输入和输出，具体来说，应用以下面向字符型节点流类型：
对文件：FileReader，FileWrieter
其字节型节点流类型为：FileInputStream，FileOutputStream
对内存（数组）：CharArrayReader，CharArrayWriter
其字节型节点流类型为：ByteArrayInputStream，ByteArrayOutputStream
对内存（字符串）：StringReader，StringWriter
对管道：PipedReader，PipedWriter
其字节型节点流类型为：PipedInputStream，PipedOutputStream
同时，应该用以下面向字符型处理流来处理输入和输出：
BufferedWriter，BufferedReader
其字节型的处理流为：BufferedInputeStream，BufferedOutputStream
InputStreamReader，OutputStreamWriter
其字节型的处理流为：DataInputStream，DataOutputStream
其中InputStreamReader和InputStreamWriter用于将字节流按照指定的字符编码集转换到字符流，如：
InputStreamReader in = new InputStreamReader(System.in，"GB2312")；
OutputStreamWriter out = new OutputStreamWriter (System.out，"GB2312")；
例如：采用如下的示例JAVA编码就达到了要求：

//Read.java
import java.io.*;
public class Read {
public static void main(String[] args) throws IOException {
String str = "\n中文测试，这是内部硬编码的串"+"\ntest english character";
String strin= "";
BufferedReader stdin = new BufferedReader(new InputStreamReader(System.in,"gb2312")); //设置输入接口按中文编码
BufferedWriter stdout = new BufferedWriter(new OutputStreamWriter(System.out,"gb2312")); //设置输出接口按中文编码
stdout.write("请输入:");
stdout.flush();
strin = stdin.readLine();
stdout.write("这是从用户输入的串："+strin);
stdout.write(str);
stdout.flush();
}}
同时，在编译程序时，我们用以下方式来进行：
javac -encoding gb2312 Read.java

2、 针对EJB类和不可以直接运行的支持类(如JavaBean类)

由于这种类它们本身被其它的类调用，不直接与用户交互，故对这种类来说，我们的建议的处理方式是内部程序中应该采用字符流来处理程序内部的中文字符串（具体如上面一节中一样），同时，在编译类时用-encoding gb2312参数指示源文件是中文格式编码的即可。

3、 针对Servlet类

针对Servlet，我们建议用以下方法：

在编译Servlet类的源程序时，用-encoding指定编码为GBK或 GB2312，且在向用户输出时的编码部分用response对象的setContentType("text/html;charset=GBK"); 或gb2312来设置输出编码格式，同样在接收用户输入时，我们用request.setCharacterEncoding("GB2312")；这样无论我们的servlet类移植到什么操作系统中，只有客户端的浏览器支持中文显示，就可以正确显示。如下是一个正确的示例：

//HelloWorld.java
package hello;
import java.io.*;
import javax.servlet.*;
import javax.servlet.http.*;
public class HelloWorld extends HttpServlet
{
public void init() throws ServletException { }
public void doGet(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException
{
request.setCharacterEncoding("GB2312"); //设置输入编码格式
response.setContentType("text/html;charset=GB2312"); //设置输出编码格式
PrintWriter out = response.getWriter(); //建议使用PrintWriter输出
out.println("Hello World! This is created by Servlet!测试中文!");
}

public void doPost(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException
{
request.setCharacterEncoding("GB2312"); //设置输入编码格式
response.setContentType("text/html;charset=GB2312"); //设置输出编码格式
String name = request.getParameter("name");
String id = request.getParameter("id");
if(name==null) name="";
if(id==null) id="";
PrintWriter out = response.getWriter(); //建议使用PrintWriter输出
out.println("你传入的中文字串是：" + name);
out.println("你输入的id是：" + id);
}
public void destroy() { }
请用javac -encoding gb2312 HelloWorld.java来编译此程序。

 

4、 JAVA程序和数据库之间

为避免JAVA程序和数据库之间数据传递出现乱码现象，我们建议采用以下最优方法来处理：
1、 对于JAVA程序的处理方法按我们指定的方法处理。
2、 把数据库默认支持的编码格式改为GBK或GB2312的。

如：在mysql中，我们可以在配置文件my.ini中加入以下语句实现：
在[mysqld]区增加：
default-character-set=gbk
并增加：
[client]
default-character-set=gbk
在SQL Server2K中，我们可以将数据库默认的语言设置为Simplified Chinese来达到目的。

5、 针对JSP代码

由于JSP是在运行时，由WEB容器进行动态编译的，如果我们没有指定JSP源文件的编码格式，则JSP编译器会获得服务器操作系统的file.encoding值来对JSP文件编译的，它在移植时最容易出问题，如在中文win2k中可以很好运行的jsp文件拿到英文 linux中就不行，尽管客户端都是一样的，那是因为容器在编译JSP文件时获取的操作系统的编码不同造成的（在中文wink中的 file.encoding和在英文Linux中file.encoding是不同的，且英文Linux的file.encoding对中文不支持，所以编译出来的JSP类就会有问题）。网络上讨论的大多数是此类问题，多是因为JSP文件移植平台时不能正确显示的问题，对于这类问题，我们了解了JAVA中程序编码转换的原理，解决起来就容易多了。我们建议的解决办法如下：

1、我们要保证JSP向客户端输出时是采用中文编码方式输出的，即无论如何我们首先在我们的JSP源代编中加入以下一行：

<%@page contentType=”text/html;charset=gb2312″%>

2、为了让JSP能正确获得传入的参数，我们在JSP源文件头加入下面一句：

<%request.setCharacterEncoding(”GB2312″);%>

3、为了让JSP编译器能正确地解码我们的含有中文字符的JSP文件，我们需要在JSP源文件中指定我们的JSP源文件的编码格式，具体来说，我们在JSP源文件头上加入下面的一句即可：
或
这是JSP规范2.0新增加的指令。
我们建议使用此方法来解JSP文件中的中文问题，下面的代码是一个正确做法的JSP文件的测试程序：

<%@page pageEncoding=”GB2312″%>
<%@page contentType=”text/html;
charset=gb2312″%>
<%request.setCharacterEncoding(”GB2312″);
%>
<%
String action = request.getParameter(”ACTION”);
String name = “”;
String str = “”;
if(action!=null && action.equals(”SENT”))
{
name = request.getParameter(”name”);
str = request.getParameter(”str”);
}
%>
<html>
<head>
<title></title>
<Script language=”JavaScript”>
function Submit()
{
document.base.action =
“?ACTION=SENT&str=传入的中文”;
document.base.method = “POST”;
document.base.submit();
}
</Script>
</head>
<body bgcolor=”#FFFFFF”
text=”#000000″ topmargin=”5″>
<form name=”base” method =
“POST” target=”_self”>
<input type=”text” name=”name”
value=”" size=”30″>
<a href = “JavaScript:Submit()”>提交</a>
</form>
<%
if(action!=null && action.equals(”SENT”))
{
out.println(”<br>你输入的字符为：”+name);
out.println(”<br>你通过URL传入的字符为：”+str);
}
%>
</body>
</html>



=================================================================================================


JVM
JVM启动后，JVM会设置一些系统属性以表明JVM的缺省区域。
user.language,user.region,file.encoding等。 可以使用System.getProperties()详细查看所有的系统属性。
如在英文操作系统(如UNIX)下，可以使用如下属性定义强制指定JVM为中文环境 -Dclient.encoding.override=GBK -Dfile.encoding=GBK -Duser.language=zh -Duser.region=CN
.java-->.class编译
说明：一般javac根据当前os区域设置,自动决定源文件的编码.可以通过-encoding强制指定.
错误可能:
1 gbk编码源文件在英文环境下编译,javac不能正确转换.曾见于java/jsp在英文unix下. 检测方法:写\u4e00格式的汉字，绕开javac编码,再在jvm中,将汉字作为int打印，看值是否相等；或直接以UTF-8编码打开.class 文件，看看常量字符串是否正确保存汉字。
文件读写
外部数据如文件经过读写和转换两个步骤，转为jvm所使用字符。InputStream/OutputStream用于读写原始外部数据，Reader/Writer执行读写和转换两个步骤。
1 文件读写转换由java.io.Reader/Writer执行；输入输出流 InputStream/OutputStream 处理汉字不合适,应该首选使用Reader/Writer，如 FileReader/FileWriter。
2 FileReader/FileWriter使用JVM当前编码读写文件.如果有其它编码格式,使用InputStreamReader/OutputStreamWriter
3 PrintStream有点特殊，它自动使用jvm缺省编码进行转换。
读取.properties文件
.propeties 文件由Properties类以iso8859-1编码读取，因此不能在其中直接写汉字，需要使用JDK 的native2ascii工具转换汉字为\uXXXX格式。命令行：native2ascii ?encoding GBK inputfile outputfile
读取XML文件
1 XML文件读写同于文件读写，但应注意确保XML头中声明如<? xml version=”1.0” encoding=”gb2312” ?>与文件编码保持一致。
2 javax.xml.SAXParser类接受InputStream作为输入参数，对于Reader，需要用org.xml.sax.InputSource包装一下，再给SAXParser。
3 对于UTF-8编码 XML，注意防止编辑器自动加上\uFFFE BOM头, xml parser会报告content is not allowed in prolog。
字节数组
1 使用 new String(byteArray,encoding) 和 String.getBytes(encoding) 在字节数组和字符串之间进行转换
也可以用ByteArrayInputStream/ByteArrayOutputStream转为流后再用InputStreamReader/OutputStreamWriter转换。
错误编码的字符串(iso8859-1转码gbk)
如果我们得到的字符串是由错误的转码方式产生的，例如：对于gbk中文，由iso8859-1方式转换，此时如果用调试器看到的字符串一般是 的样子，长度一般为文本的字节长度，而非汉字个数。
可以采用如下方式转为正确的中文：
text = new String( text.getBytes(“iso8859-1”),”gbk”);

WEB/Servlet/JSP
1 对于JSP，确定头部加上 <%@ page contentType="text/html;charset=gb2312"%>这样的标签。
2 对于Servlet，确定 设置setContentType (“text/html; charset=gb2312”)，以上两条用于使得输出汉字没有问题。
3 为输出HTML head中加一个 <meta http-equiv="Content-Type" content="text/html; charset=gb2312"> ，让浏览器正确确定HTML编码。
4 为Web应用加一个Filter，确保每个Request明确调用setCharacterEncoding方法,让输入汉字能够正确解析。
import java.io.IOException;
import javax.servlet.Filter;
import javax.servlet.FilterChain;
import javax.servlet.FilterConfig;
import javax.servlet.ServletException;
import javax.servlet.ServletRequest;
import javax.servlet.ServletResponse;
import javax.servlet.UnavailableException;
import javax.servlet.http.HttpServletRequest;
/**
 * Example filter that sets the character encoding to be used in parsing the
 * incoming request
*/
public class SetCharacterEncodingFilter
implements Filter {
public SetCharacterEncodingFilter()
{}
protected boolean debug = false;
protected String encoding = null;
protected FilterConfig filterConfig = null;
public void destroy() {
this.encoding = null;
this.filterConfig = null;
}
public void doFilter(ServletRequest request, ServletResponse response,
FilterChain chain) throws IOException, ServletException {
// if (request.getCharacterEncoding() == null)
// {
// String encoding = getEncoding();
// if (encoding != null)
// request.setCharacterEncoding(encoding);
//
// }
request.setCharacterEncoding(encoding);
if ( debug ){
System.out.println( ((HttpServletRequest)request).getRequestURI()+"setted to "+encoding );
}
chain.doFilter(request, response);
}
public void init(FilterConfig filterConfig) throws ServletException {
this.filterConfig = filterConfig;
this.encoding = filterConfig.getInitParameter("encoding");
this.debug = "true".equalsIgnoreCase( filterConfig.getInitParameter("debug") );
}
protected String getEncoding() {
return (this.encoding);
}
}
web.xml中加入：
<filter>
<filter-name>LocalEncodingFilter</filter-name>
<display-name>LocalEncodingFilter</display-name>
<filter-class>com.ccb.ectipmanager.request.SetCharacterEncodingFilter</filter-class>
<init-param>
<param-name>encoding</param-name>
<param-value>gb2312</param-value>
</init-param>
<init-param>
<param-name>debug</param-name>
<param-value>false</param-value>
</init-param>
</filter>
<filter-mapping>
<filter-name>LocalEncodingFilter</filter-name>
<url-pattern>/*</url-pattern>
</filter-mapping>
5 用于Weblogic（vedor-specific）：
其一:在web.xml里加上如下脚本:
<context-param>
<param-name>weblogic.httpd.inputCharset./*</param-name>
<param-value>GBK</param-value>
</context-param>
其二（可选）在weblogic.xml里加上如下脚本:
<charset-params>
<input-charset>
<resource-path>/*</resource-path>
<java-charset-name>GBK</java-charset-name>
</input-charset>
</charset-params>
SWING/AWT/SWT
对于SWING/AWT，Java会有些缺省字体如Dialog/San Serif，这些字体到系统真实字体的映射在$JRE_HOME/lib/font.properties.XXX文件中指定。排除字体显示问题时，首先需要确定JVM的区域为zh_CN，这样font.properties.zh_CN文件才会发生作用。对于 font.properties.zh_CN , 需要检查是否映射缺省字体到中文字体如宋体。
在Swing中，Java自行解释TTF字体，渲染显示；对于AWT,SWT显示部分交由操作系统。首先需要确定系统装有中文字体。
1 汉字显示为”□”，一般为显示字体没有使用中文字体，因为Java对于当前字体显示不了的字符，不会像Windows一样再采用缺省字体显示。
2 部分不常见汉字不能显示，一般为显示字库中汉字不全，可以换另外的中文字体试试。
3 对于AWT/SWT，首先确定JVM运行环境的区域设置为中文，因为此处设计JVM与操作系统api调用的转换问题，再检查其它问题。
JNI
JNI中jstring以UTF-8编码给我们，需要我们自行转为本地编码。对于Windows，可以采用WideCharToMultiByte/MultiByteToWideChar函数进行转换，对于Unix，可以采用iconv库。
这里从SUN jdk 1.4 源代码中找到一段使用jvm String 对象的getBytes的转换方式，相对简单和跨平台，不需要第三方库，但速度稍慢。函数原型如下：
/* Convert between Java strings and i18n C strings */
JNIEXPORT jstring
NewStringPlatform(JNIEnv *env, const char *str);
JNIEXPORT const char *
GetStringPlatformChars(JNIEnv *env, jstring jstr, jboolean *isCopy);
JNIEXPORT jstring JNICALL
JNU_NewStringPlatform(JNIEnv *env, const char *str);
JNIEXPORT const char * JNICALL
JNU_GetStringPlatformChars(JNIEnv *env, jstring jstr, jboolean *isCopy);
JNIEXPORT void JNICALL
JNU_ReleaseStringPlatformChars(JNIEnv *env, jstring jstr, const char *str);
附件jni_util.h,jni_util.c
JDK1.4/1.5新增部分
字符集相关类(Charset/CharsetEncoder/CharsetDecoder)
jdk1.4开始，对字符集的支持在java.nio.charset包中实现。
常用功能：
1 列出jvm所支持字符集：Charset.availableCharsets()
2 能否对看某个Unicode字符编码，CharsetEncoder.canEncode()
常见问题
在JVM下，用System.out.println不能正确打印中文，显示为???
System.out.println是PrintStream，它采用jvm缺省字符集进行转码工作，如果jvm的缺省字符集为iso8859-1，则中文显示会有问题。此问题常见于Unix下，jvm的区域没有明确指定的情况。
在英文UNIX环境下,用System.out.println能够正确打印汉字，但是内部处理错误
可能是汉字在输入转换时，就没有正确转码：
即gbk文本à(iso8859-1转码)àjvm char(iso8859-1编码汉字)à (iso8859-1转码)à输出。
gbk汉字经过两次错误转码，原封不动的被传递到输出，但是在jvm中，并未以正确的unicode编码表示，而是以一个汉字字节一个char的方式表示，从而导致此类错误。
GB2312-80，GBK，GB18030-2000 汉字字符集
GB2312-80 是在国内计算机汉字信息技术发展初始阶段制定的，其中包含了大部分常用的一、二级汉字，和 9 区的符号。该字符集是几乎所有的中文系统和国际化的软件都支持的中文字符集，这也是最基本的中文字符集。其编码范围是高位0xa1－0xfe，低位也是 0xa1-0xfe；汉字从 0xb0a1 开始，结束于 0xf7fe；
GBK 是 GB2312-80 的扩展，是向上兼容的。它包含了 20902 个汉字，其编码范围是 0x8140-0xfefe，剔除高位 0x80 的字位。其所有字符都可以一对一映射到 Unicode 2.0，也就是说 JAVA 实际上提供了 GBK 字符集的支持。这是现阶段 Windows 和其它一些中文操作系统的缺省字符集，但并不是所有的国际化软件都支持该字符集，感觉是他们并不完全知道 GBK 是怎么回事。值得注意的是它不是国家标准，而只是规范。随着 GB18030-2000国标的发布，它将在不久的将来完成它的历史使命。
GB18030-2000(GBK2K) 在 GBK 的基础上进一步扩展了汉字，增加了藏、蒙等少数民族的字形。GBK2K 从根本上解决了字位不够，字形不足的问题。它有几个特点，
它并没有确定所有的字形，只是规定了编码范围，留待以后扩充。
编码是变长的，其二字节部分与 GBK 兼容；四字节部分是扩充的字形、字位，其编码范围是首字节 0x81-0xfe、二字节0x30-0x39、三字节 0x81-0xfe、四字节0x30-0x39。
UTF-8/UTF-16/UTF-32
UTF，即Unicode Transformer Format，是Unicode代码点(code point)的实际表示方式，按其基本长度所用位数分为UTF-8/16/32。它也可以认为是一种特殊的外部数据编码，但能够与Unicode代码点做一一对应。
UTF-8是变长编码，每个Unicode代码点按照不同范围，可以有1-3字节的不同长度。
UTF-16长度相对固定，只要不处理大于\U200000范围的字符，每个Unicode代码点使用16位即2字节表示，超出部分使用两个UTF-16即4字节表示。按照高低位字节顺序，又分为UTF-16BE/UTF-16LE。
UTF-32长度始终固定，每个Unicode代码点使用32位即4字节表示。按照高低位字节顺序，又分为UTF-32BE/UTF-32LE。
UTF 编码有个优点，即尽管编码字节数不等，但是不像gb2312/gbk编码一样，需要从文本开始寻找，才能正确对汉字进行定位。在UTF编码下，根据相对固定的算法，从当前位置就能够知道当前字节是否是一个代码点的开始还是结束，从而相对简单的进行字符定位。不过定位问题最简单的还是UTF-32，它根本不需要进行字符定位，但是相对的大小也增加不少。
关于GCJ JVM
GCJ并未完全依照sun jdk的做法，对于区域和编码问题考虑尚不够周全。GCJ启动时，区域始终设为en_US，编码也缺省为iso8859-1。但是可以用Reader/Writer做正确编码转换


**** encrypt
Encrypt message/information(plaintext) to ciphertext
	It's done with encryption algorithm and encryption key.
	
	Format:
		CipherdInfo = f(Mapper, PlainInfo)
		Mapper = f(Algorithm, Key) 
		
		Note:
			Normally PlainInfo is in Plaintext format.
			PlainInfo may contains: Char, Frequency info ...

encrypt algorithm
hash(or digest) algorithm is a one-way function which produce a pice of fixed-length output data(the hash), such as a password
	Relative algorithm: MD5
	


Data Encryption Standard
对称算法
密钥为64位，有效密钥长度为56位（有8位用于奇偶校验）

Data Encryption Algorithm，DEA
Advanced Encryption Standard，AES




常见的非对称加密算法：

RSA：由 RSA 公司发明，是一个支持变长密钥的公共密钥算法，需要加密的文件块的长度也是可变的；

DSA（Digital Signature Algorithm）：数字签名算法，是一种标准的 DSS（数字签名标准）；

DSA 用于签名，而 RSA 可用于签名和加密。


**** cert
How to generate Cert
1, Generator generate Key pair
2, Send CA the public key & generator info.
3, CA do verify.
4, CA send generator a Cert which contains public key & generator info & CA's signature info.

What used for & how to use
Public key will be used to encrypt data & verify signature
Generator info is only used for ur refer no other usage.
CA's signature info is used to verify this Cert is valid.

Format
	Name Format:
		*.cer
	Content Format:
		Base-64 encoded X.509 (.CER)
			-----BEGIN CERTIFICATE-----
			${certificate string}
			-----END CERTIFICATE-----
		
		
Sign Cert
	CA put signature in Unsigned Cert


**** java cipher
KeyGenerator is used to generate Key to do symmetric encryption.
Java Cipher object will be a helper object (Cipher.ENCRYPT_MODE, Cipher.DECRYPT_MODE)


KeyPairGenerator is used to generate KeyPair to do:
asymmetric encryption - Cipher object will be a helper object (Cipher.WRAP_MODE, Cipher.UNWRAP_MODE)
Signature - Signature will be the helper object


**** encrypt key

Public Key contains:
exponent
modulus

Private Key contains:
P
Q
D


All above are numbers.



Key is a (group of) number, used to d/encrypt data via calculate with data.

Symmetrical Key have only one key.
Asymmetrical Key pair have Public & Private key.
	Public Key can be used to do Encrypt & Signing
	

**** key store
A file to store keys
	Many keystore formatters like:
		JKS - java's standard keystore formatter, created by keytool under jdk
		PKCS11, PKCS12 - internet standard can be used by OpenSSL or Microsoft's Key-Manager
	
	Each entry in keystore is identified by an alias string
	
	Key can be imported from CA(.crt file)
	
	
	Details:
		CSR - Certificate Signing Request
		CA - Certificate Authority
			will authenticate the certificate requestor (usually off-line) and will return a certificate or certificate chain, 
			used to replace the existing certificate chain (which initially consists of a self-signed certificate) in the keystore.
		Private Key
			used to create the PKCS#10 certificate request
		Keystore
			Include:
				Private Key, Public Key, Certificate
		
**** encrypte salt
Salt - A random bits. 
	One of the inputs to a one-way function, the other input is usually a password
	Salt will store together with encrypted password, to do the password verification.
	Used to avoid dictionary attack, since attacker can not build dictionary for each salt.


**** entity data model

Entity Data Model(EDM) - A data model, just like Atom & RSS



**** SDLC
Tech Stack:
	Framework Choose		->	dart, polymer, rest, dojo, spring, jpa, hibernate, oracle
	Coding					->	Eclipse, DartEditor, WebStorm
	Testing					->	Jrebel
	Version Control			->	Git
	Project Manage			->	Maven (Mainly for Build)
		Dependency Manage	->	Maven, Dart Pub
		Build
		Deploy
	Continuous Integration	->	Jenkin
	Server Runtime			->	Tomcate
	Domain Manage			->	Godaddy
	PaaS(OS)				->	rhc, ssh


Build
	Construct consumable artifact(normally refer to artifact able to run in specific env) from source



Release:
	Requirement:
		Be able to link to source
			Source need to be perm (check in SCM)
			There should be a link (Tag source in SCM)
			so that be able to re-deploy or change

	Steps:
		Check in & Tag code in SCM
		Build base on it
		Deploy to env


Dev:
	Requirement:
		Be able to link to source for short term
			Workcopy is temp, but satisfy short term requirement


	Build & Deploy to server here is not Release, since no Check in & Tag in SCM




**** SDO
Service Data Objects - A data programming  architecture and an API 
	Unifying data programming across data source types
	Architecture:
		DataObject - Representation of a business object
			Not tied to any specific persistent storage mechanism
			
		DataGraph - Collect a graph of related DataObjects
			Contains: 
				DataObjects
				ChangeSummary
				
		Data Access Services (DAS) - Load & save DataGraph
		


**** polymorphism
one stuff have different state

## Details
in java, they think overwrite method and overwritten method are logically same, so here comes polymorph.  
in js, same name method are regard as same method, no matter it's overwrite or not  

**** cdi
Contexts and Dependency Injection for Java EE platform
	weld is the reference implement

	Bean
		managed bean
            Basically, any concrete class




	@Produces
        Producer Method

    @Disposes
        Dispose Method

	@Inject
        Inject Point

    @Qualifier
        Used to define Qualifer, so that inject can identify different bean with same type

	@Named("cart")
        Specify a key used in EL

    Scope:
        @RequestedScoped
        @SessionScoped
        @ApplicationScoped
        @ConversationScoped
        @Dependent

    Steps:
        Add dependency
            weld-core, weld-servlet-core
        Add listener in web.xml : org.jboss.weld.environment.servlet.Listener
        Add @Produces method
        Use with @Inject

**** program development
***** dev enveroment
Windows:
COMMON:
xunlei
chrome
expressvpn
vlc

DEV:
emacs
7-zip - used by emacs to extract file
cygwin - unix-like tools required by emacs e.g. diff
git - used by emacs/magit
gostscript - required by doc-view-mode to convert postscript/pdf to png, need to rename gswin4c.exe to gs.exe & availabe in $PATH

jdk
lein

idea - java remote debugger UI, inner maven for download sources, 







Linux:
expressvpn
openssh-server - for remote access
curl - for download


gcc - for compile
make - for build(compile, install ...)
libncurses-dev - provide function tputs used by emacs installation
emacs - editor
unzip - required by emacs clojure find symbol
git - for scm
chicken - chichen scheme
tk - provide  bin:wish, used be feathers, which is a chicken built-in debugger


openjdk-8-jdk-headless - java, for clojure
lein - for clojure build

libappindicator3-dev - required by lantern
lantern - proxy

nodejs - for cljs runtime (need to config apt repo to install latest version 8.9.0)
npm:
  source-map-support - support source mapping





***** development method

****** agile
# Agile

## Agile Manifesto

We are uncovering better ways of developing software by doing it and helping others do it. Through this work we have come to value:

 * Individuals and interactions over Processes and tools
 * Working software over Comprehensive documentation
 * Customer collaboration over Contract negotiation
 * Responding to change over Following a plan
      
That is, while there is value in the items on the right, we value the items on the left more.
		
		
## Principles behind the Agile Manifesto

 * Our highest priority is to satisfy the customer through early and continuous delivery of valuable software.
 * Welcome changing requirements, even late in development. Agile processes harness change for the customer's competitive advantage.		
 * Deliver working software frequently, from a couple of weeks to a couple of months, with a preference to the shorter timescale.		
 * Business people and developers must work together daily throughout the project.		
 * Build projects around motivated individuals. Give them the environment and support they need, and trust them to get the job done.		
 * The most efficient and effective method of conveying information to and within a development team is face-to-face conversation.		
 * Working software is the primary measure of progress.		
 * Agile processes promote sustainable development. The sponsors, developers, and users should be able to maintain a constant pace indefinitely.		
 * Continuous attention to technical excellence and good design enhances agility.		
 * Simplicity--the art of maximizing the amount of work not done--is essential.		
 * The best architectures, requirements, and designs emerge from self-organizing teams.		
 * At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly.
		

		
## Concrete Implementations:

 * SCRUM
 * KANBAN


    lean and just-in-time (JIT) production  
    Cycle time is a key metric for kanban team  
    Cycle time is the amount of time it takes for a unit of work to travel through the team’s workflow  
    A control chart shows the cycle time for each issue as well as a rolling average for the team. 


****** scrum
Scrum
	An iterative and incremental agile software development framework
	
	Elements:
		3 roles
			product owner
			scrum master
				responsible for daily standup meetings and tracking the overall progress. 
				It is the duty of scrum master to make sure team is not blocked at any point of time due to external or internal issues. 
				But, scrum master should not be thought as a task master - since in a pure agile approach the team assigns tasks to itself.
			scrum team
		3 main artefacts
			burndown chart, product backlog and sprint backlog
		4 important activities
			daily standup meeting
				the scrum team along with the scrum master sit and discuss the daily progress for a 15 - 30 minute period. 
				Important to notice here is the need to keep these meetings short and precise.
			sprint planning meeting, sprint review meeting and the retrospective meeting
				
			
	Terms(Also apply for other Agile Method):
		USER STORY
			define a software feature from an end-user perspective
				E.g.
					As a user, I want to be able to update my profile with age, present occupation and social interests, so that people visiting my profile page get an idea of my interests
			Generally, it is good to follow this template:
				As a <end-user-type>, I want to be able to <user-requirement> so that <reason>.
			ideally user story must be independent of other user stories	
			
		USER STORY POINTS
			a way to estimate the task size
			the average story points, we calculated above is also called the team velocity
			
		Iteration
			A period (generally 1 - 4 weeks long) when the agile development team produces the next increment of the software (or any other product) is called an iteration
			The requirements/tasks to be done in the iteration are defined at the beginning of iteration by the product owner and agreed upon by the team
			Once the iteration is ongoing, the team is not supposed to respond to any new requirement or change requests
			
		Poker Planning
			This is a consensus based approach for estimating the efforts for a task. 
			This generally involves team members and product owners proposing estimation values using poker cards and then finally everyone agreeing to one value.
			
		


****** interactive development
Runtime enveroment is keeped up and exposed, so that you can coding in runtime.


## Details
In contrast, normal development: coding, runtime enveroment start up, read all code, execute and exist.   

REPL is a program to support Interactive Development, as it keeps runtime up & expose it.  
REPL type:

 * Local REPL
 * Remote REPL

### Benifit

 * you no longer coding blindly
 * you can keeping try and get feed back immediatly
 * you can directly query or change a runtime
 * ...



**** context-free grammar
	every production rule is of the form V → w where V is a single nonterminal symbol, and w is a string of terminals and/or nonterminals (w can be empty). 
	
	A formal grammar is considered "context free" when its production rules can be applied regardless of the context of a nonterminal. 
	It does not matter which symbols the nonterminal is surrounded by, the single nonterminal on the left hand side can always be replaced by the right hand side.
	
**** closure
Closure(lexical closure / function closure)
	Expression whose open bindings (free variables) have been closed by (or bound in) the lexical environment, resulting in a closed expression, or closure.

	Why Closure:
		Some Expression Variables ONLY declared in Expression declaration stage, to make them available in execution stage we need to bind them in lexical environment.
	
Disadvantage
	variables lifecycle need to extend untill the corresponding function distroyed
	
**** data model
Data Model -  Model of the data
	Here, data is inside software
	In narrow sense:
		It covers the Data structure
	In broad sense:
		It covers the Data structure, Data flow, Data access & persist

**** data source
DataSource
	A factory for Connection
	
	Details:
	 	An alternative to the DriverManager facility, a DataSource object is the preferred means of getting a connection. 
	 	An object that implements the DataSource interface will typically be registered with a naming service based on the JavaTM Naming and Directory (JNDI) API.
	
		The DataSource interface is implemented by a driver vendor. There are three types of implementations:
			Basic implementation -- produces a standard Connection object
			Connection pooling implementation -- produces a Connection object that will automatically participate in connection pooling. This implementation works with a middle-tier connection pooling manager.
			Distributed transaction implementation -- produces a Connection object that may be used for distributed transactions and almost always participates in connection pooling. This implementation works with a middle-tier transaction manager and almost always with a connection pooling manager.

**** data structure
Date Structure:
	Standalone
	Cluster(Grid)

Sequence
	List
		tuple link to other tuple via reference to formulate a chain

**** coding-over-configuration
2 approaches to customize the behavior of a complex framework or server
	Coding
		1 problem:
			Need to have knowlege on the code
		
		E.g.
			Maven, Grunt
	Configuration
		2 problems:
			Not so direct, additional code needed to read, parse, and interpret these configuration files
			Logic support is poor
			
		E.g.
			Gradle, Gulp
		
**** command object
Command Object
	Encapsulate Command & pass to Controller
	Normally this is bind to form

**** concurrency
Concurrency
	Multiple Execution perform concurrently
	
	
	Current Execution Approaches:
		Shared ExecutionContext for different Execution
			Raise Problem:
				Some Execution can only be done in Exclusive ExecutionContext
					E.g. 
						Transaction
						
			Problem Solution:
				Use Isolation to create Exclusive ExecutionContext inside Shared ExecutionContext
				
		Clonable Exclusive ExecutionContext for different Execution

	
	Non-current Execution Approaches:
		Non-clonable Exclusive ExecutionContext for different Execution

**** CAS
CAS - compare-and-swap

**** JUC
JUC - java.util.concurrent
	Executor
	
	
	

happens-before
	The results of a write by one thread are guaranteed to be visible to a read by another thread only if the write operation happens-before the read operation.


**** algorithm

***** recursion
A shape

E.g. Recursive Container - similar stuffes can put into this Container

One stuff contains isomorphic stuff

So it's a container

RPC - Recursion produce Complex: Prime + Adder + Adder ...

Recursion make Infinite possible

Examples can implemented via Recursion:
List:
  container contains 1 isomorphic stuff & 1 another stuff
Tree:
  container contains multiple isomorphic stuff & multiple another stuff
Recursion-Logic:
  function recursion
  Execution of Recrusion-Logic:
    1, Ignore Container
    2, Nearby Logic Executed Nearbyly
    3, Nearbyly Executed Logic may pass data
  Execution of Recursion-Logic will create/extract Recursion Data if:
    1, Nearbyly Executed Logic pass data
    2, wrape/unwrape passed data
Complex State:
  A State = another State(previous State) + one Change
Set:
  A Set = another Set(sub Set) + a Incremental
Number:
  A Number = another Number + 1
Any Complex Stuff:
  A Complex Stuff = another Complex Stuff(sub Complex Stuff) + a Incremental


## Details
### Can be created via:

 * loop between: outside inside
 * replace reference in function which contains a reference of itself

### Simple Example:

    (((((0
    
Note:  
These '('s are isomorphic  
If the '('s are the same, it's a dead loop in program  
This structure can be used to ship repeated stuff like: (x(x(x(x...  
U can divide this structure on ur favor. E.g.: (x, (x, (x, ... or (x(x(x(x(x, (x(x(x(x, (x(x(x, ...  

### Function Recursion(Declarative View):

    A --          -- Q
     Ai --      -- Qi
      Aii --  -- Qii
            ...
      Abase == Qbase

Note:  
A, Ai, Aii... are answers  
Q, Qi, Qii... are questions  
--- are relations(functions)

### Procedure Recursion(Imperative View):

Recursively apply a process which:

1. have Answer and Problem as input
2. eat Problem Piece and generate Answer Piece
3. add Answer Piece to Answer


Recursion - The process of repeating items in a self-similar way

	Common Pattern:
		Resolve part of the problem
		Recursion Application

	Normally this is used as a Pattern to decompose complex problem & resolve.

	Simulate via program:
		E.g.
            function appendA(s){
                var ns = s.append("a");
                appendA(ns);
            }

			Note: appendA is a complex problem, so use Recursion to decompose it & resolve a bit at one go


***** iteration
Iteration
	A Process Pattern in which same sub-process happen iteratively

	Details:
		recursive process - make state change iteratively from internal to external
			internal state change base on external state change
		
		iterative process - make state change iteratively from external to internal
			external state change base on internal state change
		
		Independent Iteration Impl: 
			Every Iteration Process should contains 3 sub-process (only one process will be used in Execution):
				First Iteration Process
					give init state
					continue next Iteration Process
				Middle Iteration Process
					continue next Iteration Process
				Last Iteration Process
					exist Iteration chain

					
					
recursion process need to apply to self similar data, as problem target need to be peeled in each recursion and rest of problem target need to pass to next recursion

recursion pattern
     get the problem target
     resolve part of the problem
     pass the rest of problem target to next recursion


recursion is normally executing a set of similar processes, if it execute a process(same procedure with same arguments) it will be a dead loop.

to have a hole picture of recursion better to view it form this perspective:
     recursion contains a chain (invocation of itself)
     process logics in each chain element


chain/iteration vs recursion
     iteration unit don't contains other iteration unit, so iteration unit need additional step to combine
     recursion unit contains other recursion unit
          recursion unit contains:
               one of: 
                    base - only in last recursion unit
                    other recursion unit & addition
               



		Iteration Process:
			Init State
			Exist?
			Process State
			Exist?
			Process State
			...



different from other closure structure, addition in recursion is the same, from this addition perspective it should same as iteration
					
***** while-true
Common Pattern:                
        init state x           
        while true:            
                check state x  
                        return 
                process state x

**** continous delivery
Continuous Delivery:
	Continuous Delivery is a process that integrates Continuous Integration with automated deployment, test, and release.

	Pipeline:
		An automated manifestation of your process for getting software from version control into the hands of your users

		Details:
			Pipeline structure:
				Tasks inside Jobs inside Stages inside Pipelines 
					Multiple Pipelines run in parallel
					Multiple Stages within a Pipeline run sequentially
					Multiple Jobs within a Stage run in parallel
					Multiple Tasks within a Job run sequentially
		
			The Pipeline is automated:
				To support automated build & deployment:
					Everything required to re-create your application's binaries and the environments in which they run need to be maintained in VCS

				automating the entire deployment process embodies a key agile practice – making your code (in this case your deployment scripts) your documentation. 
					build and deployment scripts capture your deployment and environment testing process
				
				Automating deployment principles
					1.  Each build stage should deliver working software – don't have separate stages for intermediate artifacts such as frameworks. 
					2.  Deploy the same artifacts in every environment – manage your runtime configuration separately. 
					3.  Automate testing and deployment – use several independent testing stages. 
					4.  Evolve your production line along with the application it assembles. 
			
					Principle 1:
						This build will be kicked off by any change in the source code of any part of that application, including the framework.
						It is important to note that your source code should still be organized in exactly the same modular way you normally would. This may mean having separate source control projects for your frameworks, common modules and applications. These components may also each have their own continuous integration projects. The important point is that the binaries created by one build stage don’t get used as inputs to dependent projects.
						As a framework matures and stabilizes, it should then be treated just as any other third party module that the software depends on. 
						
					Principle 2:
						The key to managing configuration is twofold: separate binaries from configuration, and keep all configuration information in one place.
						it should be stored in a version control system such as Subversion. It can then be made available either directly from version control, or via LDAP, a RESTful web service, or some other simple, generic method.
						Another choice that needs to be made in any configuration system is whether to have defaults that can be overridden, or to require all configurations to be explicit. The advantage of the former approach is that it keeps the custom information for each environment small and easy to manage. However, the latter option means you have all the configuration information in one place.
					
					Principle 3:
						There are three principles that drive how this should be done. 
							The first principle is that different types of testing should be independent from each other, with every stage of application testing tagging a particular version of a binary with an “OK” or “fail” stamp. 
							The second principle is to automate fully deploying into all test environments, staging, and even production. 
							Finally, you need to be able to test the environments to which you are deploying.
						
						Principle 3-1:
							One metaphor for this aspect of the build production line is scout badges. 
							As the binaries pass certain testing stages, they earn badges. Badges don't necessarily need to be earned in any specific order, although some badges may define pre-requisites. 
							It's also possible to drop out of the badge certification process early if you decide it's not for you. 
							At the end of the process, if a build has a full set of badges, then it earns a big shiny badge that says it has completed the entire gamut of tests. Once a binary reaches this stage, it can be considered fit for production.
						
						Principle 3-2:
							All modern application servers have scriptable remote administration tools. 
							Build systems such as Ant provide tools for performing many of these tasks, but if Ant cannot carry out the tasks required, custom scripts can fill the gap.
							It is a common requirement to have multiple versions of an application working on the same server or cluster at the same time, especially when hardware is at a premium. It is also vital in functional testing where you want to compare the behaviour of different versions of an application.
							Thus you have multiple versions of your application testable at any time. This strategy can be used on your production environment to ensure that your service is continually available, and to provide an extremely simple failover or back-out strategy to a previous version of your software in case the newest version fails.
						
						Principle 3-3:
							Server setup, DB connection setup need to be tested
							
					Principle 4:
						Customize the process base on ur application
			
**** statement
The smallest standalone element of an imperative programming language which expresses some action to be carried out.
Statement represent Action

**** expression
A finite combination of symbols that is well-formed according to rules that depend on the context.
A combination of explicit values, constants, variables, operators, and functions that are interpreted according to the particular rules of precedence and of association for a particular programming language, which computes and then produces (returns, in a stateful environment) another value. 
Expression represent Value

**** Function

***** normal function

***** high-order function

***** infix function

***** prefix function

***** curry function

**** Procedure
A sequence of actions

## Details
procedure may have a return value


**** Parameter
Normal Parameter
Generalization Type Parameter
  Need to be passed when u use Object Template

**** Format
a collection of Data in format of 0 & 1
		

**** execution flow control
Flow control should depends on semantic(whether to go on, to skip, to loop, to return...)
Invoker don't know the Invokee's semantic, so it can only be Invokee

implicit control semantic(execute next expression) is in all expressions except exist
by default next expression is the one indicated by program counter/instruction pointer/instruction address register/instruction counter

some language have expressions have explicit control semantic
e.g. return, goto, break, throw Exception

**** continuation
If there is no reused unit(e.g. function), all commands write one by one then, there is no need for continuation, all commands execute one by one until the end.

but a unit 'finished', it should not truly finished, only the unit finished, other commands after the unit invokation still need to be executed.

command a4, a5 locagically behind command b4 in the context of function A. But not addressly behind b4.
the sequence executer (get & inc program counter/instruction pointer/instruction address register/instruction counter, execute correpsonding command) after execute commands in function B by default not execute a4 a5, as there is no code addressly after a unit.

To make the programe continue, the last command(explictly or implicitly coded in source) in a unit should change program counter to where the unit is invoked.

The last command is continuation.




function A:
command a1
command a2
command a3
(function B)
command a4
command a5






function B:
command b1
command b2
command b3
command b4



**** explict over implicit
Explicit
  You can know what it's doing base on explicit expression.



Explicit
  boot
  
Implicit
  leiningen
  deps.edn
  deps.cljs
  maven
  

**** annotation

Annotation is just metadata

	Normally various processor need to be added to perform various actions base on these metadata.
	
	Annotation Lookup Strategy:
		considerInherited - lookup Annotation on parent class
		considerInterfaces - lookup Annotation on interfaces
		considerMetaAnnotations  - lookup Annotation on Annotations
	
	In Java:
		You define the annotation's structure(like interface). 
		
		During execution, JDK will :
			1, Invoke java.lang.reflect.Proxy.getProxyClass() to get proxy class
			2, Create instance of sun.reflect.annotation.AnnotationInvocationHandler, with values defined in the java code. 
			3, Initial object of the generated proxy class with above instance. 

**** architect
Architect
	Derives from the Latin architectus, which derives from the Greek arkhitekton (arkhi-, chief + tekton, builder), i.e., chief builder. 

	So he need to take all responsibilities,  but he can delegate some work to others.



**** Security
Web Security Zoo Division
	Server
	Client
		Self Site Page
		Non Self Site Page
	Network
	

**** session
Session is a Group (Refer to Container.txt)
	Web Session Create Steps:
		Client send Request to Server, Server create & save Group ID (session id)
		Server send Response to Client, Client save Group ID (cookie)
		
	Note:
		When there are current Requests without Group ID send to Server, there will be multiple Group ID created & send back to Client.
		In this case, the last return back Group ID will be used for further communication, other Group ID, Group & its contents will lost.
	


**** s expression
S-expression
	notation for nested list (tree-structured) data
	significance of symbols in identifying the value

	Definition:
        1, an atom, or
        2, an expression of the form (x . y) where x and y are s-expressions.

	Example:
		Corrected_S-expression_tree_2.png - Tree data structure representing the s-expression for (* 2 (+ 3 4))



**** single thread language
STL - Single Thread Language
	Language  Execution is Single Thread
	
	When Language  Execution invoke other Application/OS, other Application/OS Execution can be multiple thread
		E.g. 
			xhr.send(url1); 
				// Invoke OS to send data &  the invoke return immediately, language execution go ahead
				// But OS may open multiple thread to send data



**** solution stack
SolutionStack
	a set of software subsystems or components needed to create a complete platform such that no additional software is needed to support applications
	
	Note:
		Base on the definition: " ... create a complete platform ...", seems SolutionStack same to FullStack Platform
		But FullStack Solutions should cover SDLC whole process
		
	Some Common/Named Stacks:
		LAMP
		LYME
		LYCE
		GLASS
		MEAN
		
	Different Solutions provided in different stack(platform)
		runtime framework platform
			E.g.
				spring
				
		dev tool platform
			E.g.
				eclipse
				
		build platform
			E.g.
				maven
				
		collaboration platform
			E.g.
				rtc
				
		sdlc platform (fullstack)
			E.g.
				?

	FullStack Frameworks:
		Seam
		forge - seems using dsl to do dev setup and code gen
		roo
		play
		grails
		web4j
		jrapid
		Ninja
		Isis
		OpenXava
		Tynamo
		RomaFramework
		Ruby on Rails


**** SPI
SPI - Service Provider Interface

	Service - A set of interfaces
	Service Provider - Specific implementation of a Service


	A service is represented by a single type, that is, a single interface or abstract class
	Provider classes must have a zero-argument constructor so that they can be instantiated during loading
	A service provider is identified by placing a provider-configuration file in the resource directory META-INF/services
	The file's name is the fully-qualified binary name of the service's type
	The file contains a list of fully-qualified binary names of concrete provider classes, one per line
	
	
	ServiceLoader:
		java.util.ServiceLoader
			load(Class service) - Create ServiceLoader for given service type
			iterator() - Lazily loads the available providers of this loader's service
			

**** SMTP
SMTP - Simple Mail Transfer Protocol
	Used to send mail
	Base on TCP/IP


POP3 - Post Office Protocol 3
	Used to access mail


IMPA - Internet Message Access Protocol
	Used to access mail


**** standard
Standard for specific language is not so popular than those for common language
	E.g.
		JMS vs AMQP
		JPA-RS vs OData



**** staging enveroment
Env mirrors production environment
	Normally perform UAT in this Env


**** TCP/IP
IP analogy to city's address
	One net card map to one IP address

Port analogy to city's port
	port is a indicator of transport channel.


TCP IP Connection:
	The Connection is from Port to Port
	One Port can talk to several different Ports at same time
		E.g.
			10.100.12.12:51660          10.100.9.16:3306
			10.100.12.12:51654          10.100.9.16:3306
			10.100.12.12:51661          10.100.9.16:3306


Address Binding & Listening:
	Application need to binding to IP:Port
		Note:
			If IP not specified, it default to 0.0.0.0 which means all IP
			If IP not exist on current server, it will throw error: EADDRNOTAVAIL

		E.g.
			Listen: real ip
            	Access:
            		127.0.0.1 -> Not able to connect
            		real -> OK


            Listen: none exist ip
            	Fatal error: listen EADDRNOTAVAIL


            Listen: 127.0.0.1
            	Access:
            		127.0.0.1 -> OK
            		real -> Not able to connect

            Listen: 0.0.0.0
            	Access:
            		127.0.0.1 -> OK
            		real -> OK



**** router
A message router steps.

1, Check the address, if it's a IP, then find the gate way and deliever to message to specified IP.(Don't need to send message to DNS server)
2, If it's not a IP, find the DNS IP and send a new message(request the Domain Name's IP) and get the IP.
3, Find the gate way and deliever to message to specified IP.

**** dns
我认为域名的解析过程如下:

A上网客户机1.1.1.1   B ISP DNS 服务器2.2.2.2   C (root) DNS 服务器8.8.8.8    D (CNNIC .CN) DNS服务器 5.5.5.5   E (abc.cn) DNS 服务器 

A 的DNS服务器设定为 B

过程一:
(1)A 需要访问www.abc.cn , ------ >;  A 便询问了 B  ---->;(2) B 先检查缓存里有没有www.abc.cn 的记录, ----->;(3) 如果有www.abc.cn 的纪录,变将记录的结果给 A 



过程二:
(1)A 需要访问www.abc.cn , ------ >;  A 便询问了 B  ---->;(2) B 先检查缓存里有没有www.abc.cn 的记录, ----->;(3) 没有 www.abc.cn 的记录---->;
(4)由B来询问C ".CN 由睡负责?" ------>;(4) C告诉B 是由D 负责的 --->; (5) B得知这个消息后立刻问".CN"域的负责人D "abc.cn 谁负责?" ------>;(6) D告诉B "是由E 来负责的" ----->; B 便询问E "www.abc.cn 的地址是什么?" ---->;(7) B 把问到的结果返回给A 并把结果缓存起来



**** template
Template + Data = Document

Natural Template
	The Template can be a Document as valid as the final result, the engine syntax doesn't break the document's structure
	
	
HTML Template
	Make HTML dyna
	2 techs to impl template
		String Template
			Merge Model into Template then parse to DOM
		DOM Template
			Parse Template to DOM then merge Model into it


**** test
coverage
Function coverage - Has each function (or subroutine) in the program been called?
Statement coverage - Has each node in the program been executed?
Decision coverage - branch of each control structure (such as in IF and CASE statements)
Condition coverage - All boolean expression & it's sub expression. 
Parameter Value Coverage -  E.g. 1) null, 2) empty, 3) whitespace (space, tabs, new line), 4) valid string, 5) invalid string, 6) single-byte string, 7) double-byte string


Tools
	instrumenting Java bytecode
		JCov
			static instrumentation & dynamic instrumentation
			Go with JDK
		JaCoCo
			as a replacement for EMMA
		 	dynamic instrumentation
		 Cobertura
		 	static instrumentation
		 EMMA
		 	NOT currently under active development
	instrumenting source code
		 Clover


performance test
Tool:
	Apache BenchMark
		ab -n 100000 -c 2000 http://127.0.0.1:81/
		

Concurrency Level
	keep number of requests open at all times
	one request finished will open a new one to keep the Concurrency Level
	


smok testing
Smoke Testing (also confidence testing, sanity testing)
	preliminary testing to reveal simple failures severe enough to reject a prospective software release


test type
Unit Test VS Integration Test
    Unit Test: do test before runtime integration
    Integration Test: do test after runtime integration

    E.g.
        Start up web server to integrate servlet with server

		Junit test cases with following notations should be integration test instead of unit test
			@RunWith(SpringJUnit4ClassRunner.class)
			@SpringApplicationConfiguration(classes = Application.class)
			@WebIntegrationTest
				Note: this annotation is optional
		as:
			@SpringApplicationConfiguration will create a ApplicationContext to perform runtime integration(integrate spring beans)
			@WebIntegrationTest will create a web container to perform runtime integration(integrate http listener, servlet, filter ...)


**** time complex
一个算法中的语句执行次数称为语句频度或时间频度。记为T(n)。
n称为问题的规模

T(n)/f(n)的极限值为不等于零的常数，则称f(n)是T(n)的同数量级函数。


记作T(n)=Ｏ(f(n)),称Ｏ(f(n)) 为算法的渐进时间复杂度，简称时间复杂度。

其虽然对f(n)没有规定，但是一般都是取尽可能简单的函数。例如，O(2n2+n +1) = O (3n2+n+3) = O (7n2 + n) = O ( n2 ) 


T(n)=n2+3n+4与T(n)=4n2+2n+1它们的频度不同，但时间复杂度相同，都为O(n2)

这里的O就是数学中同阶无穷小的运算符，比如一个算法的循环次数是 N^2 + N，那么算法复杂度就是 N^2，也就是 N^2 + N 的同阶无穷小

大O符号（Big O notation）是用于描述函数渐近行为的数学符号。更确切地说，它是用另一个（通常更简单的）函数来描述一个函数数量级的渐近上界。

代表“order of ...”（……阶）的大O


Big O notation characterizes functions according to their growth rates: different functions with the same growth rate may be represented using the same O notation. The letter O is used because the growth rate of a function is also referred to as order of the function. 



**** transaction
Transaction: 
	a logical, atomic unit of work comply with ACID properties:
		A - Atomicity
			All tasks of a transaction are performed or none of them are
		C - Consistency
			The transaction takes the database from one consistent state to another consistent state
		I - Isolation
			#from oracle document
			The effect of a transaction is not visible to other transactions until the transaction is committed
			transaction execution context is isolated from other transaction's effect
			Txn Concurrency implemented via Clonable Exclusive ExecutionContext for different Execution
				as:
					Concurrent txn can change Context without visibility to other txn
				Note:
					No currency on data update, data update will use Non-clonable Exclusive ExecutionContext, all isolation level will lock the data from other change
					"update xxx where xxx" clause is evaluated in this Non-clonable Exclusive ExecutionContext
				refer to Concurrency.txt
				
		D - Durability
			Changes made by committed transactions are permanent
	
	
	Details:
		TPM - Transaction Processing Model
			AP - Application Program
				invoke:
					TM.startTxnUnit()
					RM.joinTxnUnit()
					RM.workInTxnUnit()
					TM.endTxnUnit()
			RM - Resource Manager
			TM - Transaction Manager

		Distributed Transaction
			Transaction across distributed Resource
			
		Transaction Concurrent
			Problems:
				Lost update
					两个事务都同时更新一行数据，一个事务对数据的更新把另一个事务对数据的更新覆盖了
				Dirty Reads
					一个事务读取到了另一个事务未提交的数据操作结果
				Non-repeatable Reads
					一个事务对同一行数据重复读取两次，但是却得到了不同的结果
					Contains:
						虚读
							事务T1读取某一数据后，事务T2对其做了修改，当事务T1再次读该数据时得到与前一次不同的值
						Phantom Reads
							事务在操作过程中进行两次查询，第二次查询的结果包含了第一次查询中未出现的数据或者缺少了第一次查询中出现的数据（这里并不要求两次查询的SQL语句相同）。这是因为在两次查询过程中有另外一个事务插入数据造成的。
		
		Isolation:
			Transaction Isolation Level:
				Read uncommitted
					允许脏读取，但不允许更新丢失。如果一个事务已经开始写数据，则另外一个事务则不允许同时进行写操作，但允许其他事务读此行数据。该隔离级别可以通过“排他写锁”实现。
					txn's init Shared ExecutionContext for read will be changed by other txn when uncommitted change
				Read committed
					允许不可重复读取，但不允许脏读取。这可以通过“瞬间共享读锁”和“排他写锁”实现。读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。
					txn's init Shared ExecutionContext for read will be changed by other txn when committed change
				Repeatable read
					禁止不可重复读取和脏读取，但是有时可能出现幻影数据。这可以通过“共享读锁”和“排他写锁”实现。读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。
					txn's init Non-clonable Exclusive ExecutionContext for read will NOT be changed
				Serializable
					要求事务序列化执行，事务只能一个接着一个地执行。如果仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。
					transaction no currency
				
				Note:
					txn's init ExecutionContext for write is Non-clonable Exclusive ExecutionContext
					
			Impl:
				usually implemented by locking whatever is accessed in a transaction. 
				two different approaches to transactional locking: Pessimistic locking and optimistic locking.
					pessimistic locking:
						Steps:
							1, resource is locked from the time it is first accessed in a transaction until the transaction is finished, making it inaccessible to other transactions during that time.
						advantage:
							locks are applied in a fail-safe way
						disadvantage:
							If most transactions simply look at the resource and never change it, an exclusive lock may be overkill as it may cause lock contention
					optimistic locking:
						Steps:
							1, the state of the resource at the time when it would have been locked with the pessimistic locking approach is saved
							2, At commit time, when the resource is about to be updated in persistent storage, the state of the resource is read from storage again and compared to the state that was saved when the resource was first accessed in the transaction. If the two states differ, a conflicting update was made, and the transaction will be rolled back.
						advantage:
							resource is not actually locked when it is first is accessed by a transaction
							Other transactions are able to concurrently access to the resource
						disadvantage:
							possibility of conflicting changes is possible
		Note:
			it is not acceptable for a database transaction to span a user interaction. 
			


**** DTP
DTP - Distributed Transaction Processing
	X/Open Distributed Transaction Processing (DTP) model same as TPM
		
**** two phase commit
2PC (Two-phase commit)
	a type of atomic commitment protocol (ACP)
	Done by Transaction Manager to coordinate multiple Resource Manager to perform prepare & commit.
	From outside only commit method exposed by Transaction Manager
	
	Phase 1
		MSG "prepare T" sent from coordinator to participants. 
		MSG "ready T" or "not commit T" revert from participants to coordinator, base on participant's check result. 
	Phase 2
		MSG "commit T" sent from coordinator to participants, if all participants reverted "ready T"
		MSG "abort T" sent from coordinator to participants, if any one not revert or revert "not commit T"
		MSG "succeed committed T" or "failed committed T" or "succeed aborted T" or "failed aborted T" revert from participants to coordinator, base on participant's action result. 

Note:
	Commit Change rely on:
		Application
		OS
		Hardware
	
	So:	
		Application can NOT give unconditional promise on Successful Change Commitment.
		But Application can give conditional promise on Successful Change Commitment. (Condition: if no exception in OS & Hardware)
		Prepare in Phase 1 is to request participants give conditional promise
	


**** Turing machine

Turing Machine
	A machine imaged by Turing
	A hypothetical device that manipulates symbols on a strip of tape according to a table of rules


Turing Complete
	Turing Complete means that it is at least as powerful as a Turing Machine. This means anything that can be computed by a Turing Machine can be computed by a Turing Complete system


**** TXT
Trusted Execution Technology
	computer hardware technology
	whose primary goals are 
		(a) attestation – attest to the authenticity of a platform and its operating system (OS); 
		(b) assure that an authentic OS starts in a trusted environment and thus can be considered a trusted OS; 
		(c) provide the trusted OS with additional security capabilities not available to an unproven OS.
		
	Intel TXT uses a Trusted Platform Module (TPM) and cryptographic techniques to provide measurements of software and platform components 
	so that system software as well as local and remote management applications may use those measurements to make trust decisions.


**** fundamental type
fundamental type
	scalar
		e.g. int, float, boolean, none
	non-scalar


**** versioning
Versioning - About how to version software
	Versioning strategys:
		Semantic Versioning(http://semver.org/)
			MAJOR.MINOR.PATCH
				MAJOR version when you make incompatible API changes,
				MINOR version when you add functionality in a backwards-compatible manner, and
				PATCH version when you make backwards-compatible bug fixes.
				Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format.


				A pre-release version MAY be denoted by appending a hyphen and a series of dot separated identifiers immediately following the patch version. Examples: 1.0.0-alpha, 1.0.0-alpha.1, 1.0.0-0.3.7, 1.0.0-x.7.z.92.
                Build metadata MAY be denoted by appending a plus sign and a series of dot separated identifiers immediately following the patch or pre-release version.Examples: 1.0.0-alpha+001, 1.0.0+20130313144700, 1.0.0-beta+exp.sha.5114f85.
				Major version zero (0.y.z) is for initial development. Anything may change at any time. The public API should not be considered stable.
				Precedence refers to how versions are compared to each other when ordered.
					Precedence MUST be calculated by separating the version into major, minor, patch and pre-release identifiers in that order (Build metadata does not figure into precedence). Precedence is determined by the first difference when comparing each of these identifiers from left to right as follows: Major, minor, and patch versions are always compared numerically. Example: 1.0.0 < 2.0.0 < 2.1.0 < 2.1.1. When major, minor, and patch are equal, a pre-release version has lower precedence than a normal version. Example: 1.0.0-alpha < 1.0.0.
					Precedence for two pre-release versions with the same major, minor, and patch version MUST be determined by comparing each dot separated identifier from left to right until a difference is found as follows: identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers. A larger set of pre-release fields has a higher precedence than a smaller set, if all of the preceding identifiers are equal. Example: 1.0.0-alpha < 1.0.0-alpha.1 < 1.0.0-alpha.beta < 1.0.0-beta < 1.0.0-beta.2 < 1.0.0-beta.11 < 1.0.0-rc.1 < 1.0.0.


		GNU Style:
        	Major_Version_Number.Minor_Version_Number[.Revision_Number[.Build_Number]]
	            Revision_Number - Bug fix
	            Minor_Version_Number - Subtle new functionality
	            Major_Version_Number - Major new functionality or radical reflact.


**** virtualization
Virtualization - Create a virtual (rather than actual) version of something

	Intel VT - Intel Virtualization Tech
		VT-x - For CPU
		VT-d - For IO


**** semantic web
Semantic Web
	Web of Data
		Precisely it should be Web of Semantic Data
		Semantic Data means Data need to obey Syntax Rule
		This Syntax Rule proposed by W3C is RDF
	
	Different from Traditional Web: Web of documents
	
	
	
	Linked data are empowered by technologies such as RDF, SPARQL, OWL, and SKOS.
	
	This collection of interrelated datasets on the Web can also be referred to as Linked Data
	
	RDF provides the foundation for publishing and linking your data.
	
	Vocabularies
		OWL to build vocabularies, or “ontologies”
		SKOS for designing knowledge organization systems
		
	SPARQL is the query language for the Semantic Web
	
	Inference
		
	Vertical Applications
		W3C is working with different industries


**** web animation
Web Animation - Abstract model for animation
	Contains:
		Timing model
		Animation model


**** web api
Web API - API exposed via Web
	Typically expressed in JSON or XML
	Typically done as HTTP/REST
	Nothing is defined, output can be eg. JSON/XML, input can be XML/JSON/or plain data
	


**** web components
Web Components - HTML enhance to support Component model for the Web
	Gramar/API Enhance:
		<template>
		<element>
		ShadowRoot
		<content>
		<shadow>
		<link rel="import" href="xxx.html">
		
		
	Details:
		<template> - Template, contains markup intended to be used later
			The content of the <template> element is parsed by the parser, but it is inert: scripts aren't processed, images aren't downloaded, and so on. The <template> element is not rendered.
			
			
		<element> - Custom Elements, support object oriented html element definition
			It specifies the type of element it's a refinement of using the extends attribute
			Behaviors & Attributes are defined inside <element>/<script>. 
			Operate DOM directly or use ShadowDOM to customize UI in ready callback
			
			
		ShadowRoot - See ShadowRoot.png
			ShadowRoot created & added via createShadowRoot(). Yonger ShadowRoot overrite older overrite original element
			These shadow DOM subtrees can be associated with an element, but do not appear as child nodes of the element.
			Shadow DOM can be applied to an element by calling the createShadowRoot method. This returns a ShadowRoot node which can then be populated with DOM nodes.
			An element with shadow DOM is called a shadow host. When an element has shadow DOM, the element's children are not rendered; the content of the shadow DOM is rendered instead.
			Special markup emelment:
				content - insert elements from overrited dom tree to current shadow dom tree
				shadow - insert hole overrited dom tree(older shadow tree) to current shadow dom tree
			Elements of the shadow DOM subtree are not exposed outside of the subtree, because Shadow DOM is a web component suppose to be developed sepratly without impact on other components
		
		
		<link rel="import" href="xxx.html"> - Import, to import custom elements & decorators from xxx.html	
	


**** web hook
Webhook
	user-defined HTTP callback

	Details:
		They are usually triggered by some event
			E.g. 
				pushing code to a repository
				a comment being posted to a blog
		When that event occurs, the source site makes an HTTP request to the URI configured for the webhook.
	
	Common Usage:
		trigger builds with continuous integration systems
		notify bug tracking systems


**** web package manage
Solution to manage web package(include js, css, img, dart ...) dependency, just like maven package dependency manage
	Implemented tools like:
		pub(dart), bower, jam, Component, Ender, Volo, npm(nodejs), gem(ruby) 




**** web service
SOAP
Simple Object Access Protocol
	It disregard many HTTP capabilities, e.g. authentication, caching, content type negotiation. Designer need to design these features. 


	
WADL
Web Application Description Language


WSDL
<definitions xmlns="http://schemas.xmlsoap.org/wsdl/" name="addPostService"
	targetNamespace="http://forum.hishark.com/common">
Attr name & targetNamespace below to xmlns:http://schemas.xmlsoap.org/wsdl/


xsd:import can import different namespace xsd. 

WSDL:
types - Define data type
message - Define wsdl message
portType - Contain wsdl operation (Just like a function library)
binding - Only defines how to do message transfer. 
service - Publish binding (Define address to access binding)


Axis generated Stub Class name will follow Service declare naming convention, 
while the method name will follow the operation name in portType

==============================================================================================================
<soap:binding transport="http://schemas.xmlsoap.org/soap/http"
			style="document" />:
Document: 
Directly put element,defined by part's element attr, in message body.

RPC:
Put operation name under body.
element,defined by part's name & type attr, will under operation.

use="literal" 
Parse message according to xsd.

use="encoded" 
Parse message according to enhanced protocol to xml schema.

==============================================================================================================
RPC WSDL Ex:
<message name="myMethodRequest">
    <part name="x" type="xsd:int"/>
    <part name="y" type="xsd:float"/>
</message>
<message name="empty"/>
<portType name="PT">
    <operation name="myMethod">
        <input message="myMethodRequest"/>
        <output message="empty"/>
    </operation>
</portType>


RPC Message Ex:
<soap:envelope>
    <soap:body>
        <myMethod>
            <x>5</x>
            <y>5.0</y>
        </myMethod>
    </soap:body>
</soap:envelope>


Document WSDL Ex:
<types>
    <schema>
        <element name="xElement" type="xsd:int"/>
        <element name="yElement" type="xsd:float"/>
    </schema>
</types>
<message name="myMethodRequest">
    <part name="x" element="xElement"/>
    <part name="y" element="yElement"/>
</message>
<message name="empty"/>
<portType name="PT">
    <operation name="myMethod">
        <input message="myMethodRequest"/>
        <output message="empty"/>
    </operation>
</portType>

Document Message Ex:
<soap:envelope>
    <soap:body>
        <xElement>5</xElement>
        <yElement>5.0</yElement>
    </soap:body>
</soap:envelope>



dataType.xsd
<?xml version="1.0" encoding="UTF-8" ?>
<xs:schema xmlns:xs="http://www.w3.org/2001/XMLSchema"
	targetNamespace="http://forum.hishark.com/common/schema" xmlns:tns="http://forum.hishark.com/common/schema"
	version="1.0">
	<xs:element name="Post" type="tns:PostType"></xs:element>
	<xs:element name="Status" type="xs:string"></xs:element>
	<xs:complexType name="PostType">
		<xs:sequence>
			<xs:element name="title" type="xs:string"></xs:element>
			<xs:element name="content" type="xs:string"></xs:element>
			<xs:element name="createDate" type="xs:dateTime"></xs:element>
			<xs:element name="lastModified" type="xs:dateTime"></xs:element>
		</xs:sequence>
	</xs:complexType>
</xs:schema>

addposts.wsdl
<?xml version="1.0" encoding="UTF-8" ?>
<definitions xmlns="http://schemas.xmlsoap.org/wsdl/" name="addPostService"
	targetNamespace="http://forum.hishark.com/common/wsdl" xmlns:soap="http://schemas.xmlsoap.org/wsdl/soap/"
	xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:tns="http://forum.hishark.com/common/wsdl"
	xmlns:datatype="http://forum.hishark.com/common/schema">
	<types>
		<xsd:schema>
			<xsd:import namespace="http://forum.hishark.com/common/schema"
				schemaLocation="dataType.xsd"></xsd:import>
		</xsd:schema>
	</types>
	<message name="addPostReq">
		<part element="datatype:Post"></part>
	</message>
	<message name="addPostRes">
		<part element="datatype:Status"></part>
	</message>
	<portType name="addPostPort">
		<operation name="addPostOp">
			<input message="tns:addPostReq"></input>
			<output message="tns:addPostRes"></output>
		</operation>
	</portType>
	<!-- Above contains all data and operation declare -->

	<!-- Below is used to bind the portType -->
	<binding name="addPostPortBinding" type="tns:addPostPort">
		<soap:binding transport="http://schemas.xmlsoap.org/soap/http"
			style="document" />
		<operation name="addPostOp">
			<soap:operation soapAction="" />
			<input>
				<soap:body use="literal"></soap:body>
			</input>
			<output>
				<soap:body use="literal"></soap:body>
			</output>
		</operation>
	</binding>

	<!-- publish binding -->
	<service name="addPostPortBindingService">
		<port name="addPostPortBindingServicePort" binding="tns:addPostPortBinding">
			<soap:address location="http://localhost:8080/wsdl" />
		</port>
	</service>


</definitions>



**** XaaS
X as a Service
	Contains:
		IaaS - Infrastructure as a Service
		PaaS - Platform as a Service
		SaaS - Software as a Service


**** XMPP
Extensible Messaging and Presence Protocol


When you authenticate to the XMPP server on your backend application (for example via a BOSH client in Django), you’ll receive two tokens, RID (request ID) and SID (session ID)

Connection Manager
	HTTP connections are stateless and usually shortlived. XMPP on the other hand, is the protocol that enables instant messaging, and its connections are stateful and usually longer.
	
	To enable a web application like Converse.js to communicate with an XMPP server, we need a proxy in the middle that can act as a bridge between the two protocols. 
	This is the job of a connection manager. A connection manager can be either a standalone application or part of an XMPP server. 
	ejabberd for example, includes a connection manager (but you have to enable it)
	
	BOSH
		a bridge between HTTP, the protocol of the web, and XMPP, the instant messaging protocol.
		

OTR
	Off-the-record
	
	OTR protocol not only encrypts your messages, it provides ways to verify the identity of the person you are talking to, plausible deniability and perfect forward secrecy by generating new encryption keys for each conversation.
	

**** authentication
# Authentication

## Base
Identity and Feature have relation.  
i.e. Identity = f(Feature), Feature = g(Identity)

## Impl
Find Identoity from Feature



**** self-similarity
self-similarity
	component sub-part have same structure as component itself
	
	E.g.
		list
		    con + element + list
		stream
		    con + element + delay + stream

**** Application Cache
Used to support offline application

Steps:
	1, Add manifest on html tag
	2, Add corresponding gplatform.appcache
		Example:
	        CACHE MANIFEST
	        # v1 2013-11-27
	        *

	        NETWORK:

	        FALLBACK:

	3, Register type:text/cache-manifest for manifest file if your server not support
		Example for httpd:
            AddType text/cache-manifest                         appcache manifest



**** REST
Representational State Transfer - a software architecture style
	Different from service oriented architecture(SOA), it's resource oriented architecture(ROA)
	A set of architectural guidelines:
		Client–server - REST-style architectures conventionally consist of clients and servers
			Clients initiate requests to servers, servers process requests and return appropriate responses
			Requests and responses are built around the transfer of representations of resources
				A resource can be essentially any coherent and meaningful concept that may be addressed,  they are conceptually separate from the representations
					E.g. Customer Address Info
				A representation of a resource captures the current or intended state of a resource(represent the resource)
					E.g. HTML, XML or JSON
		Stateless - no state info in server side
		Cacheable - Responses must therefore, implicitly or explicitly, define themselves as cacheable, or not, to prevent clients reusing stale or inappropriate data in response to further requests
		Layered system - Server & client should not care about the connection between them
		Code on demand (optional)
		Uniform interface
			Identification of resources
				Individual resources are identified in requests, for example using URIs in web-based REST systems. 
			Manipulation of resources through these representations
				Manipuate resource via it's representations(E.g. HTML XML JSON)
			Self-descriptive messages
				Each message includes enough information to describe how to process the message. For example, which parser to invoke may be specified by an Internet media type (previously known as a MIME type). Responses also explicitly indicate their cacheability.
			Hypermedia as the engine of application state (A.K.A. HATEOAS)
				Clients make state transitions only through actions that are dynamically identified within hypermedia by the server (e.g., by hyperlinks within hypertext). Except for simple fixed entry points to the application, a client does not assume that any particular action is available for any particular resources beyond those described in representations previously received from the server.
		
		Avoid "re-invention of the wheel" (I think this should also be one of the mandatory guidelines)
			Maximize the use of the existing, well-defined interface and other built-in capabilities provided by the chosen network protocol
				E.g. 
					Operations defined in HTTP protocol: GET, POST, PUT, PATCH, DELETE
					HTTP Authentication
					HTTP caching
					HTTP content-type negotiation
			Minimize the addition of new application-specific features on top of it
				E.g
					Application defined operations, which supplant HTTP operations, like: getCustomerInfo, updateAddress, deletePhone		
	
	
	We can say one system is REST architectural style(RESTful), if it conforming to above 6 + 1 guidelines.
	
	REST was initially described in the context of HTTP, but it is not limited to that protocol. It may be based on other Application Layer protocols if they already provide a rich and uniform vocabulary for applications based on the transfer of meaningful representational state


REST Web Service
	Use some REST guidlines(transport part) to implement SOA application. 



**** restful object
Restful Objects
	A public specification of a hypermedia API for domain object models
	
	Different to JAXRS
		JAXRS help in abstracting away pure network issues, they don't ensure any uniformity in the structure of the resources defined to interact with different types of domain object.
		JAXRS provide no support for what is arguably the most important principle of RESTful systems: "hypertext as the engine of application state", or HATEOAS.
		
	Different to OData
		Odata is really targeted to CRUD (Create, Read, Update, Delete) functionality
		Restful Objects provides access to the full behaviour (the methods) of the objects
		
	Frameworks that implement the Restful Objects spec:
		don't just make the task of writing a HATEOAS-conformant API to a domain object model easier - they actually eliminate the work altogether
		
	URL specification:
		/objects - 
		/services - singleton objects such as repositories and factories that have methods but no properties
		/domain-types - type metadata
		
	Resource Taxology:
		Object resource
		Object Property resource
		Object Collection resource
		Object Action resource
		Object Action Invoke resource


**** container
Container - A component which can hold reference to other component
	JVM is also a Container, since it hold all Objects' reference.
	Spring is a Container it can hold reference to other Object, so that Objects can be managed/processed.

**** Execution Context
Execution Contexts:
	Application Context
	Session Context
	Transaction Context
	Request Context
**** asynchronous io
Asynchronous I/O (also named non-blocking I/O) - A form of I/O processing that permits other processing to continue before the I/O processing has finished.
    I/O processing is extremely slow compared to data processing

**** event loop
Event Loop - A programming structure.

**** authenticate
Check Something is true or false

	When Authentication used in session, normal case is:
		Something - Client is the Session owner
		Check - Client show Session ID to Server to verify

	When Authentication used in normal login, normal case is:
		Something - Client is xxxxxx
		Check - Client show Credential to Server to verify

	When Authentication used in oauth login, normal case is:
		Something - Client is xxxxxx from Provider
		Check - Client ask Provider to give access to his Provider Account so that Server can retrieve his Provider Account name

**** CORS
Cross-Origin Resource Sharing
	Browser will only send & process cookies when XMLHttpRequest.withCredentials = true, but if server disallow credential (Access-Control-Allow-Credentials:false), the browser will error the request.

	It's better to give this job to dedicated filter

	Android WebKit browser will only read last same name header, so can not use SS to config the CORS, as it will separate multiple header values

**** CRLF
CRLF - Carriage Return & Line Feed
	CR is char "\r", LF is char "\n"
	Used to start a new line
		In windows:
			Use CR + LF
		In Unix/Linux:
			Use LF
		In Mac:
			Use CR


**** DB migration
DB Migration
	The core task is to do change merge.
	
	Parallel Changes base on DB Base Version:
		- changes done by dev
		- changes done by runtime
		
	Merge Approach:
		1, Extract changes done by runtime & apply onto changes done by dev
			Seems not possible as:
				a, some DB can only extract data to binary
				b, the changes done by runtime can be very huge
		2, Extract changes done by dev & apply onto changes done by runtime

**** Domain-Driven Design

**** design
性 -> expectation -> how(Design)


Design - a roadmap or a strategic approach for someone to achieve a unique expectation.
	Incarnation can be:
		Process
		Structure


	Describe Design
		Use different View to describe Design, so that different stakeholder can focus on different part of the Design.
		
	
	Naming
		Name is highest abstract of FUNCTION
	
		From name to implementation
			Steps:
			1, Give name
			2, Give functionality boundary and communication boundary base on name
			
	RSA Steps:
		Requirement Model(Use Case Diagram) -> Sketch(Note a Model) -> Deployment Model(Software & Hardware) ->  Domain Model
																														Static Model(Class Diagram)
																														Dyna Model(Sequence Diagram)

	Pattern to solve problem via program:
		1, Find Solution for problem
		2, Simulate the Solution via program
			So the program/algorithm should focus on the solution(process), not the final result





Many framework/application design prefer to make system start from loading config.
	Spring start from load bean-context.xml
	Angular start from load Module declared in ng-app
	
It's better to have env.properties to maintain env related config, because evn related config should be limited, been to seprate it from application functional config

I prefer to use spring profile to support different env, so it can be switched directly without rebuild

If name is not the function's core, it's a bad design





**** design pattern
Design Pattern is a structure(relation,communication,behavior...). 
	When we apply this structure to software design, we structure software components. 
	We can structure software components without interface, only shortcoming is that component in the structure is not easily replaced.
	


**** hexagonal architecture
Derive from HCLC (refer to HighCohesionLooseCoupling.txt)

Alternative name: Ports & Adapters

	Port
		a technology-independent protocol capturing a reason for a discussion
	
	Adapter
		mapping that protocol to different external technologies
		
		
OUTSIDE <-> transformer <--> ( application  <->  domain )

Each face of the hexagon represents some "reason" the application is trying to talk with the outside world. This is why it is concentric hexagons and not concentric circles

**** exchange
Exchange
	A data exchange model
	
	Details:
		Request
			Logical Request can can be represented by multiple request object(new request can wrap old request)
			Request Scope should precisely named Logical Request Scope
		Response
	
	base model for tech:
		Servlet
		Web Socket
		FTP
		BS
			Server have States
			Browser show & submit States
		CS
		...


**** expression
	sequence of operants and operators

**** FHS
Filesystem Hierarchy Standard
	?How to mount & organize different Filesystems in a tree

	two independent distinctions among files:
		shareable vs. unshareable
		variable vs. static
	
		Shareable
			can be stored on one host and used on others
			E.g.
				files in user home directories
		Unshareable
			not shareable
			E.g.
				device lock files
				
			Note:
				not all files in the filesystem hierarchy are shareable and so each system has local storage containing at least its unshareable files
				It is convenient if all the files a system requires that are stored on a foreign host can be made available by mounting one or a few directories from the foreign host.
				
		Static
			do not change without system administrator intervention
			E.g.
				binaries, libraries, documentation
		Variable
			not static
			
			Note:
				Static and variable files should be segregated because static files, unlike variable files, can be stored on read-only media and do not need to be backed up on the same schedule as variable files.
		
		
	Root Filesystem
		The contents of the root filesystem must be adequate to boot, restore, recover, and/or repair the system
			boot a system
				enough must be present on the root partition to mount other filesystems
				This includes utilities, configuration, boot loader information, and other essential start-up data.
				
				/usr, /opt, and /var are designed such that they may be located on other partitions or filesystems.
			recovery and/or repair of a system
			restore a system
			
		Applications must never create or require special files or subdirectories in the root directory.
			There are several reasons why creating a new subdirectory of the root filesystem is prohibited:
				It demands space on a root partition which the system administrator may want kept small and simple for either performance or security reasons.
				It evades whatever discipline the system administrator may have set up for distributing standard file hierarchies across mountable volumes
	
		Root Directory Description
			required:
				bin - Essential command binaries
					which are required when no other filesystems are mounted
					There must be no subdirectories in /bin
				boot - Static files of the boot loader
					contains everything required for the boot process except configuration files not needed at boot
					time and the map installer. Thus /boot stores data that is used before the kernel begins executing user-mode
					programs. This may include saved master boot sectors and sector map files.
				dev - Device files
				etc - Host-specific system configuration
					etc/opt
				lib - Essential shared libraries and kernel modules
					contains those shared library images needed to boot the system and run the commands in the root filesystem
				media - Mount point for removeable media
					Although the use of subdirectories in /mnt as a mount point has recently been common, it conflicts with a much older tradition of using /mnt directly as a temporary mount point.
				mnt - Mount point for mounting a filesystem temporarily
				opt - Add-on application software packages
					/opt/bin, /opt/doc, /opt/include, /opt/info, /opt/lib, and /opt/man are reserved for local system administrator use
				sbin - Essential system binaries
					Utilities used for system administration (and other root-only commands)
				srv - Data for services provided by this system
					One method for structuring data under /srv is by protocol, eg. ftp, rsync, www, and cvs.
				tmp - Temporary files
				usr - Secondary hierarchy
				var - Variable data
					var/opt
			required if the corresponding subsystem is installed:
				home - User home directories (optional)
					it is clearly a site-specific filesystem. The setup will differ from host to host. Therefore, no program should rely on this location.
				lib<qual> - Alternate format essential shared libraries (optional)
				root - Home directory for the root user (optional)
				
				
	/usr Hierarchy
		/usr is shareable, read-only data. 
			That means that:
				/usr should be shareable between various FHS-compliant hosts 
				must not be written to
		/usr/local - Local hierarchy
			use by the system administrator when installing software locally. It needs to be safe from being overwritten when the system software is updated.
		/usr/share - Architecture-independent data
	
	
	
	/var Hierarchy

**** model
Domain Model (refer to miaoshu.txt, world.txt)
	Describe Problem Domain's Entity's State & Behavior

	Domain - Problem Domain
		real-world Problem Domain, outside of software (in the context without awareness of any tech stuffs)
		It may contains different Entity 
		
	Entity (Refer to shijie.txt)
		State
		Behavior
			Input
			Output
			Process
	
		Note:
			This Model see the world start from YingYang so it put BianHua inside YingYang, but in fact they are equal
			Entity - YingYang
			State - Description of YingYang, include the Linkage to BianHua
			Behavior -  BianHua
	
	Domain Object
		Represent Domain Model (refer to miaoshu.txt)

	GUI(presentation) is also to solve problem, but it's not Domain Problem, it is Application Problem(UI(Input/Output) in Domain Model is hard to use)
		GUI seems like a Adaptor between human & DomainModel Input/Output(UI)
		as:
			Domain Problem can be resolved even without gui
			it specific to tech : graphic
			

ViewModel (same as Presentation Model)
	Describe View's State & Behavior
**** FileSystem
VFS(Virtual File System / Virtual Filesystem Switch)
	Contains:
		superblock object
		inode object
		dentry object
		file object


File:
	Everything is File in Linux
		Folder is a special File, which contain other file names
		Linux take Device as File also.

	Contains:
		User Data (data block) - Real file content
		Metadata - File attributes, like: inode number, size, ower, last modified...
			Inode (index node)
            	It will be created by core, when new file created
            	A folder contains pointers point to Inode
            	Copy, move, delete operations only apply to pointers

	Category:
		Normal File
		Folder
		Link
			Category:
				Hard Link
	                A File, share same inode with source File
	                Command:
	                    link oldfile newfile
	                    ln oldfile newfile

	                Can only create on Normal File
	                Folder . & .. are Hard Link

				Soft Link(Symbolic Link)
					A File, have different inode. Data block contains source file's path info
					Command:
						ln -s old.file soft.link

			Refer to:
				HardLinkAndSoftLink.jpg


	Note:
		Storage of file is flat, folder structure is just a logic concept, concept info maintained in directory file.

**** firewall
Firewall
	network security system that monitors and controls the incoming and outgoing network traffic based on predetermined security rules
	
	
	iptables
		Linux Firewall
		Interface:
			firewalld
			ufw
		
 
**** program tree
program logic is orgnized like a tree

Normally leafs/subtree are abstractions, as they are api calls

Only Tree Owner can master the tree, as even abstraction parts are under control(can be replaced)


NOTE:
framework/IoC introducted means that you give up Tree Owner
explicit-over-implicit means you are the Tree Owner


**** IoC
IoC (Inversion of Control)
	It's a architecture style
	Base on binding, framework calls custom-written logic rather custom-written logic calling the framework. 
	This phenomenon is Inversion of Control (also known as the Hollywood Principle - "Don't call us, we'll call you")

DI (Dependency Injection)
	This is a concrete tech, can used to help impl IoC style
	Field not bee initialized by ur self, container will inject it for u by invoke setter method.
**** IDE
Integrated Development Environment
	You can operate all resources(files, tools and so on) in single interface, to avoid synchronize issue when you operate same thing from different interface
**** flash of unstyled content
flash of unstyled content - web page appears briefly unstyled prior to loading an external CSS stylesheet
	This is due to the web browser engine rendering the page before all information is retrieved
**** integration
系统内部消息传递一般通过普通方法调用。 
系统与系统之间消息传递受限于技术无法通过普通方法调用，所以需要集成解决方案。
**** interface
Java Interface maintain description of Conceptual Interface.

Java Interface is only a place holder not a component.
It's introduced only to make switch of IMPL without code change.

Program (on interface perspective) have 2 parts:
	Own logic - Hard code
	Invocation of sub-system(Other class' method) - Better to invoke interface of sub-system instead of impl


interface impl can be changed easily, so that no need to change a lot of code to invoke new sub-system. 
	
**** generic programming
A style of computer programming
	Algorithms are written in terms of to-be-specified-later types that are then instantiated when needed for specific types provided as parameters.
	
**** info architecture
Info Architecture
	Identify Mother Info & put them in one place
	All other Info are derived from Mother Info
	
**** enterprise application
Enterprise Application
	Features		---		Supported JavaEE API		---		Supported Spring API
		Session		---		WebContainer Session(Only support via Servlet)		---		Scope=Session
		Port		---		JCA		---		Spring Integration
			HTTP Interface		---		Servlet		---		MVC Annotation
				REST		---		JAXRS		---		Spring HATEOAS
			DB Access		---		JDBC, JPA		---		Spring Data
			Message		---		JMS		---		AMQP
		HTML		---		JSP		---		Templates
		Transaction		---		JTA		---		Transaction Annotation
		Authentication & Authorization		---		JAAS		---		Spring Security
		HA		---		Cluster		---		NA
		
**** doc modular
To reuse some definition, something definitions, named abstract operation/symbol, are used in ECMAScript Specification.

Martin Flower's common format:
	Title
	Main Success Scenario
	Extension

**** homoionic
Homoiconicity
	Same icon
		PIR(Program Internal Representation)'s structure = PER(Program External Representation)'s structure
		So that, developer can manipulate PIR via program
		Normally PIR is Source, PER is AST


	additional meaning in homoiconic languages:
		PIR is a language type


	Homoiconic Language Advantage:
		Additional expressiveness provided via code generation, preprocessor, compiler plugins to non-homoiconic language
		can simply achieved via runtime PIR manipulation in homoiconic language

**** logging
Logging System Contains:
	Log Facade
		E.g.
			JCL(Jakarta Common Logging), SLF4J
	Log Impl
		E.g. 
			log4j, logback, JUL(Java Util Logging), timbre


Normally Logging System will be initialized when first invoke getLogger()
	So when need to support dyna config at runtime, we may need to re-init it
	Normally logging data are maintained in Class field, so different ClassLoader can have multiple logging data
	
	
MDC - Mapped Diagnostic Context
	To uniquely stamp each request, the user puts contextual information into the MDC, the abbreviation of Mapped Diagnostic Context.
	The MDC manages contextual information on a per thread basis
	A child thread automatically inherits a copy of the mapped diagnostic context of its parent.

**** model driven view
MDV - Model Driven View
	Watch Model Change to update View or Observe DOM(View) Change to update Model
	View is to present Model's data, so the Model Change here scope to Model's data change.
	Model's data can be:
		data retrieved from attribute
		data retrieved from method
	Model's data can be identified by its retrieve expression
	We know attribute change will impact on data retrieved from attribute
	We don't know what will impact on data retrieved from method, the data retrieved from method may different with NO change on the Model
	
	
	Implement:
		1, Bind a Model to a View
		2, Use {{retrieve expression}} to identify Model's data which need to be watched
		3, Create Watcher & MutationObserver for above Model's data
			Watcher
				Watch Model Change & Contains a Handler
					Handler - Update DOM(View) when Model Change occurs
					
				Use expression inside {{}} to retrieve & store data, any possible impact on the retrieve will trigger new evaluate of retrieve expression & compare.

			
			MutationObserver
				Observe DOM(View) Change & Contains a Handler
					Handler - Update Model when DOM(View) Change occurs


**** messaging
Messaging Model
	Listen
		attach a voice device to target
	Monitor
		keep look at

**** metadata
Data used to discribe data

**** mvcc
MVCC - multi-versioned concurrency control
	a concurrency scheme popular with relational databases and other data stores
	
	Impl in Infinispan
		Reader threads do not acquire explicit locks
		Writers need to acquire a write lock
		
		To allow concurrent reads, writers make a copy of the entry they intend to modify, by wrapping the entry in an MVCCEntry
			This copy isolates concurrent readers from seeing partially modified state.
			Once a write has completed, MVCCEntry.commit() will flush changes to the data container and subsequent readers will see the changes written.
		
		Isolation
			Via Different MVCCEntry impl, have different behaviour in how state is committed back to the data container

**** mvvm
MVVM - Model-View-ViewModel
	A design pattern
	Also described as MVB(Mode-View-Binder) 
	Contents:
		Model - Same as M in MVC
		View - Same as V in MVC
		ViewModel - model of the view
			It mainly to model the view's data source perspective

**** naked objects
Naked Objects
	an architectural pattern
	
	Similar to Separated Presentation architecture
		but:
			Presentation is auto generated
			Data flow:
				Input -> View -> Domain Model
				Output -> Domain Model -> View
		
	viewing and manipulating the 'naked' business domain objects
	
	Domain Model:
		All required business functionality must therefore be encapsulated on the domain objects
		the only way that the user can initiate action is by invoking a behaviour on a business object
	
	Presentation:
		domain objects are rendered visible to the user by means of a completely generic presentation layer or 'viewing mechanism'
		automatically generated object-oriented UI, constructed at runtime from the domain model.
		This isn't compile-time code generation scaffolding, it's building a metamodel on-the-fly at runtime.
		lets the objects present themselves to the user in a standardized way.
		The idea of auto-generating a user interface from an underlying business model definition is not new
			E.g.
				several fourth-generation languages
				W3C Xforms
				device-independent User Interface Mark-up Language
			all these technologies are strongly data-oriented rather than object-oriented
		user interface is strongly object-oriented (OOUI)
		
	Naked Objects framework
		provide two capabilities:
			implementation of the generic presentation layer (i.e. a set of classes that fulfil the roles of View and Controller in an MVC architecture)
			generic presentation layer identifies the domain objects and their behaviours, in order to render them available to the user
		
		
	Support the idea of business process
		distinguishing two broad categories or stereotypes of entity object: 'purposeful' and 'non-purposeful'
		non-purposeful object
			state of the object is defined implicitly by the agglomeration of its various attributes and associations
			state changes do not advance in any particular direction
		purposeful object
			state of the object is defined explicitly
			often represented by a single field that can take one of a finite set of pre-determined values
			state generally changes in a pre-ordained direction
		
		
		
		
		
		
**** network
3 connection type:
    Bridged
    NAT
    Host Only

**** OASIS
OASIS (Organization for the Advancement of Structured Information Standards)

**** OSI Model
OSI Model
	Open Systems Interconnection model
	Characterizes and standardizes the internal functions of a communication system by partitioning it into abstraction layers
	
	
**** OSS
Deploy:
	Deploy snapshot artifacts into repository https://oss.sonatype.org/content/repositories/snapshots
	Deploy release artifacts into the staging repository https://oss.sonatype.org/service/local/staging/deploy/maven2
Promote staged artifacts into repository 'Releases' - this release repo will sync to central repo

Download:
	Download snapshot and release artifacts from group https://oss.sonatype.org/content/groups/public
	Download snapshot, release and staged artifacts from staging group https://oss.sonatype.org/content/groups/staging

**** page object

Page Object pattern represents the screens of your web app as a series of objects
	PageObjects can be thought of as facing in two directions simultaneously. 
		Facing towards the developer of a test, they represent the services offered by a particular page. 
		Facing away from the developer, they should be the only thing that has a deep knowledge of the structure of the HTML of a page
		
	methods on the PageObject should return other PageObjects.
	
	
	PageFactory
		In order to support the PageObject pattern, WebDriver's support library contains a factory class
		
	
**** persevere
Composed of various components including Pintura, Pintura represents a simplification of Persevere

Pintura is server side javascript based framework


**** platform
A computing platform
	A Context (refer to Context.txt)
	pre-existing environment
		where a piece of software is designed to run within, obeying its constraints, and making use of its facilities. 

	Typical platforms include
		a hardware architecture, 
		an operating system (OS), 
		and runtime libraries.
		
	2 kinds of software run on platform:
		SP(service provider)
		SC(service consumer)

**** parse
Parse
	Translate data format from plain to structure so that the code can use
	
	The result is usually a tree
	
	2 sub processes:
		Lexical Analysis
			Convert input into tokens(valid language vocabulary) base on Vocabulary definition
			
			Vocabulary is usually expressed by regular expressions
			Normally done by Lexer
			Flex can create Lexer
			
			
		Syntax Analysis
			Convert tokens into structure base on Syntax Rules
			
			Syntax Rules  is usually expressed in BNF
			Normally done by Parser
				2 types of parsers: top down parsers and bottom up parsers
			Bison can create Parser
			
**** pattern
Pattern - A model considered worthy of imitation

**** overload
overloaded operator have a meaning depends on the type of operants

**** port forwarding
Port Forwarding Program
	Listen on From Port
	Forward requests to To Port


**** Request for Comments
Request for Comments
是一系列以编号排定的文件。文件收集了有关互联网相关信息，以及UNIX和互联网社区的软件文件。

**** bypes
byte 2 int:(add "0" or "1" according the high bit)

00000001---------->0000000000000000000000001
10000000---------->1111111111111111110000000


int 2 byte:(Directly cut the unnessary bits)

000000000000000000000001-------->00000001
1111111111111111101111111------->01111111

What's negative? How to define?



Generally speeking, that negative is a number which contain a sign '-', but that just like a language, actually negative is something contains the negative's specific character and it's behavior.

So complement code ignore the language(a sign '-'), focus on the negative's essence, and find another language in computer to express it.

Sometimes we should focus on the essence not on the outside.

**** process an thread
Process
	A series of things
	
	Those things can be happened or not yet happen.
	Those things can be dynamic base on Context

	Internal Process
		Categories:
			Process in procedure call(this will be executed right now)
			Process in procedure definition(this will be executed late)
			
		Execution effect of these two kind of Process is the same, as procedure execution context is its definition context.
		
	A set of similar Processes can be expressed by Procedure, as Procedure can have different arguments applied.
	
	
	Procedure (Refer to: 多层系统结构.txt)
		Normal Procedure contains Combination process
		E.g.
			return process to combine current process with next process
		
	
	Procedure Application
		normal procedure application
			Start Procedure Application -> Applied Procedure -> End Procedure Application
			
			Start Procedure Application
				setup anchor
				
			End Procedure Application
				 go on  target state change & combination(flow) control
			
			
		Tail Procedure Application Optimization
			Optimization for the case that last expression of a procedure is a procedure application
			
			Details:
				Tail Procedure Application NOT setup anchor, as NO additional target state change & combination(flow) control required
				Caller Procedure contains NO Combination process
				
				tail recursion optimization is kind of Tail Procedure Application Optimization


Process - A group of related resource.
    This group of resource can support program execution
    Contains:
        at least one Thread, often called the primary Thread
        a virtual address space
        executable code
        open handles to system objects
        a security context
        a unique process identifier
        environment variables
        a priority class
        minimum and maximum working set sizes

Thread - An entity within a Process that can be scheduled for execution
    Share:
        Stuffs in Process

    Contains:
        exception handlers
        a scheduling priority
        thread local storage
        a unique thread identifier
        a set of structures the system will use to save the Thread Context until it is scheduled
            Thread Context includes:
                the thread's set of machine registers
                the kernel stack
                a thread environment block
                a user stack in the address space of the thread's process
        can also have their own security context, which can be used for impersonating clients.

**** OAuth
OAuth is an open standard for authorization
	It's using valet key pattern
		Resource - Map to luxury car
		User - Map to luxury car owner
		
		OAuth Service Provider - Map to luxury car's management system
		Application - Map to valet
		
		User Name & Password - Map to normal key
		Token - Map to valet key
	
	Details:	
		OAuth is not about Single Sign-On
		OAuth is mainly about authorization
		It is about letting the user to control how their resources may be accessed by third-parties.
		OAuth Service Provider authorize third-parties to access resources under owner's grant
		
	OAuth1 Workflow
		1, The flow starts with the application asking for a request token. The purpose of the request token is to obtain user approval and it can only be used to obtain an access token. In OAuth 1.0a, the consumer callback URL is passed to the provider when asking for a request token.
		2, The service provider issues a request token to the consumer.
		3, The application redirects the user to the provider's authorization page, passing the request token as a parameter. In OAuth 1.0, the callback URL is also passed as a parameter in this step.
		4, The service provider prompts the user to authorize the consumer application and the user agrees.
		5, The service provider redirects the user's browser back to the application (via the callback URL). In OAuth 1.0a, this redirect includes a verifier code as a parameter. At this point, the request token is authorized.
		6, The application exchanges the authorized request token (including the verifier in OAuth 1.0a) for an access token.
		7, The service provider issues an access token to the consumer. The "dance" is now complete.
		8, The application uses the access token to establish a connection between the local user account and the external provider account. With the connection established, the application can now obtain a reference to the Service API and invoke the provider on behalf of the user.
				
	OAuth2 Workflow
		1, The flow starts by the application redirecting the user to the provider's authorization URL. Here the provider displays a web page asking the user if he or she wishes to grant the application access to read and update their data.
		2, The user agrees to grant the application access.
		3, The service provider redirects the user back to the application (via the redirect URI), passing an authorization code as a parameter.
		4, The application exchanges the authorization code for an access grant.
		5, The service provider issues the access grant to the application. The grant includes an access token and a refresh token. One receipt of these tokens, the "OAuth dance" is complete.
		6, The application uses the AccessGrant to establish a connection between the local user account and the external provider account. With the connection established, the application can now obtain a reference to the Service API and invoke the provider on behalf of the user.
		
**** ODM
ODM - Object Datasource Mapping
	Mapping data from an Object Model Representation to a Datasource sepecific Model Representation
	
	Here Datasource can be anything
	Here Object is normally POJO
	E.g.
		ORM - Object Rational Mapping
			Supported by JPA
		OXM - Object XML Mapping
			Supported by JAXB
		OJM - Object JSON Mapping
			Supported by Jackson
		O?M - Object ? Mapping
			Supported by JDO, normally here ? limited to persist stuff  
			Supported by SDO, normally here ? can be any thing: like: DB, EJB, WS, JCA
**** MIME
MIME(Multipurpose Internet Main Extention)
It's a protocol. It used to make stand mark for different type of data.

Use this we can open different type of data by useing according application.







**** different programs & protocal


***** redis
Redis
	Redis is key-value store
	
	primary feature: networked, in-memory, optional durability




***** OS

Operating System
	software that 
		manages computer hardware
		provides common services for computer programs


##System Image
a copy of the entire state of a computer system stored in some non-volatile form such as a file.



****** android
Development Platform:
	Android SDK
		SDK Tools
		Android Platforms
		SDK Platform-tools
	ADT plugin for Eclipse


Debugging
	Refer to debugging.png
	adb - Android Debug Bridge(ADB Host deamon in SDK & ADB device deamon in Device)
		By default ADB Host deamon will find & connect to ADB device deamon in all USB connection
		By default ADB device deamon will listen on USB connection
		adb devices - check available devices
		Wireless usage:
			Change ADB device deamon to listen on TCP/IP connection instead of USB connection
				Connect the device to the host computer with a USB cable
				Set the target device to listen on TCP/IP connection on port 5555
					adb tcpip 5555
				Disconnect the USB cable from the target device
			ADB Host deamon to connect to ADB device deamon via TCP/IP connection
				Connect to the device, identifying it by IP address
					adb connect <device-ip-address>

Program:
	Android Program is a set of Intent & Activity & Service
	
	Activity:
		Invoke View
		Registered in AndroidManifest.xml
		Bind to Intent 
		Lunch Model:
			standard - create new instance for every Intent
			singleTop - Single instance on Stack top. 
			singleTask - Single instance in Stack. (May be pop out)
			singleInstance - Single instance in Separate Stack. (Can NOT be pop out)
			
	Intent:
		Intent Types:
			Explicit Intent
				Directly specify target comp(Activity/Service) name. Nothing to do with IntentFilter. 
			Implicit Intent
				Resolved by IntentFilter
				
		Intent Resolve:
			For Explicit Intent, just find the comp base on name in Intent.
			For Implicit Intent, 
				When startActivity() is called, the system examines all of the installed apps to determine which ones can handle this kind of intent. 
				If there's only one app that can handle it, that app opens immediately and is given the intent. 
				If multiple activities accept the intent, the system displays a dialog so the user can pick which app to use.
	
	Service:
		A component that performs operations in the background without a user interface

Project Structure:
		
	src
		java source
	
	gen
		Generated java code
		R.java
			Maintain all Resources Id info
				
	asset
		Contains Asset
	
	bin
		Compiled binary
	
	libs
		Dependency jar
	
	res
		Contains Resources
		
		layout
			Contains Layout/View
			
		xml
			Contains arbitrary xml

	AndroidManifest.xml
		project core config

****** linux
People -> shell -> kernel -> hardware


MBR(First 512B of disk):
	000-162 MBR Boot Record
	162-1BD MBR Data
	1BE-1CD DPT 1
	1CE-1DD DPT 2
	1DE-1ED DPT 3
	1EE-1FD DPT 4
	1FE-1FF 55AA
	
	
Several MBR Boot Record there, grub is one of them.

Folder Content:
	Refer to FHS.txt

mount
	connect content of a device(a file under /dev) to a dir
	

Basic setups:
  install chinese fonts to show chinese char in browser:
   sudo apt-get install ttf-wqy-zenhei ttf-wqy-microhei fonts-arphic-ukai fonts-arphic-uming
	create internet connection - configed during OS install
	Software Manage:
	    Manager:
            dpkg - the base for other installer (if "sudo dpkg -i xxx" failed due to miss dpes, use "sudo apt-get install -f" to resolve deps)
            apt-get - resolve dependency(i.e. sudo apt-get -f install) before invoke dpkg
            Synaptic, Software Center - GUI
        install software
            sudo yum install xxx
            sudo apt-get install xxx
        list software
            Debian Packager:
                dpkg --list
	mount cdrom - mount /dev/cdrom /mnt/cdrom

  share folder in vmware
    wmware-hgfsclient - show the shared folders
    install vmware tools to mount shared folders under /mnt/hgfs
      Manage -> Install VMware Tools
      mount /dev/cdrom /media/cdrom
      tar -xf /media/cdrom/VMwareTools-10.1.6-5214329.tar.gz
      sudo ./vmware-install.pl

	add user to group
		usermod -g ${group name} ${user name}
	
	startup model
		/etc/inittab

	ssh pasword free login
		generate key pair in client (~/.ssh/id_rsa, ~/.ssh/id_rsa.pub):
			ssh-keygen -t rsa
		add client's public key(~/.ssh/id_rsa.pub) to server's authorized_keys (~/.ssh/authorized_keys)


Network interface config: (/etc/network/interfaces)
# static config
auto p6p1
iface p6p1 inet static
address 192.168.31.100
netmask 255.255.255.0
broadcast 192.168.31.255
gateway 192.168.31.1
dns-nameservers 192.168.31.1
# get config from dhcp server
auto p6p1
iface p6p1 inet dhcp

Interface start & down:
ifdown p6p1
ifup p6p1

Runlevel is a mode of operation in one of the computer operating systems that implement Unix System V-style initialization.
    A runlevel defines the state of the machine after boot.
    Runlevel in LBS:
        0	Halt	Shuts down the system.
        1	Single-user mode	Mode for administrative tasks.[2][b]
        2	Multi-user mode	Does not configure network interfaces and does not export networks services.[c]
        3	Multi-user mode with networking	Starts the system normally.[1]
        4	Not used/user-definable	For special purposes.
        5	Start the system normally with appropriate display manager (with GUI)	Same as runlevel 3 + display manager.
        6	Reboot	Reboots the system.


X Window System(refer to X Window System.gif)
    XServer:
        install(xorg impl): sudo apt-get install xserver-xorg 
          (xserver-xorg-core not work, even client connected it still only show black screen, I even can not switch tty
          If need to use java awt, graphics related native libs need to be installed via "sudo apt-get install xorg")
        start: sudo X
        verify: U can see xserver screen turn to black
	Note: to enable different user access xserver, u need to disable access control via xhost
	When use XServer via ssh tunneling, X11 forwarding, ssh client will auto set variable DISPLAY in the tty to a local(xclient server) display, it will redirect this local display to remove(xserver server) display.

    XClient:
        export DISPLAY=$server_address:$display_number.$screen_number(if same server value is: ':0')
        start application
        u will see UI display in xserver's screen
        

Window Manager
  An XClient, used to manage windows.
  E.g.
    openbox
  

GCC
  GNU Compiler Collection
  

build-essentials
  contains several software for build debian package:
    gcc - c compiler
    g++ - c++ compiler
    libc6-dev - gnu c library
    make
    dpkg-dev - debian package development tools
    
****** BIOS
Start from BIOS
	Check Hardware
	Find Startable MBR(end with "55AA") in all disks
	Execute BootLoader in above MBR

****** windows
partition
    primary partition{1-4}
    extended partition{0-1}(can not directly use)
        logical partition

***** DB
DB
	It need to make sure any record at any time have only one value.

****** MySQL

Install Manually:
	1, change my-default.ini to give below values:
		basedir = C:/Users/shark/Desktop/mysql-5.7.15-winx64
		datadir = C:/Users/shark/Desktop/mysql-5.7.15-winx64/data
	2, install & register service: 
		mysqld --install mysql --defaults-file=C:/Users/shark/Desktop/mysql-5.7.15-winx64/my-default.ini
	3, initialize:
		mysqld --initialize

Uninstall:
	mysqld --remove mysql

Startup:
	net start mysql
	

Client connect, change password, create database, user:
	1, find temp password in: mysql-5.7.15-winx64\data\DESKTOP-GSOVQ5C.err
	2, login: mysql -u root -p
	3, change password: ALTER USER 'root'@'localhost' IDENTIFIED BY 'shark';
	4, create database: CREATE DATABASE shark_db DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;
	5, create user: CREATE USER 'shark'@'localhost' IDENTIFIED BY 'shark';
		Note:
			use: 'shark'@'%' to allow remote access
	6, grant: GRANT ALL ON *.* TO 'shark'@'localhost';



****** oracle
server process (Network service)
	Enable external app request router to DB instance .
	related config: listener.ora,sqlnet.ora,tnsnames.ora 
	
	
Sqlplus directly connect to DB instance without go through server process.

***** middleware
Middleware
	Software in the middle of Softwares
	
	Definition from wiki (I don't agree):
		a computer software that provides services to software applications beyond those available from the operating system


****** application server
Modern Application Server 
		Divide server to (Refer to DesignInProgram.txt): 
			Core (Group Attributes)
				contains:
					executable libs
					
			Profile/Configuration (Individual Attributes)
				contains: 
					configuration files
					deployment content
					writable areas
		

All the application server is a javaEE container.

The container can maintain servlet and ejb.


Applicaton Server主要有两个组成部分：EJB Container和Servlet Engine。其中，
	EJB Container负责EJB（Session Bean和Entity Bean）的运行时态的管理维护（Create、Active、Passive、Destroy等等）
	Servlet Engine负责Servlet和JSP的运行管理（Init、Service、Destroy等等）

******* geronimo
A running Geronimo server is composed of the following two sets of architectural parts: (GBeans & corresponding ClassLoader) and Geronimo kernel.

Geronimo is composed of a lightweight core (or kernel) and many modules.

The Geronimo kernel provides the GBean components with well-defined kernel-provided services. This set of services includes the following:

    GBean's Configuration Management
    GBean's Lifecycle Management
    GBean's Manageability Implementation

==============================================================

All components/modules files are maintained only in repository.

modules configed in var/config.xml will be loaded



However the plugins by themselves don't do anything


source path:
	latest: svn co https://svn.apache.org/repos/asf/geronimo/server/trunk
	release: svn co https://svn.apache.org/repos/asf/geronimo/server/tags/geronimo-3.0.0
	



******* undertow
undertow
	web server written in java
	
	Application Filter Entry Point:
		FilterHandler.handleRequest()
			FilterChainImpl.doFilter()
				ManagedFilter.doFilter()
					javax.servlet.Filter.doFilter()
					
	
	Container Startup:
		ServiceContainerImpl$ServiceThread.run()
			ServiceControllerImpl$StartTask.run()
				UndertowDeploymentService.start()
					DeploymentManagerImpl.deploy()
						ServletContainerInitializer.onStartup()
	
	
	ServletContextImpl implements ServletContext


******* wildfly
Configurations
	standalone.xml (default)
		Java Enterprise Edition 7 web profile certified configuration with the required technologies plus those noted in the table above.
	standalone-ha.xml
		Java Enterprise Edition 7 web profile certified configuration with high availability
	standalone-full.xml
		Java Enterprise Edition 7 full profile certified configuration including all the required EE 7 technologies
	standalone-full-ha.xml
		Java Enterprise Edition 7 full profile certified configuration with high availability
		
	domain.xml
		Java Enterprise Edition 7 full and web profiles available with or without high availability

	Starting WildFly 8 with an Alternate Configuration:
		./standalone.sh --server-config=standalone-full-ha.xml
		./domain.sh --domain-config=my-domain-configuration.xml
		
		
	Config Detail:
		standalone.xml
			extensions
			management
			profile
			interfaces
			socket-binding-group
				
		domain.xml
			Contents in standalone.xml
			system-properties
			server-groups
			
		host.xml
			management
			domain-controller
			interfaces
			jvms
				jvm
			servers
				server
				

Java Options:
	Standalone Server can be specified in env variable: JAVA_OPTS
		
	Domain Server can be specified in domain.xml

	Process Controller need to be specified in env variable: PROCESS_CONTROLLER_JAVA_OPTS
	
	Host Controller need to be specified in command parameter or env variable: HOST_CONTROLLER_JAVA_OPTS
	
	E.g.
		export JAVA_OPTS='-Djava.net.preferIPv4Stack=true -Xmx2g -XX:MaxPermSize=1.5g -agentlib:jdwp=transport=dt_socket,address=8788,server=y,suspend=n'
		export HOST_CONTROLLER_JAVA_OPTS='-Djboss.boot.server.log.level=DEBUG -Djboss.boot.server.log.console.level=DEBUG'
		export PROCESS_CONTROLLER_JAVA_OPTS='-Djboss.boot.server.log.level=DEBUG -Djboss.boot.server.log.console.level=DEBUG'

	
	
Command
	Setup Command:
		DomainController:
			rm host.xml host-slave.xml
			./jboss-cli.sh --connect --file=add-server-group.cli
			./add-user.sh -u HostController1 -p HostController1
	
		HostController (optional):
			rm domain.xml host.xml host-master.xml
			host-slave.xml config:
				add credential:
					host/name="HostController*"
					<secret value="SG9zdENvbnRyb2xsZXIx" />


	Startup Command:
		Standalone:
			(./standalone.sh -b=0.0.0.0 -bmanagement=0.0.0.0 -Djboss.socket.binding.port-offset=1000 &)
			
		Domain:
			Domain Controller:
				(./domain.sh --host-config=host-master.xml -bmanagement=0.0.0.0 &)
			
			Host Controller:
				in same physical server with Domain Controller:
					(./domain.sh --host-config=host-slave.xml --master-address=localhost -Djboss.management.native.port=9979 &)
					(./domain.sh --host-config=host-slave.xml --master-address=localhost -Djboss.management.native.port=9989 &)
				not in same physical server with Master:
					(./domain.sh --host-config=host-slave.xml --master-address=10.1.8.77 -b=0.0.0.0 &)

	
	
Other
	Dependencies
		Dependencies: Manifest Entries
		Dependencies: org.javassist export,org.apache.velocity export services,org.antlr
		
		Each dependency entry may also specify some of the following parameters by adding them after the module name:
			export This means that the dependencies will be exported, so any module that depends on this module will also get access to the dependency.
			services By default items in META-INF of a dependency are not accessible, this makes items from META-INF/services accessible so services in the modules can be loaded.
			optional If this is specified the deployment will not fail if the module is not available.
			meta-inf This will make the contents of the META-INF directory available (unlike services, which just makes META-INF/services available). In general this will not cause any deployment descriptors in META-INF to be processed, with the exception of beans.xml. If a beans.xml file is present this module will be scanned by Weld and any resulting beans will be available to the application.
			annotations If a jandex index has be created for the module these annotations will be merged into the deployments annotation index. The Jandex index can be generated using the Jandex ant task , and must be named META-INF/jandex.idx. Note that it is not necessary to break open the jar being indexed to add this to the modules class path, a better approach is to create a jar containing just this index, and adding it as an additional resource root in the module.xml file.
	
	
	
	driver
		A driver that is JDBC 4-compliant contains a META-INF/services/java.sql.Driver file that specifies the driver class name. 
	
		The JDBC driver can be installed into the container in one of two ways: either as a deployment or as a core module. 
			When you install the JDBC driver as a deployment, it is deployed as a regular JAR. 
			Any JDBC 4-compliant driver will automatically be recognized and installed into the system by name and version.
			
			To install the driver as a module, you will need to create a directory structure under the modules folder. This structure will contain the driver and a module.xml file to define the module.
			
	
	Management
		read-operation-names
		read-operation-description
		read-attribute
		write-attribute
		read-resource
		read-children-types
		read-children-names
		read-resource-description
			
	Process Controller
		create Host Controller & Server, if any process exist, it will bring it up automatically.
		startup script:
			java ${PROCESS_CONTROLLER_JAVA_OPTS} ${-Dlogging.configuration, -Dorg.jboss.boot.log.file} -jar jboss-modules.jar ${Module Path & Module Name} ${jboss-home, jvm}
				-- ${-Dlogging.configuration, -Dorg.jboss.boot.log.file} ${HOST_CONTROLLER_JAVA_OPTS} 
				-- ${default-jvm} ${Command Parameters}
			
			Note:
				${-Dlogging.configuration, -Dorg.jboss.boot.log.file} ${HOST_CONTROLLER_JAVA_OPTS} - pass to Host Controller
				${default-jvm} ${Command Parameters} - pass to Host Controller
	
	
	JBoss Logging
		Configuration specified via:
			-Dlogging.configuration=${logging configuration file}
			-D${key}=${value}
				for place hold in logging configuration file
		Server:
			File: domain/servers/server-one/data/logging.properties generated from domain.xml/subsystem:logging
		Process Controller & Host Controller
			share same: $JBOSS_CONFIG_DIR/logging.properties
			but can give different value for place hold via PROCESS_CONTROLLER_JAVA_OPTS & HOST_CONTROLLER_JAVA_OPTS
	
		Note:
			Log4j, Slf4j LoggerFactory should be loaded by JCCL (JBoss Container Class Loader), as logging is used by JBoss Container before Application started.
			The visiability of JCCL loaded class is depends on whether logging subsystem enabled for the Application
			If it's visiable to Application, it maybe changed by Application
			
	
	Session Replication:
		replication-trigger:
			SET, SET_AND_GET, SET_AND_NON_PRIMITIVE_GET, ACCESS
		replication-granularity:
			ATTRIBUTE, SESSION, FIELD
	
	
	JVM Setting:
		For a specific server group, for a host or for a particular server. If not declared, the settings are inherited from the parent scope.	
		
		jvm reference at server group level in the domain controller, the jvm's name must match one of the definitions in the host controller.
		The values supplied at domain controller and host controller level are combined, with the host controller taking precedence if the same parameter is given in both places.
		we can also override the jvm at server level. Again, the jvm's name must match one of the definitions in the host controller.
		The values are combined with the ones coming in from domain controller and host controller level, this time the server definition takes precedence if the same parameter is given in all places.
		
		E.g.
			domain.xml:
				<server-groups>
				    <server-group name="main-server-group" profile="default">
				        <jvm name="default">
				           <heap size="64m" max-size="512m"/>
				           <permgen size="128m" max-size="128m"/>
				        </jvm>
				        <socket-binding-group ref="standard-sockets"/>
				    </server-group>
				    <server-group name="other-server-group" profile="bigger">
				        <jvm name="default">
				            <heap size="64m" max-size="512m"/>
				        </jvm>
				        <socket-binding-group ref="bigger-sockets"/>
				    </server-group>
				</server-groups>
				
			host.xml
				<jvms>
				    <jvm name="default">
				        <heap size="64m" max-size="128m"/>
				    </jvm>
				</jvms>
				
				<servers>
				    <server name="server-one" group="main-server-group">
				        <\!-\- server-one inherits the default socket-group declared in the server-group \-->
				        <jvm name="default"/>
				    </server>
				 
				    <server name="server-two" group="main-server-group" auto-start="true">
				        <socket-binding-group ref="standard-sockets" port-offset="150"/>
				        <jvm name="default">
				            <heap size="64m" max-size="256m"/>
				        </jvm>
				    </server>
				 
				    <server name="server-three" group="other-server-group" auto-start="false">
				        <socket-binding-group ref="bigger-sockets" port-offset="250"/>
				    </server>
				</servers>
			
			Result:
				Server	 JVM parameters
				server-one	-XX:PermSize=128m -XX:MaxPermSize=128m -Xms64m -Xmx128m
				server-two	-XX:PermSize=128m -XX:MaxPermSize=128m -Xms64m -Xmx256m
				server-three	-Xms64m -Xmx128m



design
High level design refer to Middleware/applicationServer.txt

Folder Structure :
	Core
		modules
		 
	Configuration
		appclient
			used by the application client container
		domain 
			used by the domain mode processes
		standalone 
			used by the single standalone server
			In "standalone" mode each WildFly 8 server instance is an independent process
			
	Note:
		trivial stuffs : bin, docs, welcome-content 


Concepts:
	Core:
		base kernel:
			JBoss Modules (refer to JBossModules/JBossModules.txt)
			JBoss MSC (module service container)
			
			
		Management clients
			WildFly 8 offers three different approaches to configure and manage servers: 
				a web interface - default port 9990
					The HTTP API Endpoint serves two different contexts. One for executing management operations and another one that allows you to access the web interface:
						Domain API: http://<host>:9990/management
						Web Console: http://<host>:9990/console
				a command line client - default port 9999
				XML configuration files
				

		Class Loading
			Precedence
				System Dependencies - These are dependencies that are added to the module automatically by the container, including the Java EE api's.
				User Dependencies - These are dependencies that are added through jboss-deployment-structure.xml or through the Dependencies: manifest entry.
				Local Resource - Class files packaged up inside the deployment itself, e.g. class files from WEB-INF/classes or WEB-INF/lib of a war.
				Inter deployment dependencies - These are dependencies on other deployments in an ear deployment. This can include classes in an ear's lib directory, or classes defined in other ejb jars. 
				
			WAR Class Loading
				The war is considered to be a single module, so classes defined in WEB-INF/lib are treated the same as classes in WEB-INF/classes. All classes packaged in the war will be loaded with the same class loader.
		
				
		Modules
			Deployments
				Deployments in WildFly are also modules
				Module names for top level deployments follow the format deployment.myarchive.war while sub deployments are named like deployment.myear.ear.mywar.war. 
				Ear deployments are multi-module deployments. 
				By default the EAR/lib directory is a single module, and every WAR or EJB jar deployment is also a separate module. 
				
				Sub deployments (wars and ejb-jars) always have a dependency on the parent module, which gives them access to classes in EAR/lib
				
				
	Configuration:
		Extension is a module that extends the core capabilities of the server.  (should be a module application)
		Subsystem is an added set of capabilities added to the core server by an extension
		Profile is a named set of subsystem configurations. 
		
		Interfaces is a logical name for a network interface/IP address/host name to which sockets can be bound. 
		
		Socket binding is a named configuration for a socket.
			Socket binding groups reference an interface by it's logical name
		
		jboss-deployment-structure.xml
		
		Operating modes
			The domain and standalone modes determine how the servers are managed, not what capabilities they provide.
			standalone
				Manage Server directly
			domain
				Manage Server via Domain (Refer to Domain.txt)
	

impl
Attachable
	A thing which can have named attachments.


HttpServerExchange
	An HTTP server request/response exchange.  An instance of this class is constructed as soon as the request headers are fully parsed.
	
	Refer to Exchange.txt
	Get request data & Give response data via ServerConnection
	
	
Session Model
		Generic HttpSession Impl:
				HttpSessionImpl
	
		Specific HttpSession Impl:
			In Memory HttpSession Impl:
				InMemorySessionManager.SessionImpl
					session implementation for the in memory session manager
					
				InMemorySessionManager
					The default in memory session manager. This basically just stores sessions in an in memory hash map.

				InMemorySessionManager.InMemorySession
					class that holds the real session data
		
		Session Object Structure:
			Generic HttpSession Impl
				Specific HttpSession Impl
				
			E.g.
				HttpSessionImpl
					InMemorySessionManager.SessionImpl
						InMemorySessionManager
							InMemorySessionManager.InMemorySession


		Details:
			Same Cookie to server have different HttpSessionImpl object, but state(attributes) are the same
			
			Bug:
				HttpSession.invalidate()
					Remove InMemorySessionManager.InMemorySession object from InMemorySessionManager
					Unbind current HttpServletRequest object with HttpSessionImpl
					Bug raise: Other HttpServletRequests in other thread still binding to HttpSessionImpl


HA
High Availability
	WildFly's High Availability services are used to guarantee availability of a deployed Java EE application.



	WildFly Modules provide 2 features:
		fail-over
		load balancing
	to resolve Single Node problems:
		single point of failure
		overwhelmed server		


	Related Modules:
		JGroups
			provides group communication support for HA services in the form of JGroups channels
			provides the following features:
				allows definition of named protocol stacks
				view run-time metrics associated with channels
				specify a default stack for general use
				
		Infinispan
			provides caching support for HA services in the form of Infinispan caches
			provides the following features:
				allows definition and configuration of named cache containers and caches
				view run-time metrics associated with cache container and cache instances
				
		modcluster
			provide mod_cluster integration to support LD


Domain
Domain
	A Container ONLY to manage Server Instances, NO additional capabilities provided (E.g. HA)
	
	Domain Container
		Domain Controller
		Host Controller


	Details:	
		Domain Controller 
			maintain Domain Configuration (domain's central management policy stored by default in the domain/configuration/domain.xml)
			accept connection from Host Controller
			
			Details:
				A wired design in wildfly that Domain Controller is implemented via Host Controller & it's meta info comes from host.xml
				
				
		Host Controller
			interacts with the Domain Controller
			solely concerned with server management
			
			Details:
				Server Instance is not part of Host Controller, it's only managed by Host Controller
				by default reads its configuration from the domain/configuration/host.xml
				host.xml
					names of the actual WildFly 8 instances
					configuration of how the Host Controller is to contact the Domain Controller to register itself and access the domain configuration
					configuration of items that are specific to the local physical installation



******* tomcat
3 approaches to deploy a application

1 - Copy war to webapps folder

2 - Config in conf/server.xml
<Context path="/myapp" reloadable="true" docBase="D:/myapp" workDir="D:/myapp/work"/>
其中path是context path，docBase是JSP应用程序的物理路径，workDir是这个应用的工作目录，存放运行是生成的于这个应用相关的文件。

3 - Write a xml(name is the context path) & put to conf/Catalina/localhost
xml content : <Context path="/myapp" reloadable="true" docBase="D:/myapp" workDir="D:/myapp/work"/>
Attribute "path" doesn't work here. 

Bugs:
	Can not read input stream before getParameter(), it will cause null parameters returned. This is because the first invocation of getParameter() will parse the input stream. 


******* tomcat connection pool
Stack Trace:
	DataSourceProxy.getConnection()
	ConnectionPool.getConnection()
	ConnectionPool.borrowConnection()
	ConnectionPool.createConnection()
	ConnectionPool.getThreadDump()


ConnectionPool
	poolProperties = properties;
	busy = new ArrayBlockingQueue<PooledConnection>(properties.getMaxActive(),false);
	if (properties.isFairQueue()) {
        idle = new FairBlockingQueue<PooledConnection>();
    } else {
        idle = new ArrayBlockingQueue<PooledConnection>(properties.getMaxActive(),false);
    }
    if (properties.isPoolSweeperEnabled()) {
	    poolCleaner = new PoolCleaner(this, properties.getTimeBetweenEvictionRunsMillis());
		poolCleaner.start();
	}
	jmxPool = new org.apache.tomcat.jdbc.pool.jmx.ConnectionPool(this);
	Parse and create an initial set of interceptors. Letting them know the pool has started.
	borrowConnection InitialSize connections then return back
	

ConnectionPool.borrowConnection()
	now = System.currentTimeMillis();
	
	init state connection = idle.poll();
	while true:
		check state connection != null:
			Validates and configures a previously idle connection & return
		
		process state connection:
			if size < maxActive
				return createConnection(now, con, username, password);
			timetowait = Math.max(0, maxWait - (System.currentTimeMillis() - now));
			connection = idle.poll(timetowait, TimeUnit.MILLISECONDS);
			if connection not available & (System.currentTimeMillis() - now) >= maxWait
				throw new PoolExhaustedException
	

PoolCleaner
	run()
		if ((System.currentTimeMillis() - lastRun) > sleepTime)
		    lastRun = System.currentTimeMillis();
	        if (pool.getPoolProperties().isRemoveAbandoned())
	            pool.checkAbandoned();
	        if (pool.getPoolProperties().getMinIdle() < pool.idle.size())
	            pool.checkIdle();
	        if (pool.getPoolProperties().isTestWhileIdle())
	            pool.testAllIdle();

	
PoolProperties.isPoolSweeperEnabled()
    boolean timer = getTimeBetweenEvictionRunsMillis()>0;
    boolean result = timer && (isRemoveAbandoned() && getRemoveAbandonedTimeout()>0);
    result = result || (timer && getSuspectTimeout()>0);
    result = result || (timer && isTestWhileIdle() && getValidationQuery()!=null);
    result = result || (timer && getMinEvictableIdleTimeMillis()>0);
    return result;



******* websphere
Relationship between Application(e.g. war application) & Websphere Server Instance is only temp, 
so no need to put Application folder under server folder. 

Websphere physically contains:
Product files - Core binary
User defined Profiles - Configurations


Websphere logically contains:
Cell
	Node
		Server
	DeploymentManager
	Application(WAR)

	
	
AppServer Change(E):
	properties/profileRegistry.xml
		<profile isAReservationTicket="false" isDefault="false" name="AppSrv01" path="C:\IBM\websphere\profiles\AppSrv01"
			 template="C:\IBM\websphere\AppServer\profileTemplates\default"/>
			 
	properties/fsdb/AppSrv01.bat
		set WAS_USER_SCRIPT=C:\IBM\websphere\profiles\AppSrv01\bin\setupCmdLine.bat

virtual machine
since the request data package contains the url(doesn't contain the ip) and it will be forwarded to the mapped ip(through the dns).
So there can be several differented url packages forward to the same ip.

The targe machine can config different virtual machine, which is used to handle different packages contains different url in the head.

So the target machine(websphere server) will receive all the packages and read the head find their request url, finally handle it according to virtual machine config(forward the request to different machine)

******* weblogic
domain creatation
1, %MW_HOME%\wlserver\server\bin\setWLSEnv.cmd
2, %JAVA_HOME%\bin\java.exe -Xmx1024m -XX:MaxPermSize=128m weblogic.Server  (in empty folder)

classloader
Weblogic Class Loader(ChangeAwareClassLoader):
If class start with java,javax,weblogic(exclude javax.xml). It will ask parent loader to loader first.
Else:
Loader the class by it's self first.(In this scenario, same class can be loaded twice. First time can be loaded by it's parent, second can be loaded by it's self)

enctriped password
3DES key will be under:
${domain}\security\SerializedSystemIni.dat

****** message oriented middleware
MOM - Message oriented middleware
	Refer to Middleware
	
	Software or hardware infrastructure supporting sending and receiving messages between distributed systems.
	
	
******* JMS
当前，CORBA、DCOM、RMI等RPC中间件技术已广泛应用于各个领域。但是面对规模和复杂度都越来越高的分布式系统，这些技术也显示出其局限性： （1）同步通信：客户发出调用后，必须等待服务对象完成处理并返回结果后才能继续执行；（2）客户和服务对象的生命周期紧密耦合：客户进程和服务对象进程 都必须正常运行；如果由于服务对象崩溃或者网络故障导致客户的请求不可达，客户会接收到异常；（3）点对点通信：客户的一次调用只发送给某个单独的目标对 象。 

面向消息的中间件（Message Oriented Middleware，MOM）较好的解决了以上问题。发送者将消息发送给消息服务器，消息服务器将消息存放在若干队列中，在合适的时候再将消息转发给接 收者。这种模式下，发送和接收是异步的，发送者无需等待；二者的生命周期未必相同：发送消息的时候接收者不一定运行，接收消息的时候发送者也不一定运行； 一对多通信：对于一个消息可以有多个接收者。 
已有的MOM系统包括IBM的MQSeries、Microsoft的MSMQ和BEA的MessageQ等。由于没有一个通用的标准，这些系统很难实现 互操作和无缝连接。Java Message Service（JMS）是SUN提出的旨在统一各种MOM系统接口的规范，它包含点对点（Point to Point，PTP）和发布/订阅（Publish/Subscribe，pub/sub）两种消息模型，提供可靠消息传输、事务和消息过滤等机制。 

***** isis
all you need to write in order to get an application up-and-running is the domain model

	Deploy on your own App (deploy on some other framework's runtime)
		impl DomainObjectContainer
			This interface represents the one-and-only "touchpoint" between the domain objects and the runtime
			Isis' own runtime injects an (implementation of this) interface into each and every domain object.
			
	Deploy on Isis as an auto-generated Webapp
		One of the original motivations for Isis itself was to be able automatically generate a user interface for a domain object model.
		Deploying on Isis means that the framework also manages object persistence.
		
		presentation is derived from domain model, CSS annotation, icon method(part of model?), view model & layout config file.
		
	Deploy on Isis as a RESTful web service
		Isis' RestfulObjects viewer is an implementation of Restful Objects specification, making any Isis domain object automatically available via REST.


***** RSA

Rational Software Architect
    Like websphere profile, it support install profile(to install different component set)


***** RTC
A Product run on Jazz
	Uses the Change and Configuration Management (CCM) application to provide features that integrate development project tasks
		Provide WorkItem & related stuffs Data
			related stuffs: 
				Plan
				WorkItem Category
				Team
		
		Including 
			iteration planning
				provides tools to assist with the planning, tracking, and workload balancing of releases and iterations
				planning is just an action, its output will be maintained in change management
				Step Summary:
					Create Product Backlog & its WorkItems
					Create Release Backlog & pull WorkItems from Product Backlog
					Create Sprint Backlog & pull WorkItems from Release Backlog
					Create child WorkItems in Sprint Backlog
				
				
			process definition
				collection of roles, practices, rules, permissions, and guidelines that you use to organize and control the workflow for a project
			
			
			change management
				main feature of change management is WorkItems, which track and coordinate tasks, including stories, defects, plan items, and ordinary tasks
				
				WorkItem
					High-level WorkItem
						Epic
						Story	
							record general details about a product idea or feature
					
					Relationship to Plan & Category refer to: work_items_in_iterations.gif
					
				Backlog
					A container which contains WorkItem & Timeline
					
					Product Backlog
						Should NOT have a Timeline as WorkItems that might or might not make it into the product over time
					Release Backlog
						Contains a Timeline & WorkItems
					Sprint Backlog
						Contains a Timeline & WorkItems
				
				
			defect tracking
			source control
			build automation
				provides build awareness, control, and traceability to the development and test teams
			reporting
				provides an awareness of the actions, behaviors and progress of a team or project


		Components:
			Plan
				Backlog
					WorkItem
				Timeline
				important dates
				high-level dependencies to other components
				objectives
				test plans


In a Scrum process template, schedule dependencies do not affect the plan schedule

Plan 
	Type:
		Release plan
		Phase plan (Sprint Backlog)
		Cross-project plan

Schedule
	A plan schedule indicates the start and end dates and the sequence for the work items in a plan. 
	When you save a plan, the plan schedule is calculated based on the information that you supply. 
	Category:
		Planed
		Proposed
		Current
		
	Schedule constraints
		This feature is available only if you are using the Formal Project Management process template.
		The following constraint types are available:
			As soon as possible (default)
			Start no earlier than
			Finish no later than
			
			
	The plan schedule is determined by the following information:
		Effort estimate or duration of work items
		Start and end date of the plan
		Schedule constraints and dependencies of work items
		Project working days and hours
		Availability of resources who are assigned to work items

	Note:
		Parent Item estimate means how much time it need to wait before first item start

Critical path, Basic resource leveling
	This feature is available only if you are using the Formal Project Management process template.


The Effective Estimate column displays the value that is in the Estimate or Correction field of the work item.


A project area is an area in the repository where information about one or more software projects is stored.
	project deliverables
	team structure
	process (need to be created during project area creation)
		shared process
			By sharing a project area process, you can ensure that all project areas across your organization use the same process.
			You also centralize process maintenance.
			when a new version of the process template that the sharing project area uses becomes available, you need only update the sharing project area with the new template. 
	schedule
		timeline




RTC structure - refer to project_area.gif

WorkItems - defined in Process
Categories - defined in Process

Iterations
Repository Workspace
Source Control
Change-Sets
Flow
Baseline
Snapshot
Build - defined in Build Definition

Team Process
	指定项目的流程
	团队如何自定义该流程
	

Repository is the top object

Streams, components, baseline, snapshot are repository objects. 

Streams 
	where you can share code with team 
	similar to the branches found in other source control management systems

A baseline saves an configuration(state/version set) of a component. 

A snapshot includes one baseline for each component in a workspace or stream. When you create a snapshot, you implicitly create a baseline for any component in your workspace that does not already have one.


Each CLM application (Change and Configuration Management, Requirements Management, and Quality Management) uses project areas to organize teams' work.

source control component handles the storing, retrieving and sharing of source code and other artifacts in your project

During these setup steps you have been using the Jazz Team Process component

Iteration planning component provides tools to assist with the planning and execution of development iterations.       



work item
Plan Item vs. Execution Item

A typical example for a plan item in the agile space are Stories and Epics. Typical for plan items is that they are not estimated in real time (hours) but in an abstract notion like Story Points, T-Shirt sizes, Gummy bears, etc.

An Execution Item is a small piece of work like a Task or Defect. Often, execution items are the result of breaking down Plan Items into 'executable' chunks of work. They typically can be estimated in hours and are assigned to a person in the team. When looking at it as a tree, plan items are roots and execution items are leaves.



A work item belongs to a plan when it is planned for the iteration the plan is created for and when it is filed against a category that is associated with the project or team owning the plan.
To add a work item to a plan you have to alter its Planned For and Filed Against attributes to match what has been configured for the plan. 

By default a plan contains all work items that are planned for the plan's iteration and belong to the plan's owner. 


product backlog
	Clean garage



Task:
Clean garage
Paint house
	Paint bedroom
	Paint kitchen
		Paint wall
		Paint trim

	
Plan:	
product backlog
release backlog 1.0
	sprint backlog 1
	sprint backlog 2

Parent task's planfor equals to last planfor of child



***** gen
gem - a pkg manage tool

Install Steps:
	Runtime:
		install rubyinstaller-2.0.0-p247.exe
	DevKit:
		DevKit-mingw64-32-4.7.2-20130224-1151-sfx.exe extract to ${Ruby Path}\DevKit
		Under DevKit path (${Ruby Path}\DevKit):
			Run: "ruby dk.rb init" to generate config.yml
			Edit the generated config.yml file to include installed Rubies not automatically discovered or remove Rubies you do not want to use the DevKit with
			Run: "ruby dk.rb install" to install to ${Ruby Path}/lib/ruby/site_ruby/devkit.rb"
		
		

***** SCM
software configuration management

Different Data Files + Different Tree(link Data file & maintain structure)

Should contains:
	Data File - Real file
	Version Info - version & corresponding file location mapping
	Version Info Relation - links of Version Info's ancestor & descendant (this relation is trunk and branch)


Change
	A logic stuff, it must have a Corresponding Base

	Details:
		It can allocate on different files
		It can reallocate to another file during merge conflict resolve
		Only those with same CB can merge


Merge(Refer to: SCMMergeConcept.png)
	"Base" file
		represents the oldest version of a file, from where You and They start making changes
	"Mine" file/"Yours" file
		represents the "Base" file with all the changes you made
	"Theirs" file
		represents the "Base" file with all the changes someone else made

	Merge Conflict: different change on the same base

Merge VS Rebase
    Merge: create new commit on target branch to also extend source branch
    Rebase: change target branch's history to insert source branch's diverged changes
    Note: seems change history is NOT acceptable to me, so I strongly NOT recommend to use rebase

Stash
    saves your local modifications away and reverts the working directory to match the HEAD commit


Checkout - update Tree of working copy

Checkin - save Tree working copy to reop copy

****** svn
Normal Folder Structure:
Project
	trunk			-> Global latest code
	branches		-> Country BAU maintainence version
	tags			-> Country BAU current version (read only)

	
Checkout - Only way to download File & SCM data to local.
Export - Only download File to local. 


****** git
Core:
	CommitObjects & Refs(branch/tag/HEAD)
	

CommitObjects contains meta data, tree object(contains all files reference under all folders) & parent reference


Remote Git Repo Contains: Repository(Commit Objects), Stage Area(Commit Objects)
Stand Git Repo Contains: Repository(Commit Objects), Stage Area(Commit Objects) & Working Directory(File Copy)


Distributed SCM:
	Upstream - In terms of flow of data, refer to the master repo
		Can be specified in .git/config/[branch "${branchName}"]/remote
	Downstream - In terms of flow of data, refer to the cloned repo
	
	

Branches:
	master - local master branch
	${xxx}/master - mirror branch of repository ${xxx}'s master
		mirror branch only used to sync data can not be work branch(check out)
		use 'git fetch ${xxx} master' to sync data
		Note:
			'git fetch ${xxx} master' + 'git merge ${xxx}/master master' = 'git pull ${xxx} master'

Code example:
	~/gitrepo/forumweb
	git clone https://github.com/xfcjscn/repo3.git .
	
	git init
	touch readme.txt
	git add readme.txt
	
	git config --global user.email "xfcjscn@gmail.com"
	
	git commit -m "read me file as first commit"
	
	git tag -a 1.0 -m 'init version'
	
	git push origin --tags

	git fetch : fetch remote repo's master branch to local repo's origin/master
	
	git pull : git fetch & merge
	
	git reset - rever to previous version(move HEAD)
	
	git checkout - Just move HEAD, no change in working directory
	
	git config --global gui.encoding utf-8
	git config --global i18n.commitencoding utf-8
	git config --global i18n.logoutputencoding utf-8


Set Proxy:
	windows:
		set https_proxy=http://127.0.0.1:8580
	linux:
		export https_proxy="http://127.0.0.1:8580"


Project maintainance strategy:
	Can not merge client & server into one project, since client need to be registered in bower
	It's better to maintain one project as one git project as: 1, git change set is global not folder specific. 2, some tools like maven release use this principle


Branch Best Practice
	Category:
		main branches - infinite lifetime
			master - for production
			develop - branch from master, for development
		
		supporting branches -  limited life time
			feature-* branches - branch from develop, for parallel features development
			release-* branches - branch from develop, for release preparing
			hotfix-* branches - branch from master, for hotfix
			
	
	Merage Feature branches with "no-ff"
		git merge --no-ff myfeature

***** selenium
Selenium's Tool Suite
	Selenium 2 (aka. Selenium Webdriver)
	Selenium 1 (aka. Selenium RC or Remote Control)
		Selenium 1 is deprecated and is not actively supported
	Selenium IDE
		It is a Firefox plugin and provides an easy-to-use interface for developing automated tests
		It is not designed to run your test passes nor is it designed to build all the automated tests you will need
			Specifically, Selenium IDE doesn’t provide iteration or conditional statements for test scripts.
			Selenium IDE is simply intended as a rapid prototyping tool
		URL: http://release.seleniumhq.org/selenium-ide/2.9.0/selenium-ide-2.9.0.xpi
	Selenium-Grid
		Allows you to run your tests in parallel, that is, different tests can be run at the same time on different remote machines.
		
		
Details:
	Selenium 2 (aka. Selenium Webdriver)
		makes direct calls to the browser using each browser’s native support for automation
		WebDriver is the name of the key interface against which tests should be written, but there are several implementations. These include:
			HtmlUnit Driver
				HtmlUnit is a java based implementation of a WebBrowser without a GUI.
			Firefox Driver
				Controls the Firefox browser using a Firefox plugin.
				The Firefox Profile that is used is stripped down from what is installed on the machine to only include the Selenium WebDriver.xpi 
			Internet Explorer Driver
				This driver is controlled by a .dll and is thus only available on Windows OS.
			Chrome Driver
				WebDriver works with Chrome through the chromedriver binary (found on the chromium project’s download page). 
				You need to have both chromedriver and a version of chrome browser installed. 
				chromedriver needs to be placed somewhere on your system’s path in order for WebDriver to automatically discover it. 
				The Chrome browser itself is discovered by chromedriver in the default installation path.
				The ChromeDriver consists of three separate pieces:
					 the browser itself ("chrome")
					 language bindings provided by the Selenium project ("the driver")
					 an executable downloaded from the Chromium project which acts as a bridge between "chrome" and the "driver"
					 	This executable is called "chromedriver", but we'll try and refer to it as the "server" in this page to reduce confusion
				
			Opera Driver
			iOS Driver
			Android Driver
			
	Selenium 1 (aka. Selenium RC or Remote Control)
		'injected' javascript functions into the browser when the browser was loaded and then used its javascript to drive the AUT within the browser.
		WebDriver-Backed Selenium-RC
			The Java version of WebDriver provides an implementation of the Selenium-RC API. 
			These means that you can use the underlying WebDriver technology using the Selenium-RC API. 
			This is primarily provided for backwards compatibility. 
			It allows those who have existing test suites using the Selenium-RC API to use WebDriver under the covers.
		
	Selenium IDE
	Selenium-Grid
	Selenium-Server
		You may, or may not, need the Selenium Server, depending on how you intend to use Selenium-WebDriver. If you will be only using the WebDriver API you do not need the Selenium-Server. If your browser and tests will all run on the same machine, and your tests only use the WebDriver API, then you do not need to run the Selenium-Server; WebDriver will run the browser directly.
		There are some reasons though to use the Selenium-Server with Selenium-WebDriver.
		        You are using Selenium-Grid to distribute your tests over multiple machines or virtual machines (VMs).
		        You want to connect to a remote machine that has a particular browser version that is not on your current machine.
		        You are not using the Java bindings (i.e. Python, C#, or Ruby) and would like to use HtmlUnit Driver
		
		
Env Setup:
	1, add Selenium Webdriver to pom
		<dependency>
			<groupId>org.seleniumhq.selenium</groupId>
			<artifactId>selenium-java</artifactId>
			<version>${org.seleniumhq.selenium.version}</version>
		</dependency>
	2, Chrome: 
		The path to the driver executable must be set by the webdriver.chrome.driver system property
			E.g. 
				Via startup command:
					-Dwebdriver.chrome.driver=c:\path\to\your\chromedriver.exe
				Via code:
					System.setProperty("webdriver.chrome.driver", "c:\\path\\to\\your\\chromedriver.exe");
					
Create Script & Run:
	2, install Selenium IDE into firefox & create test script prototype
	3, complete test script & add to maven test (rename to *IT.java)
	4, enable integration test profile & run maven test



***** servlet 3.0
异步处理支持
新增的注解支持
可插性支持
ServletContext 的性能增强
HttpServletRequest 对文件上传的支持


***** slf4j
Simple Logging Facade for Java
	Refer to Logging
	
	
	LoggerFactoryBinder
		Bind to ILoggerFactory (concrete log) which will be used by LoggerFactory
		
	
	StaticLoggerBinder implements LoggerFactoryBinder
		Bind to ILoggerFactory via hard code
		This is different from JCL which bind to concrete log impl via commons-logging.properties
		StaticLoggerBinder not in slf4j.jar but in: slf4j-nop.jar, slf4j-simple.jar, slf4j-log4j12.jar, slf4j-jdk14.jar or logback-classic.jar, slf4j-timbre
		
		
	Bridges:
		* -> SLF4J
			JCL -> SLF4J
				changed JCL in jcl-over-slf4j.jar replace original JCL in common-logging.jar
			log4j -> SLF4J
				changed log4j in log4j-over-slf4j.jar replace original log4j in log4j.jar
			JUL -> SLF4J
				Can NOT change JUL since it's under java package
				introduce SLF4JBridgeHandler in jul-to-slf4j.jar to redirect JUL log to SLF4J
					Programmatic installation:
						SLF4JBridgeHandler.removeHandlersForRootLogger();
						SLF4JBridgeHandler.install();
					Installation via logging.properties:
						handlers = org.slf4j.bridge.SLF4JBridgeHandler
				Note: 
					Only logs enabled in j.u.l. will be redirected. 
					For example, if a log statement invoking a j.u.l. logger is disabled, then the corresponding non-event will NOT reach SLF4JBridgeHandler and cannot be redirected.
					So you need to set log level in logging.properties
					Normally you can set lowest log level(.level=FINEST) in logging.properties to open all logs in jul, and you can config the higher log level in logback config
		
		SLF4J -> *
				refer to bridge.png
		
		
	Config:
		Three root config element: 
			appender, root, logger


	Advantage: 
		1, API support place holder replacement, so that it will only calculate the final msg after log level is matched.
	



***** spring

****** spring boot
Spring Boot
	Provided:
		Embeded servlet container, which is a lite edition tomcat and don't load web*.xml
			ConfigurableEmbeddedServletContainer
		Autoconfig
		Other Features:
			Database initialization
			LoggingSystem
			@ConfigurationProperties
	
	Components:
		Actuator
			manage and monitor your application via Endpoints via:
				HTTP
				JMX
				remote shell (SSH or Telnet)
	
		SpringApplicationBuilder
			Create SIC
			
		SIC impl:
			AnnotationConfigEmbeddedWebApplicationContext
	
		ErrorPageFilter
			wrap response into ErrorWrapperResponse
			doFilter()
			if (status >= 400)
				handleErrorStatus()
					get error path base on status
					if error path exist -> 
						setErrorAttributes()
						forward to it
					else -> sendError()
			
		ErrorWrapperResponse
			overwrite sendError() to only set the status & message into attributes instead of the response header
			
			
		LoggingApplicationListener
			on ApplicationStartedEvent:
				LoggingSystem.get()
				LoggingSystem.beforeInitialize()
					SLF4JBridgeHandler.install()
					add TurboFilter to TurboFilterList
			on ApplicationEnvironmentPreparedEvent:
				set PID to System properties
				initializeEarlyLoggingLevel()
					set springBootLogging base on environment property
				initializeSystem()
					get LogFile, logConfig base on environment property
					LoggingSystem.initialize()
						remove TurboFilter from TurboFilterList
						init logging with configLocation/selfInitializationConfig/defaults
				initializeFinalLoggingLevels()
					LoggingSystem.setLogLevel() base on LOG_LEVEL_LOGGERS & springBootLogging
					LoggingSystem.setLogLevel() base on environment property
			
			ApplicationListener that configures a logging framework depending on what it finds on the classpath and in the Environment
			Logging re-inits:
				refer to Logging.txt
				Default Config/classpath:logback.xml -> classpath:org.springframework.boot.logging.logback/basic-logback.xml -> classpath:org.springframework.boot.logging.logback/logback.xml
				Note:
					In SB 1.2, DefaultLogbackConfiguration replaced classpath:org.springframework.boot.logging.logback/basic-logback.xml & classpath:org.springframework.boot.logging.logback/logback.xml
				
				
		EmbeddedWebApplicationContext
			getServletContextInitializerBeans()
				Get/Create(find all Filter, Servlet Component & encapsulate into ServletContextInitializer) a set of ServletContextInitializer to do dyna register in Servlet Context
					
					getOrderedBeansOfType(ServletContextInitializer.class)
					getOrderedBeansOfType(Servlet.class)
					getOrderedBeansOfType(javax.servlet.Filter)
						Get Filters registed as spring comonent
						
			Offeren used Filters:
				Order in initialization & JBoss dyna register:
					errorPageFilter
					corsFilter
					setCharacterEncodingFilter
					metricFilter
					
					customizeRequestFilter
					hiddenHttpMethodFilter
					springSecurityFilterChain
					applicationContextIdFilter
					webRequestLoggingFilter (order = Integer.MaX Value)
					
					
				Order in Wildfly8.1(undertow 1.0.15) Request Handleing
					WebRequestTraceFilter
					applicationContextIdFilter
					springSecurityFilterChain
					hiddenHttpMethodFilter
					customizeRequestFilter
					metricFilter
					setCharacterEncodingFilter
					corsFilter
					errorPageFilter
					
					
				Order in Wildfly8.2(undertow 1.1.0) & Tomcat Request Handleing:
					Same as Order in initialization & JBoss dyna register
		
		
		Jersey:
			A bug in JerseyConfig extends ResourceConfig extends Application:
				JerseyServletContainerInitializer (for Servlet 3) will find subclass of Application & register a servlet(ServletContainer) for it. 
				This will duplicate with JerseyAutoConfig which will explicitly register a servlet(ServletContainer) with this Application
				
	Bugs:
		When sb packaged to war, it will cause bitronix global transaction empty error. Finally it can not release & requeue the connection


auto-configuration
Auto-configuration
	Compare to ComponentScan based configuration, auto-config can provide @AutoConfigureAfter, @AutoConfigureBefore & exclude in @EnableAutoConfiguration

Auto-configuration classes are regular Spring Configuration beans. 
	They are located using the SpringFactoriesLoader mechanism (keyed against this class) instead of ComponentScan
	Not sure whether they are conflict?

EnableAutoConfigurationImportSelector (invoked by ConfigurationClassParser.parse())
	SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class, this.beanClassLoader)));
	Remove exclude
	Use AutoConfigurationSorter to do sorter
	

Steps to add auto-config:
	1, Add @Configuration class
	2, Add META-INF/spring.factories
		E.g.
			org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
			com.mycorp.libx.autoconfigure.LibXAutoConfiguration,\
			com.mycorp.libx.autoconfigure.LibXWebAutoConfiguration


		


****** spring data
Spring Data - Data access lib
	Support different data source like: 
		Relational DB
		Non-relational DB
		map-reduce
		cloud based data services
	
	This is an umbrella project, contains many subproject that are specific to a given database



spring data rest
A lib to expose JPA based repositories as RESTful endpoints
	Part of Spring Data family
	


spring data jpa
An lib to simplify the DAO layer
	Part of Spring Data family
	With this lib you only need to extend interface: JpaRepository & write method names in DAO, spring will generate impl code in fly automatically

	Steps:
		Include spring-data-jpa jars
        Write ur Entity Repository (interface extends Repository)
        Register in spring env : <jpa:repositories base-package="net.gplatform.server"/>
        Use Entity Repository Impl(Generated by Spring) to access DB
            Can use @Autowired to inject into your bean


****** spring framework
Spring Framework is a lightweight solution and a potential one-stop-shop for building  your enterprise-ready applications.
	
	All Spring components are run on SIC(Spring IoC Container)
	
	Module Summary:
		Core Container
			Core
			Beans - Provide IoC Container
				IoC Container provide IoC & DI support
				Container is created via new BeanFactory()		
				These bean definitions are represented as BeanDefinition
					Contain following metadata:
						package-qualified class name
						Bean behavioral configuration elements, which state how the bean should behave in the container (scope, lifecycle callbacks, and so forth).
						References to other beans that are needed for the bean to do its work; these references are also called collaboratorsor dependencies
						Other configuration settings to set in the newly created object
					Used by IoC Container to create (or acquire) an actual object
				
			Context - Provide Context
				Context inherits its features from the Beans module
					Adds support for 
						internationalization (using, for example, resource bundles), 
						event-propagation, 
						resource-loading, 
						and the transparent creation of contexts by, for example, a servlet container. 
		
				a means to access objects in a framework-style manner that is similar to a JNDI registry
				The Context module also supports Java EE features such as EJB,mJMX ,and basic remoting. 
				The  ApplicationContext interface is the focal point of the Context module.
				Normally Spring Start from initialization of ApplicationContext
					Triggered by:
						ContextLoaderListener
						...
		
				
			SpEL
				querying  and manipulating an object graph at runtime
				
		Data Access/Integration
		
		Web

					
		AOP
		
		Instrumentation
			class instrumentation support and classloader implementations to be used in certain application servers
		
		Test
			loading of Spring ApplicationContexts and caching of those contexts
			provides mock objects that you can use to test your code in isolation


Start from: TransactionInterceptor.invoke()
Internally invoke EntityTransaction.commit()

transaction management
	global
		enable you to work with multiple transactional resources, typically relational databases and message queues
		The application server manages global transactions through the JTA
	local
		resource-specific
		cannot work across multiple transactional resources
		
		
PlatformTransactionManager
	a service provider interface (SPI)
	
	
TransactionDefinition
	specifies:
		Isolation
		Propagation
		Timeout
		Read-only status
		
TransactionStatus
	
PlatformTransactionManager implementations normally require knowledge of the environment in which they work: JDBC, JTA, Hibernate, and so on.


JtaTransactionManager
	does not need to know about the DataSource, or any other specific resources, because it uses the container’s global transaction management infrastructure.


Autowired on HttpServletRequest
	Spring exposes the current HttpServletRequest object (as well as the current HttpSession object) through a wrapper object of type ServletRequestAttributes. 
	This wrapper object is bound to ThreadLocal and is obtained by calling the static method RequestContextHolder.currentRequestAttributes().
	
		
	RequestContextHolder.setRequestAttributes() invoked by RequestContextListener.requestInitialized()
		Set init Request to RequestContext
		
	RequestContextHolder.setRequestAttributes() invoked by FrameworkServlet.processRequest()
		Set wrapped Request(wrapped in filter) to RequestContext
		
	Problem:
		Because Logical Request can represented by multiple request object(Refer to Exchange.txt), 
		you dont know which one to autowire.
		
		Bean with scope=request/session have the same problem as this scope rely on autowired request


spring config
Spring can find annotation via:
	specific pkg scan - find annotations inside a pkg (E.g. Annotations(@Component, @Service, @Controller and @Repository) scaned by component-scan )
	specific class scan - find annotations on class (E.g. Annotations on Class with @Configuration annotation)

context:annotation-config
	Activates the Spring infrastructure for various annotations to be detected in bean classes
		Note: These beans need to be registered in spring context already
	Default processor:
		AutowiredAnnotationBeanPostProcessor,CommonAnnotationBeanPostProcessor,PersistenceAnnotationBeanPostProcessor, RequiredAnnotationBeanPostProcessor
	Processed Annotations:
		@Required and @Autowired
		JSR 250's @PostConstruct, @PreDestroy and @Resource
		JPA's @PersistenceContext and @PersistenceUnit
	

@ComponentScan
	processed by ComponentScanAnnotationParser
	
ComponentScanAnnotationParser
	By default scan classes annotated with @Component, @ManagedBean, @Named & register corresponding BeanDefinitions with the ApplicationContext
	Filtered by AnnotationTypeFilter
	Note:
		@Service, @Controller, @Repository @Configuration are annotated with @Component, and saner use Annotation Lookup Strategy: considerMetaAnnotation, so they can also be scanned
	Can also do what <context:annotation-config> does
	
@Import
	Indicates one or more @Configuration classes to import

@Configuration
	Indicates that a class declares one or more @Bean methods and may be processed by the Spring container to generate bean definitions
	Also annotated with @Component


Injection Annotations:
	Used to inject object base on field type & name
		@Resource
			Processed by CommonAnnotationBeanPostProcessor to inject bean
				CommonAnnotationBeanPostProcessor steps:
					Matches by Name
					Matches by Type
					Restricts by Qualifiers (ignored if match is found by name)
				
		@Autowired
			Processed by AutowiredAnnotationBeanPostProcessor to inject bean
				AutowiredAnnotationBeanPostProcessor steps:
					Matches by Type
					Restricts by Qualifiers
					Matches by Name

		@Inject
			Same as @Autowired
	
	Inject request/session scoped bean, actually inject an AOP proxy in place of the scoped bean
		That is, you need to inject a proxy object that exposes the same public interface as the scoped object, but that is smart enough to be able to retrieve the real, target object from the relevant scope (for example a HTTP request) and delegate method calls onto the real object.
		AOP Proxy type:
			CGLIB proxies
				will only intercept public method calls
			'standard' JDK interface-based proxies
				config: <aop:scoped-proxy proxy-target-class="false"/>
		
		Create AOP proxy example:
			<bean id="userPreferences" class="com.foo.UserPreferences" scope="session">
		          <!-- this next element effects the proxying of the surrounding bean -->
		          <aop:scoped-proxy/>
		    </bean>


spring java config
Use java to do configuration
	refer to Config/Config.txt
	
	Register Configurer in SIC, so that framework can get & invoke related method to perform config



xml extention
Extensible XML
	Extensions to the basic Spring XML format
		schema-based
		for defining and configuring beans
	
	Steps:
		Authoring an XML schema to describe your custom element(s).
		Coding a custom NamespaceHandler implementation
		 	NamespaceHandler that will parse all elements of this specific namespace Spring encounters while parsing configuration files
		 	Methods:
		 		init()
		 			called by Spring before the handler is used
		 		BeanDefinition parse(Element, ParserContext)
		 			Called when Spring encounters a top level element (not nested inside a bean definition or a different namespace). 
		 			This method can register bean definitions itself and/or return a bean definition
		 		BeanDefinitionHolder  decorate(Node,  BeanDefinitionHolder,  ParserContext)
		 			called  when  Spring  encounters  an  attribute  or  nested  element  of  a  different  namespace
		 			
		 	it is often the case that each top-level XML element in a Spring XML configuration file results in a single bean definition
		 	Spring features a number of convenience classes that support this scenario
		 		NamespaceHandlerSupport
		 			supports the registration of any number of  BeanDefinitionParser instances, to which it will delegate to when it needs to parse an element in its namespace
		 			This clean separation of concerns allows a NamespaceHandler to  handle  the  orchestration  of  the  parsing  of  all of  the  custom  elements  in  its  namespace
		 		
		 Coding one or more  BeanDefinitionParser implementations
		 	contain just the logic for parsing a single custom element
		 	
		 Registering the above artifacts with Spring
			META-INF/spring.handlers
			META-INF/spring.schemas
	



spring container
AbstractApplicationContext
	create BeanFactory
	postProcessBeanFactory()
	invokeBeanFactoryPostProcessors()
		Execute BeanDefinitionRegistryPostProcessor
		 	E.g. 
		 		ConfigurationClassPostProcessor


ConfigurationClassPostProcessor
	ConfigurationClassParser.parse()



spring web



SpringMVC
	Request flow:
		DispatcherServlet -> HandlerMapping -> Handler(HandlerExecutionChain) which contains Interceptor & Controller
	
	springSecurityFilterChain rely on beans defined in spring root context. 
	So security related bean need to be defined in root context (defined in ContextLoaderListener)
	@ModelAttribute
		on a method - add attribute to Model
		on a method argument - indicates the argument should be retrieved from the Model
			If not present in the model, the argument should be instantiated first and then added to the model
			Once present in the model, the argument's fields should be populated from all request parameters that have matching names
	@SessionAttributes
		list the names of model attributes which should be transparently stored in the session
		

WebApplicationInitializer
	Config ServletContext in Servlet 3.0+ instead of web.xml



SpringDispatcherServlet

Spring take DispatcherServlet as a bean so that it can manager it.




HttpServletBean - Bean Level job (e.g. Initializer)
	init()
		1, Get & Check InitParameter in web.xml & put them into PropertyValues
		2, Create BeanWrapper will PropertyValues as parameter
		3, initServletBean() - Empty
		
		
		
FrameworkServlet - FrameworkServlet Level job, Create context
	initServletBean()
		this.webApplicationContext = initWebApplicationContext();
			Find WebApplicationContext from ServletContext with key: this.contextAttribute
			Find ROOT WebApplicationContext from ServletContext with key: "WebApplicationContext.ROOT"
			Create ServletSpec WebApplicationContext through new instance of class: this.contextClass which default: XmlWebApplicationContext.class
			ServletSpec Context set fields 
				id: "WebApplicationContext:${ContextPath}/${ServletName}"
				parent: ROOT Context
				ServletContext
				ServletConfig
				Namespace: "${ServletName}-servlet"
				ConfigLocation: this.contextConfigLocation
				add ApplicationListener: new SourceFilteringListener(wac, new ContextRefreshListener())
			postProcessWebApplicationContext() - Empty
			invoke refresh() on ServletSpec Context
			onRefresh(ServletSpec Context) - Empty
			Put ServletSpec Context in ServletContext with key: "FrameworkServlet.CONTEXT.${ServletName}"
		initFrameworkServlet() - Empty
		
		
		

DispatcherServlet - MVC related job, Get bean from context & set to fields
	onRefresh()
		initStrategies()
			initMultipartResolver() - Get bean with id "multipartResolver" & put in multipartResolver
			initLocaleResolver() - Get bean with id "localeResolver" & put in localeResolver
			initThemeResolver() - Get bean with id "themeResolver" & put in themeResolver
			initHandlerMappings() - Get bean with id "handlerMapping" or type of "HandlerMapping"(base on value of detectAllHandlerMappings) & put in handlerMappings
			initHandlerAdapters() - Get bean with id "handlerAdapter" or type of "HandlerAdapter"(base on value of detectAllHandlerAdapters) & put in handlerAdapters
			initHandlerExceptionResolvers() - Get bean with id "handlerExceptionResolver" or type of "HandlerExceptionResolver"(base on value of detectAllHandlerExceptionResolvers) & put in handlerExceptionResolvers
			initRequestToViewNameTranslator() - Get bean with id "viewNameTranslator" & put in viewNameTranslator
			initViewResolvers() - Get bean with id "viewResolver" or type of "ViewResolver"(base on value of detectAllHandlerAdapters) & put in viewResolvers
	
	
	doService()
		if it is a include request, take a snap shot of request attributes
		put webApplicationContext, localeResolver, themeResolver, themeSource in request
		doDispatch()
			checkMultipart() -  if it is multipart request, change request to MultipartHttpServletRequest 
			Get HandlerExecutionChain from all HandlerMappings one by one, if not found set response code 404, return.
			getHandlerAdapter() - find a supported HandlerAdapter from handlerAdapters for Handler
			if GET & request.getDateHeader("If-Modified-Since") > lastModified from HandlerAdapter, set response code 304, return.
			if GET or HEAD response.setDateHeader("Last-Modified", lastModified)
			Get Interceptors from HandlerExecutionChain & execute before
			ModelAndView = HandlerAdapter.handle(processedRequest, response, mappedHandler.getHandler())
			if !mv.hasView(), mv.setViewName(viewNameTranslator.getViewName(request));
			Get Interceptors from HandlerExecutionChain & execute after
			render view
			
			
		
		
		
		
		
		
SpringContextLoaderListner
Static:
	Load org/springframework/web/context/ContextLoader.properties to defaultStrategies



contextInitialized()
	initWebApplicationContext()
		check whether ROOT Context exist or not
		loadParentContext()
			if "parentContextKey" configed:
				BeanFactoryLocator locator = ContextSingletonBeanFactoryLocator.getInstance(${value of "locatorFactorySelector"});
				this.parentContextRef = locator.useBeanFactory(parentContextKey);
				return (ApplicationContext) this.parentContextRef.getFactory();
		ROOT Context = createWebApplicationContext(servletContext, parent)
			Get Class Type from value of "contextClass" in web.xml, value of "WebApplicationContext" in defaultStrategies
			new instance
			ROOT Context set: Id, parent, ServletContext, ConfigLocation(value of "contextConfigLocation")
			customizeContext() - Empty
			wac.refresh()
		put ROOT Context in ServletContext
		put ROOT Context to currentContext or currentContextPerThread



****** spring integration
Refer to EIP/EIP.txt


Structure:
	Messages
	
	MessageChannel - represents the "pipe" of a pipes-and-filters model
		PollableChannel (buffering)
			QueueChannel (has  point-to-point  semantics, FIFO)
				<int:channel id="queueChannel">
					<queue capacity="25"/>
				</int:channel>
			PriorityChannel (priority is determined by the 'priority' header within each message)
				<int:channel id="priorityChannel">
					<int:priority-queue capacity="20"/>
				</int:channel>
			RendezvousChannel (enables a "direct-handoff" scenario where a sender will block until another party  invokes  the  channel's  receive() method  or  vice-versa)
				<int:channel id="rendezvousChannel"/>
					<int:rendezvous-queue/>
				</int:channel>

	
		SubscribableChannel (non-buffering)
			PublishSubscribeChannel (broadcasts  any  Message  sent  to  it  to  all  of  its subscribed  handlers)
				<int:publish-subscribe-channel id="exampleChannel"/>
			DirectChannel ( default channel type within Spring Integration, point-to-point, dispatches Messages directly to a subscriber, single thread to perform the operations on "both sides" of the channel)
				<int:channel id="exampleChannel"/>
				<int:channel id="failFastChannel">
					<int:dispatcher failover="false"/>
				</channel>
			ExecutorChannel (similar to DirectChannel, but TaskExecutor to perform the dispatch)
				<int:channel id="executorChannel">
					<int:dispatcher task-executor="someExecutor"/>
				</int:channel>
	
	Message Endpoints - represents the "filter" of a pipes-and-filters model
		Transformer
			transformer
			object-to-string-transformer
			payload-serializing-transformer
			payload-deserializing-transformer
			object-to-map-transformer
			map-to-object-transformer
			object-to-json-transformer
			json-to-object-transformer
		Enricher
			enricher
			header-enricher
		Claim Check Transformer
			claim-check-in
			claim-check-out
		Filter
			filter
			header-filter
		Router
			router
			payload-type-router
			header-value-router
			recipient-list-router
			exception-type-router
		Splitter
			splitter
		Aggregator
			aggregator
		Resequencer
			resequencer
		Service Activator
			service-activator
		Channel Adapter
			logging-channel-adapter
			inbound-channel-adapter
			outbound-channel-adapter
		Gateway
			gateway
		Bridge
			bridge
		Delayer
			delayer
		Chain
			chain
		Control Bus
			control-bus
		Channel Interceptor
			channel-interceptor
		


What is Spring Integration
	Spring Integration provides an extension of the Spring programming model to support the well-known Enterprise Integration Patterns. 
	It enables lightweight messaging within Spring-based applications and supports integration with external systems via declarative adapters. 
	Those adapters provide a higher-level of abstraction over Spring's support for remoting, messaging, and scheduling. 
	Spring Integration's primary goal is to provide a simple model for building enterprise integration solutions while maintaining the separation of concerns that is essential for producing maintainable, testable code

	Spring Integration takes this concept one step further, where POJOs are wired together using a messaging paradigm and individual components may not be aware of other components in the application. 

	In addition to wiring together fine-grained components, Spring Integration provides a wide selection of channel adapters and gateways to communicate with external systems. Channel Adapters are used for one-way integration (send or receive); gateways are used for request/reply scenarios (inbound or outbound). 

	ApplicationContext plays the central role of a Message Bus


Message Endpoints
	Estimated Structure:
		MessageEndpoint
			Consumer
				MessageHandler
			MessageSource


	When Message Endpoints (Channel Adapters) are connected to channels and instantiated, they produce one of the following 2 instances:
		EventDrivenConsumer
		PollingConsumer

	Message Endpoints are responsible for connecting the various messaging components to channels. 

	Spring Integration provides two different endpoint implementations to accommodate these two types of consumers. Therefore, the consumers themselves can simply implement the callback interface. When polling is required, the endpoint acts as a container for the consumer instance.
	Spring Integration provides two endpoint implementations that host these callback-based handlers and allow them to be connected to Message Channels.
		EventDrivenConsumer consumer = new EventDrivenConsumer(channel, exampleHandler);
		PollingConsumer consumer = new PollingConsumer(channel, exampleHandler);
	After being parsed, these endpoint elements produce an instance of either the PollingConsumer or the EventDrivenConsumer depending on the type of the input-channel that is referenced
	
	Many endpoints are composite beans; this includes all consumers and all polled inbound channel adapters. 
		Consumers (polled or event- driven) delegate to a MessageHandler; 
		polled adapters obtain messages by delegating to a MessageSource. 
	
	Endpoint contains Consumer and Adapter?
	
	MessageHandler interface is implemented by many of the components
		it is used by a Message Consumer for actually handling the consumed Messages

	MessageHandlers are registered with the application context with a bean id someConsumer.handler (where 'consumer' is the endpoint's id attribute). 
	MessageSources are registered with a bean id somePolledAdapter.source, again where 'somePolledAdapter' is the id of the adapter.

	
	Gateway
		The primary purpose of a Gateway is to hide the messaging API(API to operate with channel) provided by Spring Integration. 
		It allows your application's business logic to be completely unaware of the Spring Integration API and using a generic Gateway, your code interacts instead with a simple interface, only.
	
		A Gateway will create a temporary point-to-point reply channel which is anonymous and is added to the Message Headers with the name replyChannel. When providing an explicit default-reply-channel (reply-channel with remote adapter gateways), you have the option to point to a publish-subscribe channel, which is so named because you can add more than one subscriber to it. Internally Spring Integration will create a Bridge between the temporary replyChannel and the explicitly defined default-reply-channel.
	
		gateway invoked by model to send object to message channel
		gateway interface is defined by java interface, impl is auto generated
	
		model invoke messaging gateway
	
		Sync Gateway - single-threaded. 
			If a component downstream is still running (e.g., infinite loop or a very slow service), then setting a reply-timeout has no effect and the Gateway method call will not return until such downstream service exits (via return or exception). 
		Async Gateway - multi-threaded. 
			If a component downstream is still running (e.g., infinite loop or a very slow service), in a multi-threaded message flow setting the reply-timeout will have an effect by allowing gateway method invocation to return once the timeout has been reached
	
	
	Service Activator
		the endpoint type for connecting any Spring-managed Object to an input channel so that it may play the role of a service. 
	
	
	Adding Behavior to Endpoints
		request-handler-advice-chain
			add aop on handler
		
		Retry Advice
			aop on handler exception to do retry
		
		Circuit Breaker Advice
			The general idea of the Circuit Breaker Pattern is that, if a service is not currently available, then don't waste time (and resources) trying to use it. The o.s.i.handler.advice.RequestHandlerCircuitBreakerAdvice implements this pattern. When the circuit breaker is in the closed state, the endpoint will attempt to invoke the service. The circuit breaker goes to the open state if a certain number of consecutive attempts fail; when it is in the open state, new requests will "fail fast" and no attempt will be made to invoke the service until some time has expired.
		
		Expression Evaluating Advice
			It provides a mechanism to evaluate an expression on the original inbound message sent to the endpoint. Separate expressions are available to be evaluated, either after success, or failure.
	

System Management
	Notification Listening Channel Adapter
	Notification Publishing Channel Adapter
	Attribute Polling Channel Adapter
	Tree Polling Channel Adapter
	Operation Invoking Channel Adapter
	enables Message-driven invocation of any managed operation exposed by an MBean.
	Operation Invoking Outbound Gateway
	Similar to the operation-invoking-channel-adapter Spring Integration also provides a operation-invoking- outbound-gateway, which could be used when dealing with non-void operations and a return value is required.

	MBean Exporter
		<int-jmx:mbean-export id="integrationMBeanExporter" default-domain="my.company.domain" server="mbeanServer"/>
		@EnableIntegrationMBeanExport
	
	Message History
		<int:message-history/>
		Now every named component (component that has an 'id' defined) will be tracked. The framework will set the 'history' header in your Message. Its value is very simple - List<Properties>.
		@EnableMessageHistory
	
	Message Store
		you are able to inject your own implementation of the Serializer and/or Deserializer strategy interfaces into some MessageStore implementations (such as JdbcMessageStore) to change the behaviour of serialization and deserialization.
		if one of the headers contains an instance of some Spring Bean, upon deserialization you may end up with a different instance of that bean, which directly affects some of the implicit headers created by the framework (e.g., REPLY_CHANNEL or ERROR_CHANNEL). Currently they are not serializable, but even if they were, the deserialized channel would not represent the expected instance.
	
	Metadata Store
		Many external systems, services or resources aren't transactional (Twitter, RSS, file system etc.) and there is no any ability to mark the data as read. Or there is just need to implement the Enterprise Integration Pattern Idempotent Receiver in some integration solutions. To achieve this goal and store some previous state of the Endpoint before the next interaction with external system, or deal with the next Message, Spring Integration provides the Metadata Store component being an implementation of the org.springframework.integration.metadata.MetadataStore interface with a general key-value contract.
		The Metadata Store is designed to store various types of generic meta-data (e.g., published date of the last feed entry that has been processed) to help components such as the Feed adapter deal with duplicates. 
	
	Control Bus
		As described in (EIP), the idea behind the Control Bus is that the same messaging system can be used for monitoring and managing the components within the framework as is used for "application-level" messaging. 
		<int:control-bus input-channel="operationChannel"/>
		The Control Bus has an input channel that can be accessed for invoking operations on the beans in the application context. It also has all the common properties of a service activating endpoint
		The Control Bus executes messages on the input channel as Spring Expression Language expressions. It takes a message, compiles the body to an expression, adds some context, and then executes it. The default context supports any method that has been annotated with @ManagedAttribute or @ManagedOperation.
	
	Orderly Shutdown
		MBean exporter provides a JMX operation stopActiveComponents, which is used to stop the application in an orderly manner.
		The first step calls beforeShutdown() on all beans that implement OrderlyShutdownCapable.
		The second step stops any active channels, such as JMS- or AMQP-backed channels.
		The third step stops all TaskSchedulers, preventing any new scheduled operations (polling etc).
		 The fourth step stops all TaskExecutors, preventing any new tasks from running.
		The fifth step stops all MessageSources.
		The sixth step waits for any remaining time left, as defined by the value of the long parameter passed in to the operation. This is intended to allow any in-flight messages to complete their journeys. It is therefore important to select an appropriate timeout when invoking this operation.
		The seventh step calls afterShutdown() on all OrderlyShutdownCapable components. This allows such components to perform final shutdown tasks (closing all open sockets, for example).


SpringIntegrationEndpoints
FTP/FTPS Adapters
	Inbound  Channel  Adapter
		a special listener that will connect to the FTP server and will listen for the remote directory events (e.g., new file created) at which point it will initiate a file transfer
		
		consists of two tasks:  
			1) Communicate with a remote server in order to transfer files from a remote directory to a local directory.  
			2) For each transferred file, generate a Message with that file as a payload and send it to the channel identified by the 'channel' attribute.
		
	Outbound  Channel  Adapter
		relies  upon  a  MessageHandler implementation  that  will connect  to  the  FTP  server  and  initiate  an  FTP  transfer  for  every  file  it  receives  in  the  payload  of incoming Messages. 
	
	
	Outbound  Gateway
		provides a limited set of commands to interact with a remote FTP/FTPS server.
			ls (list files)
			get (retrieve file)
			mget (retrieve file(s))
			rm (remove file(s))
			mv (move/rename file)
			put (send file)
			mput (send multiple files)
	
	These Adapters internally use SessionFactory to do connection
		Every time an adapter requests a session object from its  SessionFactorythe session is returned from a session pool maintained by a caching wrapper around the factory. 
		A Session in the session pool might go stale (if it has been disconnected by the server due to inactivity) so the SessionFactory will perform validation to make sure that it never returns a stale session to the adapter. 
		If a stale session was encountered, it will be removed from the pool, and a new one will be created.
		
	Components:
		MetadataStore
			A store to store metadata
			E.g. file name, file modified time
		



****** spring io

POM hierarchy:
	org.springframework.boot:spring-boot-dependencies
	org.springframework.boot:spring-boot-starter-parent
	io.spring.platform:platform-bom



****** spring security
Spring  Security  provides  a  comprehensive  security  solution  for  J2EE-based  enterprise  software applications. 
	Basically it contains a lot of security related checkers
	
	Core classes: 
		AuthenticationManager (default implementor is ProviderManager)
			delegate to a list of AuthenticationProvider 
			
			
		AuthenticationProvider (default implementor is DaoAuthenticationProvider)
			leverage UserDetailsService to load UserDetails
				UserDetailsService
					JdbcDaoImpl is the implementor to connect to DB
				UserDetails
					contains GrantedAuthority
			check password in UsernamePasswordAuthenticationToken from request against the one from loaded UserDetails
			return Authentication

		
	<http>/<remember-me>/attribute:key
		Together with username,password,expirationTime,key to be encrypted & stored in cookie: SPRING_SECURITY_REMEMBER_ME_COOKIE. 
		So that the cookie can only be used with in the application who generated it.

	
	ACL - Access Control List
		Support domain object instance level security check


	Filters:
		CsrfFilter
			It's a OncePerRequestFilter
			Step:
				Get/Generate token from CsrfTokenRepository(default impl will retrieve it from session)
				Set it to request attribute
				if request is: GET|HEAD|TRACE|OPTIONS, doFilter & return
				Get client passed token from request header or parameter
				Compare token from client with token in server
				if not match invoke accessDeniedHandler & return
				otherwise, doFilter
				
				
		SecurityContextPersistenceFilter
			Get SecurityContext from SecurityContextRepository & populates to SecurityContextHolder
			doFilter()
			Save SecurityContext to SecurityContextRepository & clear SecurityContextHolder
			
			Note:
				Different SecurityContextPersistenceFilter can contains different SecurityContextRepository
		
		UsernamePasswordAuthenticationFilter
			Only Intercept, Process & Stop
				default authenticate URL(/j_spring_security_check) - xml config
				configed authenticate URL - java config
			attemptAuthentication()
				Get username & password from request & invoke AuthenticationManager.authenticate()
			
		AbstractAuthenticationProcessingFilter
			check whether request requires authentication
			if true
				attemptAuthentication()
				if pass
					sessionStrategy.onAuthentication()
					if continueChainBeforeSuccessfulAuthentication -> doFilter()
					successfulAuthentication()
				if fail
					unsuccessfulAuthentication()
					
			if false
				doFilter()
			
			
		ConcurrentSessionFilter
			Check SessionRegistry.SessionInformation.Expired
			if true - logout & redirect to expiredURL
			if false - update "last update" date/time
			
		BasicAuthenticationFilter
			Only Intercept, Process & Stop
				requests with header: Authorization
		
		LogoutFilter
			Only Intercept, Process & Stop
				default logout URL(/j_spring_security_logout) - xml config
				configed logout URL - java config
			
			
		DefaultLoginPageGeneratingFilter
			Only Intercept, Process & Stop
				default login/out page URL(/spring_security_login) - xml config
				configed login/out page URL - java config
			
			
		ExceptionTranslationFilter
			Only catch & process Exceptions throw by further Filter & Other code
				handleSpringSecurityException()
					sendStartAuthentication() / accessDeniedHandler.handle()
					
		FilterSecurityInterceptor			
			Performs security handling of HTTP resources
			
			
	Java Config:
		Config AuthenticationManagerBuilder
			Inject it into any method & process
			
		Config WebSecurity & HttpSecurity
			Extend WebSecurityConfigurerAdapter, add @Configuration & overwrite method: configure(HttpSecurity)/configure(WebSecurity)
			
		Config method security
			Add @EnableGlobalMethodSecurity 
			Extend GlobalMethodSecurityConfiguration




****** spring session
Spring Session
	Spring Session provides an API and implementations for managing a user's session information.
	
	It also provides transparent integration with:
		HttpSession - allows replacing the HttpSession in an application container
			Clustered Sessions - Spring Session makes it trivial to support clustered sessions without being tied to an application container specific solution.
			Multiple Browser Sessions - Spring Session supports managing multiple users' sessions in a single browser instance (i.e. multiple authenticated accounts similar to Google).
			RESTful APIs - Spring Session allows providing session ids in headers to work with RESTful APIs
		WebSocket - provides the ability to keep the HttpSession alive when receiving WebSocket messages
		
	
	Implementation:
		How HttpSession Integration Works
			create SessionRepositoryRequestWrapper extends HttpServletRequestWrapper
				overwrite getSession() to get session from Repository
			create SessionRepositoryFilter implements Filter
				wrap original request with SessionRepositoryRequestWrapper
				
		Multiple HttpSessions in Single Browser
			store multiple session id in one cookie.
				E.g.
					0 7e8383a4-082c-4ffe-a4bc-c40fd3363c5e 1 1d526d4a-c462-45a4-93d9-84a39b6d44ad
						first session: 7e8383a4-082c-4ffe-a4bc-c40fd3363c5e
						second session: 1d526d4a-c462-45a4-93d9-84a39b6d44ad
			use parameter _s to indicate which session id should be used
				E.g.
					_s=0
					_s=1		
					
		HttpSession & RESTful APIs
			Spring Session can work with RESTful APIs by allowing the session to be provided in a header.
			
		WebSocket Integration
			use AbstractSessionWebSocketMessageBrokerConfigurer instead of AbstractWebSocketMessageBrokerConfigurer 




****** spring social
With Spring Social, your application can play the part of the service consumer, interacting with a service provider on behalf of its users. 

	For the flow refer to OAuth
	
	spring-social-core - Service Provider 'Connect' Framework
	
	
	Connection:
		Provider's API
			Normally this is a remote API & published as a web service
			
			
		ApiBinding
			Bind method to remote API
			
			
		ServiceProvider
			Obtain authorization credentials
				Normally delegate to OAuth1/2Operations
			Factory for ApiBinding instances
			
			
		OAuth1/2Operations
			Perform OAuth dance
			Default impl is OAuth1/2Template
		
		
		Connection
			Uniform interface to manipulate ApiBinding via ApiAdapter
		
		
		ApiAdapter
			Adapter between ApiBinding and Connection
			
			
		ConnectionFactory
			Wrap ServiceProvider
			Factory for Connection instances
		
		
		ConnectionFactoryLocator
			Locate ConnectionFactory
			Default Impl is ConnectionFactoryRegistry
		
		
		Structure:
			Interface: 
				Provider Specific Interface ------ Common Interface
					ApiBinding --- ApiAdapter --- Connection
					ServiceProvider ------ ConnectionFactory
			Account Mapping:
				One2Many Mapping from LocalUserId to Connection.key.providerId & Connection.key.providerUserId
		
		
	Web:
		ConnectController
			MVC controller to handle request & delegate to ConnectionFactory				
			
			
	Signing In:
		ProviderSignInController - organizer
			MVC controller to handle request & do signin
			Below component will be injected into ProviderSignInController
				ConnectionFactoryLocator
				UsersConnectionRepository
				SignInAdapter
	
	
		Signing up
			Explicitly
				Rely on oauth1/2Callback() - Redirect to signup URL
				You need to write page & controller to retrieve LocalUserId from page & invoke ProviderSignInUtils.handlePostSignUp() to put to repository map
			Implicitly
				Rely on ConnectionSignUp to calculate LocalUserId, UsersConnectionRepository will put it to repository map
				 
		
		Components:
			ProviderSignInController
				oauth1/2Callback()
					connect to provider to create Connection Object and UsersConnectionRepository.findUserIdsWithConnection()
						if linked LocalUserId available:
							UsersConnectionRepository.createConnectionRepository().updateConnection()
							SignInAdapter.signIn()
						else
							Redirect to signup URL
		
		
			UsersConnectionRepository
				Maintain a repository map from LocalUserId to ConnectionRepository
				
				findUserIdsWithConnection()
					Get linked LocalUserId base on Connection object
						Use connection.key.providerId & connection.key.providerUserId as key
						
					if linked LocalUserId not available & ConnectionSignUp available
						invoke ConnectionSignUp.execute() to get linked LocalUserId
						createConnectionRepository().addConnection()
				
				createConnectionRepository()
					create empty ConnectionRepository and register to repository map


			ConnectionSignUp
				execute()
					calculate LocalUserId base on Connection
					
			
			SignInAdapter
				Sign system with info: LocalUserId & Connection
			
			ProviderSignInUtils.getConnection()
				to get Connection object
		
			ProviderSignInUtils.handlePostSignUp()/doPostSignUp()
				UsersConnectionRepository.createConnectionRepository().addConnection()
			
		
	

****** spring webflow
Advantage:
Control all the flows in one xml file.
While Struts put flow control in action config(forward config) & page form's action parameter.

This is make it possible to view the hole flow in one xml or make the hole flow visible (This is what JPP doing).



Ajax partical render:
Only works when Accept in request header is: text/html;type=ajax.
which fragment will be rendered depends on 
	1, render in flow config 
		(I don't think it's a good approach 
		because flow config should only contains flow logic, for view rleated logic pls leave it to JSP)
	2, request parameter fragments


***** ssh
1, ssh client connect to remote ssh server
2, ssh server start shell(configable)
3, pipeline that shell to connection

Secure Shell
	Generate Key:
		ssh-keygen -t rsa


	Key location & name:
		~/.ssh/id_rsa			->	default private key
		~/.ssh/id_rsa.pub		->	default public key
		~/.ssh/known_hosts		->	public keys for already know hosts
		~/.ssh/authorized_keys		-> public keys for authorized keys (public key corresponding private key can login without password)
	
	
	Key format:
		Private Key:
			-----BEGIN RSA PRIVATE KEY-----
			${private key string}
			-----END RSA PRIVATE KEY-----
			
		Public Key:
			ssh-rsa
			${public key string}					
		


***** struts

ActionMessage -  only contains String key & Object values[]

ActionMessageItem - only contains List list & int iOrder

ActionMessages - only contains HashMap messages
	add(String property, ActionMessage message)
		Get message.ActionMessageItem.list base on property, put message to this list
	add(ActionMessages messages)
		Get ActionMessage from ActionMessages & put in messages
	
		
ValidatorPlugIn
	init
		new ValidatorResources
		ValidatorResourcesInitializer.initialize(resources, bis, false) - Get data from xml
		resources.process()
		put resources to ServletContext


Validator - Contains ValidatorResources & other infos


***** supervisor
Supervisor
	A Process Control System
	
	install in CentOS:
		sudo yum install python-setuptools
		sudo easy_install supervisor
		
	Creating a Configuration File
		echo_supervisord_conf > /etc/supervisord.conf
    
    Start deamon: supervisord
    Start control: supervisorctl


***** thymeleaf
Thymeleaf
	Template Engine Framework (Template Engine created base on?)
	
	Define DOM Node & corresponding Dialect(a set of Processor), so that Framework can parse Template to DOM & invoke Dialects to process

	Construction(Construct Template Engine base on Template Engine Framework):
		Framework define basic DOM Node & corresponding Processor, Dialect define extend DOM node & corresponding Processor
	Runtime:
		Framework Parser parse Template to DOM, Framework invoke Processor to process DOM



Templates:
	Natural Template(refer to Template/Template.txt)
	
	Thymeleaf allows you to process six kinds of templates, each of which is called a Template Mode:
		XML
		Valid XML
		XHTML
		Valid XHTML
		HTML5
		Legacy HTML5
		
	All of these modes refer to well-formed XML files except the Legacy HTML5 mode



Comments
	<!-- ... -->
		Standard HTML/XML comment
		comments ignore by parser & browser
	<!--/* and */-->
		parser-level comment
		comments will be removed by parser
	<!--/*/ and /*/-->
		prototype-only comment
		comments still be processed by parser, but it will be ignored by browser



Standard Expression
	#{...}
		Message Expressions
		
	${...}
		Variable Expressions
		
	*{...}
		Selection Variable Expressions
			evaluates expressions on selected objects
			as long as there is no selected object, the dollar and the asterisk syntaxes do exactly the same
			When an object selection is in place, the selected object will be also available to dollar expressions as the #object expression variable
	
	@{...}
		Link URL Expressions
			Absolute URLs, like http://www.thymeleaf.org
			Relative URLs, which can be:
				Page-relative, like user/login.html
				Context-relative, like /itemdetails?id=3 (context name in server will be added automatically)
				Server-relative, like ~/billing/processInvoice (allows calling URLs in another context (= application) in the same server.
				Protocol-relative URLs, like //code.jquery.com/jquery-2.0.3.min.js

	

Standard Dialect
	Setting Body
		th:text
			set body of the tag it is in
		th:utext
			set body of the tag it is in (unescaped text)
	
	Setting Attribute:
		th:${html attribute}
			set corresponding html attribute
		th:attr
		th:attrappend
			append value to exist attribute
		th:attrprepend
			prepend value to exist attribute
		th:classappend
			append value to exist class
		th:styleappend
			append value to exist style

	Iteration:
		th:each
	
	Condition:
		th:if
		th:unless
		th:switch
		th:case
	
	Layout:
		th:fragment
			This should not be used, as we can include fragment via css selector
		th:include
		th:replace
		th:assert
		th:remove
	
	Local Variables
		th:with
		th:object
	
	Inlining:
		th:inline
			process:
				[[...]] - text
				/*[[...]]*/ - add code to result & remove here after code
				/*[+...+]*/ - add code to result
				/*[- */ and /* -]*/ - remove code from result
				
			
	Note: "th:" can replace with "data-th-"
	
	th:block
		The only element processor
		A mere attribute container that allows template developers to specify whichever attributes they want
		Thymeleaf will execute these attributes and then simply make the block dissapear without a trace
		especially useful when used in combination with <!--/*/ and /*/-->
	
	

Layout Dialect
	layout:fragment
		fragment parse logic:
			1, find top layout & parse
			2, when encounter layout:fragment, search same name layout:fragment in child layout & merge into it
				Merge logic:
					element in child page directly overwrite target element (except attribute with values)
			3, go on parse the merged page


Spring Dialect
	Note:
		To use this Dialect need to use SpringTemplateEngine instead of normal TemplateEngine

	SpEL instead of OGNL
	
	${@myBean}
		Access Spring Bean

	*/${{...}}
		Similar to */${...}, but apply Conversion Service
		
	#conversions
		Provide functions to do conversion
		E.g.
			#conversions.convert(val,'String')
			
	th:field
	th:errors
	th:errorclass
	
	#themes.code(...)
		equivalent to  the spring:theme JSP custom tag
	

Component:
	TemplateEngine 
		Execute template
		can have multiple TemplateResolver
		can have multiple MessageResolver
		can have multiple Dialect
	
	TemplateResolver
		Determining how our templates will be accessed
			retrieve template
			template mode
			amount of time that a parsed template living in cache
			encoding
			cache
			
	IMessageResolver
		Resolve messages
		Default impl is: StandardMessageResolver
			expects to find messages in .properties files in the same folder and with the same name as the template
		
		
	IContext
		Contain all the data required for an execution of the Template Engine in a variables map, and also reference the Locale that must be used for externalized messages.
		Impl:
			Context
				Add a context variable called execInfo contains:
					The template name (${execInfo.templateName})
					The current date and time (${execInfo.now})
					
			WebContext
				Add all the request attributes to the context variables map
				Add a context variable called param containing all the request parameters
				Add a context variable called session containing all the session attributes
				Add a context variable called application containing all the ServletContext attributes		
		
		
		

***** urbancode
UrbanCode Deploy
	Application Deployment Automation
	
	
***** VIM
Vim
	Vim is a highly configurable text editor built to enable efficient text editing. 
	It is an improved version of the vi editor distributed with most UNIX systems.

    Abstraction Operation Model
        Count + Action + Scope
            Count - Numbers
            Action - Move, Delete, Insert
            Scope - From(default: cursor) To
	
	Mode:
		Normal
		Visual
		Insert
		Replace
		
	
	Usage(Most commands are for Normal/Visual Mode):
		OPERATORS(CHANGES)
			d, p, y, r, c (deletes the word and places you in Insert mode)
		MOTIONS
			w, e, $, h, j, k, l, G, gg, %
		REPEATS
			numbers
		Search:
			/
		Other:
			:s, :!, :w, :r, :set <option>
		Change Mode:
			i a o O R c v
			
		The format for a change command is:
			operator   [number]   motion


	Meaning:
		a - append
		b - back word
		c - change
		d - delete
		e - end
		f - find
		g - go

		h - head
		i - insert
		j - join
		k
		l - low
		m - middle
		n - next

		o - open new line
		p - put
		q
		r - replace
		s
		t

		u - undo
		v - visual
		w - word
		x - delete
		y - yank
		z


***** webminifier
minify & conbine js also change html js import


***** worklignt

Eclipse Install
http://public.dhe.ibm.com/ibmdl/export/pub/software/mobile-solutions/worklight/wdeupdate/
http://public.dhe.ibm.com/ibmdl/export/pub/software/mobile-solutions/worklight/mtwwupdate/ 



***** wss4j
Web Services Security for Java
	Java implementation of the WS-Security specifications
		SOAP Message Security 1.1
		Username Token Profile 1.1
		X.509 Certificate Token Profile 1.1
		SAML Token Profile 1.1
		Kerberos Token Profile 1.1
		SOAP Messages with Attachments Profile 1.1
		Basic Security Profile 1.1


	Apply approach:
		Action based approach: WSS4J offers an "Action" based approach to applying WS-Security to a SOAP request or response
			Supported actions defined in class ConfigurationConstants
			Explicitly telling WSS4J what WS-Security functionality to perform on a request
				E.g.
					"UsernameToken, "Signature", "Encrypt", "Timestamp", "SAMLTokenSigned"
			
			Config:
				"user" can be either the username to insert into a UsernameToken, or the keystore alias to use for either signature or encryption
				"signatureUser" and "encryptionUser" configuration tags override the more general "user" tag
				specify a CallbackHandler implementation to use to retrieve passwords
					On the sending side, this is used to retrieve a password to insert into a UsernameToken and to decrypt a private key from a keystore for Signature. 
					On the receiving side, it is used to retrieve a password to validate a received UsernameToken, and to decrypt a private key from a keystore to use for decryption.
				
				specify a Crypto implementation if you are using Signature or Encryption
				For signature
					the path of this properties file can be referred to by the tag "signaturePropFile" and "encryptionPropFile" for outbound request
					"signatureVerificationPropFile" and "decryptionPropFile" for inbound requests"
				the Elements to sign or encrypt can be specified by the "signatureParts" and "encryptionParts" configuration tags. Both default to the SOAP Body
				
			
		WS-SecurityPolicy based approach: WSS4J can be configured for a SOAP request/response via WS-SecurityPolicy (recommend)
			WS-SecurityPolicy specification defines a set of WS-Policy expressions that can be used to define the security requirements of a web service
			Typically one or more policies are attached to the WSDL of a service, which conveys the security requirements of the service to the client
			A WS-SecurityPolicy aware stack such as Apache CXF or Apache Axis/Rampart can parse the policies and configure WSS4J appropriately
			 
		Standalone approach: WSS4J offers a low-level (DOM) API to construct/sign/encrypt/etc
		
	

***** yeoman
Yeoman is a workflow & a collection of tools & best practices to make web development better
	Contains:
		Yo - scafold out a new application
		Grunt - task runner
		Bower - dependency pkg manage
		
	Usage Steps:
		npm install -g yo 				# install yo, grunt, bower
		
		Normal Web App:
		npm install -g generator-webapp # install yo plugin for webapp generate
		yo webapp                      # scaffold out a skeleton web app project
		bower install underscore       # install a dependency for your project from Bower
		grunt                          # build the application for deployment

		AngularJS Web App:
		npm install -g generator-angular  # install yo plugin for angularjs generate
		yo angular                        # scaffold out a AngularJS project
		bower install angular-ui          # install a dependency for your project from Bower
		grunt test                        # test your app
		grunt server                      # preview your app
		grunt                             # build the application for deployment


***** requirejs

Refer to javascript/AMD.txt for more info

Shim:
	The shim config just delays loading of the files until dependencies are loaded, but does not do any auto-wrapping of define.
	For any shimmed script, its dependencies must be loaded before the shimmed script executes. This means either building its dependencies directly in the buid layer that includes the shimmed script, or loading its dependencies with a require([], function (){}) call, then doing a nested require([]) call for the build layer that has the shimmed script.


Optimize:
	Optimizer will analysis module code & change unnamed module to named module, so that they can combine to one js file:
		E.g.
			from:
				if (typeof define == "function" && define.amd_disable) return define(["exports"], mod); // AMD
			to:
				if (typeof define == "function" && define.amd_disable) return define('client-infra/app/scripts/vendor/jaydata/jaydata',["exports"], mod); // AMD

			Note: here is a bug on the analysis, define.amd_disable should be skiped.
			
			
Source Analysis:
	require() - line 1707: req = requirejs = function (deps, callback, errback, optional) {}
		context.require(deps, callback, errback)
			localRequire(deps, callback, errback)
				getModule(makeModuleMap(null, relMap))
				Module.init()
					require.load()
					
				
	require.createNode()
		create script element
	
	
	require.load()
		require.createNode()
		attach listener: context.onScriptLoad to created node
		set src attribute
		insert into page head
		
		
	context.onScriptLoad()
		var data = getScriptData(evt);
		context.completeLoad(data.id);


	getScriptData()
		removeListener from script node
		return {
                node: node,
                id: node && node.getAttribute('data-requiremodule')
            }

	completeLoad()
		takeGlobalQueue()
		get Module def from defQueue
		callGetModule(args)
		checkLoaded()
		
				
API:
	require.onResourceLoad - called after Module loaded


***** OData
OData - Open Data
	A standardized protocol
	
	for creating and consuming data APIs
	builds on core protocols like HTTP and commonly accepted methodologies like REST
	The result is a uniform way to expose full-featured data APIs.

	Metadata File Structure:
		Schema
			EntityType - Structured type with a key & may also NavigationProperty.
				Key
				Property - Ship actual data
				NavigationProperty - Ship NO actual data, only a link
			ComplexType - Structured type without a key. Can be used as type of EntityType property.
				Property
			Association
				End
				End
			EntityContainer
				EntitySet - Group of Entity(instance of EntityType)
				AssociationSet
					End
					End


	Atom Parse:
		EntitySet - <feed>
		Entity - <entry>
		NavigationProperty - <link>
		Property - <d:xxx>

***** OSGi
Open Service Gateway Initiative


A stand, just like JavaEE. 
	Infra Provider to provide container used to run bundles
	Service/Application Provider to provide bundles

Implements:
	felix & equinox are 2 implementions of OSGi specification/standard.
	Karaf & Aries are 2 set of OSGi conforming bundle run on felix/equinox.


Bundle is just a jar with a MANIFEST.MF

Below value used to control the bundle access domain:
MANIFEST.MF/Export-Package, MANIFEST.MF/Import-Package


java -jar org.eclipse.osgi_3.7.1.R37x_v20110808-1106.jar -console -> Start OSGi Env

osgi> install reference:file:bundles\com.hishark.osgi.dicquery_1.0.0.201201162317.jar -> Install bundle


-----------------------console start-----------------------
osgi> ss

Framework is launched.

id      State       Bundle
0       ACTIVE      org.eclipse.osgi_3.7.1.R37x_v20110808-1106
2       INSTALLED   com.hishark.osgi.dicquery_1.0.0.201201162317

-----------------------console end-----------------------
***** olingo
Components:
	ODataRequestHandler
		ODataContext
			ODataRequest
			ODataServiceFactory
			ODataService
	
	ODataService - Olingo Core Comp to handle requests
		Created by ODataServiceFactory.createService(ODataContext)
		Contains:
			Edm
			MetadataProcessor
			ServiceDocumentProcessor
			EntityProcessor
			EntitySetProcessor
			EntityComplexPropertyProcessor
			EntityLinkProcessor
			EntityLinksProcessor
			EntityMediaProcessor
			EntitySimplePropertyProcessor
			EntitySimplePropertyValueProcessor
			FunctionImportProcessor
			FunctionImportValueProcessor
			BatchProcessor
			ODataProcessor
				ODataContext
	
	
	EdmImplProv - Implements Edm
		Edm data provided by EdmProvider
	
	
	ODataSingleProcessorService - Implements ODataService
		Use ODataSingleProcessor(implements all processors) as all processors
		Create EdmImplProv(base on EdmProvider) as Edm

	
	EdmProvider:
		Maintain metadata data



Handle Flow:
	ODataSubLocator.handle()
		ODataRequestHandler.handle()
			new Dispatcher(ODataServiceFactory, ODataService).dispatch()
				ODataService.getXXXProcessor().XXX()


Bugs:
	java.lang.IllegalArgumentException: Not an entity: interface java.util.List when:
		@ManyToOne
		@JoinColumn(name = "order_id")
		private List<Step> stepList;


***** Nginx
nginx - engine x
	What's Nginx
		It's a: 
			HTTP server
			reverse proxy server
			a mail proxy server

	
	Runtime Process Structure
		One Master Process and several Worker Processes
			Master Process
				read and evaluate configuration
				maintain worker processes
			Worker Process
				do actual processing of requests
	
	
	Command
		nginx -s reload
			master process
				checks the syntax validity of the new configuration file
				tries to apply the configuration provided in it
				If this is a success, the master process starts new worker processes and sends messages to old worker processes, requesting them to shut down. 
				Otherwise, the master process rolls back the changes and continues to work with the old configuration. 
			Old worker processes
				receiving a command to shut down, stop accepting new connections and continue to service current requests until all such requests are serviced. After that, the old worker processes exit.
		
	
	Configuration (nginx.conf)
		Directive
			Simple Directive
				consists of the name and parameters separated by spaces and ends with a semicolon (;)
			Block Directive
				same structure as a simple directive, but instead of the semicolon it ends with a set of additional instructions surrounded by braces ({ and }). 
				
				Context
					If a block directive can have other directives inside braces, it is called a context
					inherits parent context's directives

				    	Main Context
				    		Top config is in implicit Context which is Main Context
				    	
		
		Note:
			Using include, you can also split configuration into a hierarchy of files, including file contents
			Support Variables
				$remote_addr contains the client IP address and $uri holds the current URI value
	
		Directive Details:
			http
				server
					listen
					root
					location
						proxy_pass
		
		
		
	Components:
		Proxy
			Cache
				Caching Processes
					cache loader
						activated only once, right after NGINX starts. It loads the meta information about the previously cached data into the shared memory zone
						works in iterations configured with parameters of the proxy_cache_path directive.
					cache manager
						activated periodically to check the state of the cache file storage. In particular, it removes the least recently used data when the size of the file storage exceeds the max_size parameter
			
			
			Load Balancing
				upstream directive define a named group
				
				Methods
					round-robin
					least_conn
					ip_hash
						support session "sticky" or "persistent"
				
				Health Monitoring
					Passive Health Monitoring
						fail_timeout
						max_fails
					Active Health Monitoring
						health_check
		
		
		Sharing Data with Multiple Worker Processes
			The zone directive is mandatory for health checks and runtime modification of the server group. However, other features of the server groups can benefit from the use of this directive as well.
		
		SSL
			SSL handshake
				It's the most CPU-intensive operation
				Two ways to minimize the number of these operations per client
					Enabling keepalive connections to send several requests via one connection
					Reusing SSL session parameters to avoid SSL handshakes for parallel and subsequent connections			
				Established before the browser sends an HTTP request
					So NGINX does not know the name of the requested server. Therefore, it may only offer the default server's certificate.
		
			SSL Certificate Chains
		
			Server Name Indication
				TLS extent
				Allows a browser to pass a requested server name during the SSL handshake
		
		Compression
			gzip on
			gzip_proxied on
			gzip_static on
			gunzip on
		
		Index Files
			autoindex
		
		Trying Several Options
			try_files
		
		Restricting Access
			allow
			deny
			auth_basic
	
		Limiting Access
			limit_conn_zone
			limit_conn
			limit_req_zone
			limit_req
			limit_rate
		
		Logging and Monitoring
			error_log
			log_format
			access_log


debug
Steps:
	Run nodejs app with arg: --debug to enable V8 debug service
	Install & run debug web interface: node-inspector
	Visit : http://127.0.0.1:8080/debug?port=5858 to debug



example
#upstream   cms-upstream{
#     ip_hash;
#     server server1.cms:3000 weight=1  max_fails=2 fail_timeout=30s;
#     server server2.cms:3000 weight=1  max_fails=2 fail_timeout=30s;
#}

server {
    listen       80;
    server_name  www.sharkxu.com;

    location  / {
        # Can NOT use $host:$server_port, as $host:$server_port may different from request header's Host
        # E.g. when another proxy in front of nginx
        proxy_set_header Host $http_host;
        proxy_set_header X-Forwarded-For $remote_addr;
        proxy_pass   http://cms:3000;
    }
}

#server {
#    listen       443 ssl;
#    server_name  www.sharkxu.com;
#
#    ssl on;
#    ssl_certificate      /etc/nginx/certs/cms.pem;
#    ssl_certificate_key  /etc/nginx/certs/cms.key;
#
#    location  / {
#        proxy_set_header Host $host:$server_port;
#        proxy_pass   http://cms:3000;
#    }
#}


***** primavera6
structure
Project Structure:
EPS(Enterprise Project Structure)
	Project
		WBS
			Activity
			
	

install
1, Create DB Instance(Oracle Server & Oracle Client both need to be installed)

2, Install DB release
	P6_R81_Client_Applications\Database\dbsetup.bat 
		Select create new DB
	
3, Install Client_Applications
	P6_R81_Client_Applications\setup.exe
		DB URL: //localhost:1521/xe

4, Install Compression Server
	


user type
admuser
privuser
pubuser
bgjobuser


***** nodejs
Chrome's JavaScript Runtime + Library
	Library:
		HTTP - HTTP Server
		
			
	__dirname - the parth of current file folder

***** connect
An extensible HTTP server framework
	Built on NodeJS HTTP Library
	

***** express
Web Application Framework
	Built upon Connect

***** npm
npm - nodejs package manager
	run on nodejs
	package.json - define the pkg dependencies
		scripts - An object hash of script commands that are run at various times in the lifecycle of your package. The key is the lifecycle event, and the value is the command to run at that point.
		main - A module ID that is the primary entry point to your program.
			That is, if your package is named foo, and a user installs it, and then does require("foo"), then your main module's exports object will be returned.
		bin - Install executable files into the PATH. (Seems only used for global install)
		
		
	Command: 
		npm install
		npm install <pkg>
		npm install <pkg>@<tag>
		npm install <pkg>@<version>
		npm install <pkg>@<version range>
		npm install <folder>
		npm install <tarball file>
		npm install <tarball url>
		npm install <git:// url>
		npm install <github username>/<github project>
		
	global packages are important, but best avoided if not needed
	
	Change pkg install temp folder:
		set TMPDIR=c:\temp
	

***** polymer
Polymer is a implementation of Web Components

Git Components:
	platform/ — The platform shims and polyfills.
	polymer/polymer.js — Polymer core
	polymer-elements/ — A collection of core utility elements.
	polymer-ui-elements/ — A collection of UI elements.
	projects/ — Larger examples, demos, and tools that use Polymer.
	toolkit-ui/ — older widget examples.
	more-elements/ — additional elements

The polyfill(s) parse element definitions and handle their upgrade asynchronously, so we should wait for the WebComponentsReady event before working with the node

Polymer supports declarative binding of events to methods in the component. It uses special on-event syntax to trigger this binding behavior, without the need for any glue code. 

The event handler is passed the following arguments: 
	inEvent: is the standard event object.
	inDetail: A convenience form of inEvent.detail.
	inSender: A reference to the node that declared the handler. This is often different from inEvent.target (the lowest node that received the event) and inEvent.currentTarget (the component processing the event), so Polymer provides it directly.

Change watchers
	All properties on Polymer elements can be watched for changes by implementing a propertyNameChanged handler. When the value of a watched property changes, the appropriate change handler is automatically invoked. 

Overriding a parent’s methods
	When you override an inherited method, you can call the parent’s method with this.super().

Firing custom events
	Polymer core provides a convenient fire() method for sending custom events.
	In cases where you need to fire an event after microtasks have completed, use the asynchronous version: asyncFire().
	fire(inType, inDetail, inToNode)
	If your element is within another Polymer element, you can use the special on-* handlers to deal with the event: <ouch-button on-ouch="myMethod"></ouch-button>

debug
	<script src="platform/platform.js" debug></script>
	By default a minified version of platform (platform.min.js) is loaded. Using debug loads platform.debug.js.
	
log
	<script src="platform/platform.js" log="bind,ready"></script>
	see polymer-logs.png

shadow
	Selects a Shadow DOM implementation: native for supported browsers or polyfill for unsupported browsers.
	<script src="platform/platform.js" debug shadow="polyfill"></script>

<polymer-element>:attributes
	attributes of <polymer-element> is a sign to perform bi-direction binding. Connect model attribute to custom element instance's node attribute.
	
RED layer: We get tomorrow's web through a set of polyfills. Keep in mind, those libraries go away over time as browsers adopt the new APIs.

YELLOW layer: Sprinkle in some sugar with polymer.js. This layer is our opinion on how to use the spec'd APIs, together. It also adds things like data-binding, syntatic sugar, change watchers, published properties...We think these things are helpful for building web component-based apps.

GREEN: The comprehensive set of UI components (green layer) is still in progress. These will be web components that use all of the red + yellow layers.


ShadowDOM/src/wrappers/Document.js

		

           
ShadowDOM/src/wappers.js
	forwardMethodsToWrapper()
		Overwrite methods in native Constructor.prototype with wrapped version
		Wrapped version Logic:
			wrapIfNeeded the invoke target to generate wrapper
			invoke wrapper's method of the same name
				
	wrap(node)
		assert isNative(node)
		node.polymerWrapper_ = new (getWrapperConstructor(node))(node)
		return node.polymerWrapper_
		
	isWrapper()
		object instanceof wrappers.EventTarget ||
		object instanceof wrappers.Event ||
		object instanceof wrappers.Range ||
		object instanceof wrappers.DOMImplementation
		
	isNative()
		object instanceof OriginalNode ||
		object instanceof OriginalEvent ||
		object instanceof OriginalWindow ||
		object instanceof OriginalRange ||
		object instanceof OriginalDOMImplementation;
		
	wrapIfNeeded()
		if !isWrapper() then wrap()	
		
	getWrapperConstructor(node)
		get prototype of node
		get prototype's corresponding constructor from constructorTable
		if available
			return it
		else 
			parentWrapperConstructor = getWrapperConstructor(prototype)
			GeneratedWrapper = createWrapperConstructor(parentWrapperConstructor);
			registerInternal(nativePrototype, GeneratedWrapper, node);
			return GeneratedWrapper;
	
	createWrapperConstructor(superWrapperConstructor)
		create constructor GeneratedWrapper
			call superWrapperConstructor on this 
			Copy superWrapperConstructor.prototype(create empty object & copy properties) and set to GeneratedWrapper.prototype 
			Change GeneratedWrapper.prototype.constructor to GeneratedWrapper



***** mylyn
Mylyn is used to manager tasks via eclipse plugin.

***** odoo
Install
	Refer to ansible/setupEnv.yml

Admin
	1, Go to http://xxxxxx:8069
	2, Create DB
	3, Config Application

***** OFBiz
OFBiz - Open For Business
	an open source product for the automation of enterprise processes
	
	Include:
		framework components
		business applications
			ERP 
			CRM 
			E-Business / E-Commerce
			SCM (Supply Chain Management) 
			MRP (Manufacturing Resource Planning)
			MMS/EAM (Maintenance Management System/Enterprise Asset Management)
			POS (Point Of Sale)
			


***** maven
Maven - A platform to run plugin goals

	mvn ${groupID}:${artifactID}:${version}:${goal}
		Execute plugin's GOAL (Mojo instance). 
			${groupID} - Default is org.apache.maven.plugins / org.codehaus.mojo
			${artifactID} - Short name is ${short name}-maven-plugin / maven-${short name}-plugin
			${version} - Default is latest
			
	mvn ${build phase}
		Execute the plugins' GOALs which bind to the build phase. 
		All execution goals must defined in effective-pom.


POM (Project Object Model)
	Maintain ALL project's info, extend Super POM. 

	
Config in parent POM project can shared by all Child Project & itself
	But Build Setting(how to build) should only be shared by non-POM project, as POM project build is very different from other project
	To share Config only to child project, here is the workaround:
		Put Config in profile:
			<profile>
				<id>child</id>
				<activation>
					<file>
						<missing>nobuild.txt</missing>
					</file>
				</activation>
			</profile>
		Add nobuild.txt to POM project to avoid this profile


Plugin
	A set of goals
		goal
			provide:
				functionality
				execution
					implicit execution:
						default-${goal} execution
						default-cli execution
					explicit execution:
						default execution
						non-default execution
			
	merge:
		same plugin defined in main & profile build execution config will be merged.
		merge logic:
			main build plugin is base, if not null config available in profile build plugin, then overwrite.
				
	
Stage Repo
	Stage Repo is a temp repo normally used to sync artifacts to release repo
	Normally this repo will be removed after sync to release repo


overlays
Overlay is used to config overwrite policy when one war depends on another war.


PROFILE
Activate profile will merge to existing config, if same config available it will overwrite.
Inheritance:
	When activated, they are applied directly to the parent pom, prior to that parent being used for inheritance into the child.

properties
Implicit Properties:
project.X - pom.xml
setting.X -setting.xml
env.X - system env
java.X - java env

Explicit Properties:
X - project.properties.X / command -D parameters 


Note:
	build.plugins.plugin.*.configuration.X only set the plugin's parameter nothing to do with properties discussed here
	But you can specify property as parameter value in Mojo define. 

snapshot
SNAPSHOT Version(Opposite to  RELEASE version)
	Just append "-SNAPSHOT" after version no. maven will automaticly handle it as SNAPSHOT version
	Multiple jars in repository with name: ${jar name}-20120312.071200-17.jar
	maven-metadata.xml introduced  to maintain the SNAPSHOT version info

useful comand:
deploy jar:
	mvn org.apache.maven.plugins:maven-deploy-plugin:2.8.2:deploy-file -Dfile=Sdk4J.jar -Djavadoc=Sdk4J-javadoc.jar -Dsources=Sdk4j-sources.jar -Durl=https://oss.sonatype.org/service/local/staging/deploy/maven2 -DgroupId=net.gplatform -DartifactId=Sdk4J -Dversion=2.0 -DrepositoryId=sonatype-oss-stage

sign & deploy jar:
	mvn org.apache.maven.plugins:maven-gpg-plugin:1.5:sign-and-deploy-file -Dfile=Sdk4J.jar -Djavadoc=Sdk4J-javadoc.jar -Dsources=Sdk4j-sources.jar -Durl=https://oss.sonatype.org/service/local/staging/deploy/maven2 -DgroupId=net.gplatform -DartifactId=Sdk4J -Dversion=2.0 -DrepositoryId=sonatype-oss-stage

sign & deploy with pom:
	mvn org.apache.maven.plugins:maven-gpg-plugin:1.5:sign-and-deploy-file -DpomFile=Sdk4J.pom -Dfile=Sdk4J.jar -Djavadoc=Sdk4J-javadoc.jar -Dsources=Sdk4j-sources.jar -Durl=https://oss.sonatype.org/service/local/staging/deploy/maven2 -DrepositoryId=sonatype-oss-stage
	add -Dgpg.passphrase=thephrase to avoid enter password everytime
	central repository valid pom example:
		<project xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd" xmlns="http://maven.apache.org/POM/4.0.0"
		    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
		  <modelVersion>4.0.0</modelVersion>
		  <groupId>net.gplatform</groupId>
		  <artifactId>Sdk4J</artifactId>
		  <version>2.0</version>
		  
		  <name>Sdk4J</name>
			<description>Sdk4J from http://wiki.open.qq.com/wiki/website/SDK%E4%B8%8B%E8%BD%BD</description>
			<url>http://wiki.open.qq.com/wiki/website/SDK%E4%B8%8B%E8%BD%BD</url>
			<licenses>
				<license>
					<name>GNU General Public License, version 2</name>
					<url>http://www.gnu.org/licenses/gpl-2.0.txt</url>
					<distribution>repo</distribution>
				</license>
			</licenses>
			<developers>
				<developer>
					<id>qq</id>
					<name>mahuateng</name>
					<email>mahuateng@qq.com</email>
				</developer>
			</developers>
		
			<scm>
				<connection>scm:git:https://www.qq.com</connection>
				<developerConnection>scm:git:https://www.qq.com</developerConnection>
				<url>https://www.qq.com</url>
				<tag>HEAD</tag>
			</scm>
		</project>
		
		
	mvn archetype:generate  -D archetypeGroupId=org.apache.isis.archetype -D archetypeArtifactId=simpleapp-archetype -D archetypeVersion=1.6.0 -D groupId=com.mycompany -D artifactId=myapp -D version=1.0-SNAPSHOT -B




plugin
Consists of:
	pom of maven-plugin packaging 
	implementation of Goal (Mojo, a sub-class of AbstractMojo)
	
Related description file will auto generated from Mojo comments. 


plugins:
Failsafe - for Integration Test, no impact to build
	Rely on different providers:
		TestNG
		JUnit (3.8 or 4.x)
		POJO
	Which providers are available is controlled simply by the inclusion of the appropriate dependencies
	
Surefire - for Unit Test, any failed will fail the build.


Release - release a project
	Note: usename & password need to be set, as push need the username & password
		E.g. mvn release:prepare -Dusername=xxx -Dpassword=xxxx

	Goals:
		prepare
			Prepare for a release
			Steps:
				Check that there are no uncommitted changes in the sources
				Check that there are no SNAPSHOT dependencies
				Change the version in the POMs from x-SNAPSHOT to a new version (you will be prompted for the versions to use)
				Transform the SCM information in the POM to include the final destination of the tag
				Run the project tests against the modified POMs to confirm everything is in working order
				Commit the modified POMs
				Tag the code in the SCM with a version name (this will be prompted for)
				Bump the version in the POMs to a new value y-SNAPSHOT (these values will also be prompted for)
				Commit the modified POMs
				
		perform
			Perform a release
			Steps:
				Checkout from an SCM URL with optional tag
				Run the predefined Maven goals to release the project (by default, deploy site-deploy) with profile: release-profile, ${releaseProfiles}
					mvn deploy -P release-profile, ${releaseProfiles}
				
		rollback
			Rollback a release
			Steps:
				All project POMs are reverted back to their pre-release state locally, and also in the SCM if the previous release command was able to successfully make changes in the SCM to the POMs
				The created branch/tag in SCM for the release is removed(Note: This is not yet implemented so you will need to manually remove the branch/tag from your SCM.)
				
		clean
			Steps:
				Delete the release descriptor (release.properties)
				Delete any backup POM files
		
		stage
			Similar to perform, but deploy to repository: ${stagingRepository}


Stage
	Goals:
		copy
			copy artifacts from one repository to another repository.
			There is a bug here
	Note:
		Seems this project is not maintained
		
		

***** meteor
Meteor
	Platform for building web apps
	
	Consist of:
		library of packages
		command-line tool called meteor
	
	Key idea in the Meteor package system:
		Everything should work identically in the browser and on the server
		
	
	Fold Structure:
		public
			Only available to client via web server
		private
			Only available to server code via the Assets API
		server
			Load into server
		client
			Load into client
			
		tests - not loaded by both client & server
		rest of the files - loaded by both client & server
		
	Template sections, on the other hand, are converted into JavaScript functions, available under the Template namespace.
	
	When you app is loaded, it automatically renders the special template called <body>, which is written using the <body> element
	
	insert a template inside another template by using the {{> inclusion}} operator
	
	Package
		simply a directory with a package.js
		default package: standard-app-packages
		internal packages are inside meteor, external package are installed in packages folder
		manipulate pkg:
			meteor list
			meteor add
			meteor remove
	
	Namespacing

	Meteorite
		package manager
		Used to manage external packages
	
	API:

		DDP.connect()
			Connect to different Meteor application
			
			By default client open a connection to the server from which they 're loaded.
			
		Meteor.publish(name, func)
			Publish a record set (Data Set in Collection)
			Publish Collection & its specific Data Set to Client
			
		Meteor.subscribe()
			Subscribe to a record set (Data Set in Collection)
			Sync Data Set from server Collection to client same Collection
		
		Meteor.Collection(name)			
			Data Access Interface
			name - Data Set name
			
			Meteor stores data in Collection
			find()
				returns a Cursor
				It does not immediately access the database or return documents. 
			
			
		autopublish
			Meteor.publish() & Meteor.subscribe() is not required
		
		Deps.Computation
			represents code that is repeatedly rerun in response to reactive data changes
		
		Deps.Dependency
			represents an atomic unit of reactive data that a computation might depend on
			they just track the set of computations to invalidate if something changes
			Typically, a data value will be accompanied by a Dependency object that tracks the computations that depend on it
			
		DDP - Distributed Data Protocol
			supports two operations:
				Remote procedure calls by the client to the server
				The client subscribing to a set of documents, and the server keeping the client informed about the contents of those documents as they change over time
			
			may use either SockJS or WebSockets as a lower-level message transport
				WebSockets
					URL E.g.
						wss://ddp--0999-sudoor.meteor.com/sockjs/675/g0fgqb77/websocket
			DDP messages are JSON objects
		
		Reactivity
			Reactive data source getter will add runtime computation to its dependent list
			
***** linked data
Linked Data - Connect Distributed Data across the Web

***** log4j
LOG4J major components: 
	Logger, Appender, Layout

Root Logger Config: 
log4j.rootLogger = [ level ] , ${appenderName}, ${appenderName}, … 

Appender Config:
log4j.appender.${appenderName} = fully qualified name of appender class
log4j.appender.${appenderName}.layout = fully qualified name of layout class
log4j.appender.${appenderName}.ConversionPattern = pattern expression

Log Level:
OFF, FATAL,ERROR, WARN, INFO, DEBUG, ALL

Provided Appender:
org.apache.log4j.ConsoleAppender（控制台），
org.apache.log4j.FileAppender（文件），
org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件），
org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件），
org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） 

Provided Layout:
org.apache.log4j.HTMLLayout（以HTML表格形式布局），
org.apache.log4j.PatternLayout（可以灵活地指定布局模式），
org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串），
org.apache.log4j.TTCCLayout（包含日志产生的时间, 线程, 类别等等信息） 

Ex:
log4j.rootLogger=WARN, Console
log4j.appender.Console=org.apache.log4j.ConsoleAppender
log4j.appender.Console.layout=org.apache.log4j.PatternLayout
log4j.appender.Console.layout.ConversionPattern=(%r ms) [%t] %-5p: %c#%M %x: %m%n



***** logback
logback - concrete log impl
	
	Init
		look for & load logback.xml from class path
		load included config
		Process elements by ch.qos.logback.core.joran.action.*
			conversionRule
			appender
			root
			logger


	
***** JRebel
Class Hot Deployment achieved via : 
	javaagent (Instrumentation), change the class bytes directly. 

Other resource Hot Deployment achieved via (should be):
	Change servlet-mapping in web.xml.
		Router all request to JRebel Servlet,
		JRebel Servlet :
			search monitor path
			if available, change request's resource path, 
			router to original servlet


JRebel
	Monitor class & resources changes and hot deploy to server without restart. 
	Setup:
		1, Download jrebel-5.0.0-nosetup.zip & extract
		2, Run bin/jrebel-config.cmd to config license
	Use:	
		1, Add maven plugin:
			<plugin>
				<groupId>org.zeroturnaround</groupId>
				<artifactId>jrebel-maven-plugin</artifactId>
				<version>1.1.2</version>
				<executions>
					<execution>
						<id>generate-rebel-xml</id>
						<phase>process-resources</phase>
						<goals>
							<goal>generate</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
		2, Create server start script & start server:
			@echo off
			set JAVA_OPTS=-javaagent:${JRebel Home}\jrebel.jar %JAVA_OPTS%
			call "%~dp0\startup.bat" %*

There is a bug for JSP(other resource) hot deployment when link path is "/":
	After control delivered to original servlet, JSP2Dom will parse JSP to load included sub-jsp base on changed resource path (contextURL).
	
***** intellij
Concept Mapping (intellij <-> eclipse):
	Project	<->	Workspace
	Module	<->	Project

Concepts:
	Project - Folder contains .idea
	Module - Folder contains *.iml
	New Project/Module - Create intellij project/module from nothing
	Import Project/Module - Convert exsiting plain code/eclipse project/maven project to intellij project/module & import

	Docked Model - The view of this model will like a docked boat share space with other boats


Stash VS Shelve
    Stash rely on git
    Shelve rely on IDE

***** jaxb
JAXB is used to generate class files from xml and generatne xml from objects.

JAXBContext.newInstance("com.xdc"); // this will find jaxb.properties in the path.


Ex:
<!-- the generated class code is very like followed structure. If we put the SubappType define into the LogicSupportType define it will generate inner class   -->
	<xs:element name="logic-support" type="LogicSupportType" />
	
	<xs:complexType name="LogicSupportType">
      <xs:sequence>
				<xs:element minOccurs="0" maxOccurs="unbounded" name="subapp" type="SubappType"/>
      </xs:sequence>
  </xs:complexType>
	
	<xs:complexType name="SubappType">
		<xs:sequence>
			<xs:element name="logic-element" type="LogicElementType" minOccurs="0" maxOccurs="unbounded"></xs:element>
		</xs:sequence>
		<xs:attribute name="appId" type="xs:string" />
	</xs:complexType>
	
	
	<xs:complexType name="LogicElementType">
      <xs:attribute name="id" type="xs:string" />
      <xs:attribute name="logicSupported" type="xs:string" />
  </xs:complexType>

***** LDAP
LDAP - Lightweight Directory Access Protocol
	A protocol defines Directory related stuff:
		Directory Functional Model
			Directory Access Method
			Security Model
		Directory Data(Information) Model

		
	Directory
		A database optimized for read access

		Details:
			Directory Data(Information) Model
				data is stored in entries, which build up a hierarchical, tree like structure (Refer to DirectoryDataModel.png)
				
				Entry
					A collection of attributes that has a globally-unique Distinguished Name (DN)
					Each of the entry's attributes has a type and one or more values
						The types are typically mnemonic strings, like "cn" for common name, or "mail" for email address. 
						The values of the objectClass attribute determine the schema rules the entry must obey.
					Entries are arranged in a hierarchical tree-like structure
						Traditionally, this structure reflected the geographic and/or organizational boundaries. 
						
				Schema
					Defines what kind of Entries can be stored within the Directory
					Consists:
						AttributeType : the type of values that can be stored in an attribute
						ObjectClass : the set of AttributeType that can or must be used in an entry
						Syntax : The syntax the values must abide to
						MatchingRule : The rules used to retrieve the data
***** jaxrs
Provider
	Annotated with @Provider
	Mark it should be discoverable by JAX-RS runtime during a provider scanning phase

	Category:
		Entity Provider
			Convert between Java & MIME type
			Implement MessageBodyWriter or MessageBodyReader
			cxf-rt-rs-extension-providers contains predifined providers

		Filter
			Implement ContainerResponseFilter or ContainerRequestFilter

		Resource?
		    Pojos annotated with @Path, used to represent web resource


Register Providers
	Application approach:
		Create sub class of javax.ws.rs.core.Application, used to register Resources & Providers
		Register:
			Serverlet 2.x:
				<web-app>
					<servlet>
						<servlet-name>Jersey Web Application</servlet-name>
						<servlet-class>org.glassfish.jersey.servlet.ServletContainer</servlet-class>
						<init-param>
							<param-name>javax.ws.rs.Application</param-name>
							<param-value>org.foo.rest.MyApplication</param-value>
						</init-param>
						...
					</servlet>
					...
				</web-app>
	
	Init Param approach (for Provider):
		<init-param>
            <param-name>jersey.config.server.provider.packages</param-name>
            <param-value>net.gplatform.server.infra.cors</param-value>
        </init-param>


Representation:
	String
	Response
	byte[]
	java.io.InputStream
	java.io.Reader
	java.io.File
	JAXB
		JAXBElement
		@XmlRootElement
		@XmlType
	StreamSource
	SAXSource
	DOMSource
	Document


Name binding
    bind a filter or an interceptor to a specific resource method
    @NameBinding is used as meta annotation for other user implemented annotations that are applied to a providers and resource methods.
    name-bound annotations(annotation with @NameBinding), apply to resource & fileter/interceptro, to bind fileter/interceptro to resource

***** jersey1
Request Process Steps:
	RootResourceClassesRule.accept(path)
		RightHandPathRule.accept(path)
			ResourceClassRule.accept(WebApplicationContext)
				Get HttpMethodRules from WebApplicationContext.getRules(resourceClass)
				HttpMethodRule.accept(resource)
						


WebApplicationImpl
	rootsRule - RootResourceClassesRule
		rules - UriRules
		
		
	metaClassMap
		Key: Resource.class
		Value: ResourceClass (encapsulate something)
			resource - AbstractResource
			config - DefaultResourceConfig
			wadlFactory - WadlFactory
			rules - UriRules(HttpMethodRules)
				map
					Key: method name
					Value: ResourceMethodListPair
						ResourceHttpMethod
						
				accept(resource)
					get ResourceMethodListPair from map with method name as param
					invoke ResourceHttpMethod in ResourceMethodListPair
				
				
		
	abstractResourceMap
		Key: Resource.class
		Value: AbstractResource
			resourceMethods - method with out Path
				AbstractResourceMethod
			subResourceMethods - method with Path
				AbstractSubResourceMethod


------------------------------------------------------------------------------
Only if provider available in the lib, Object can convert to JSON.

With below config - List<Post> convert to : [{id:"xxx", name:"xxx"},{id:"xxx", name:"xxx"}]
Without below config - List<Post> convert to : {post: [{id:"xxx", name:"xxx"},{id:"xxx", name:"xxx"}]}
<init-param>
    <param-name>com.sun.jersey.api.json.POJOMappingFeature</param-name>
    <param-value>true</param-value>
</init-param>



***** jersey 2
Runtime Stack:
	ServletContainer.service()
		WebComponent.service()
			Create ContainerRequest (requestContext, created base on HttpRequest & HttpResponse )
			ApplicationHandler.handle(requestContext);
				ServerRuntime.process(requestContext);
					org.glassfish.jersey.process.internal.Stages.process()
						Execute chain of Stage


Stage - stateless data processing unit(can be used to create dynamic data processing chains)
	class Continuation - Encapsulate result(processed data) & next Stage
		of() - create Continuation
	interface Builder - Linear stage chain builder
		to() - Add target to Stage chain
		Stage<DATA> build() - build Stage chain
	public Continuation<DATA> apply(DATA data); - Performs a data processing task


Router - Hierarchical request router that can be used to create dynamic routing tree structures
	class Continuation - similar to Stage.Continuation
	interface Builder - similar to Stage.Builder
	public Continuation apply(ContainerRequest data); - similar to Stage.apply()


RoutingStage
	Execute chain of Router (MatchResultInitializerRouter(routingRoot) -> PathPatternRouter(rootRouter) -> MethodSelectingRouter)


WebComponent
	appHandler - ApplicationHandler
	application - javax.ws.rs.core.Application
	runtimeConfig - RuntimeConfig(ResourceConfig)
		state - State
			componentBag - ComponentBag
				classes - Set<Class<?>>


ResourceConfig
	extends javax.ws.rs.core.Application
	data maintained in State
	
	
WrappingResourceConfig
	extends ResourceConfig
	contains a Application
	merge Application state to State
	

Router Impl Details:
	MethodSelectingRouter.apply()
		MethodSelectingRouter.getMethodRouter()
			Find corresponding ConsumesProducesAcceptor from MethodSelectingRouter.consumesProducesAcceptors

	ConsumesProducesAcceptor
		Represents a 1-1-1 relation between input and output media type and an MethodAcceptorPair. 


Startup Process (assume): 
	Load Application
	Find Resources
	Create ConsumesProducesAcceptor

***** jazz
Jazz
	An Initiative to transform software and systems delivery by making it more collaborative, productive and transparent, through integration of information and tasks across the phases of the lifecycle. 
	
	Consists of three elements:
		Platform
			An open platform for lifecycle tool integration
		Products
			Provide different lifecycle Tool
		Community
	
----------------------------------------------------------------------
	
	Platform
		2 principal facets of the Jazz architecture (Refer to JazzPlatform.png):
			Linked Lifecycle Data
				applying the W3C "Linked Data" standards to the realm of lifecycle data (e.g., requirements, change requests, test plans, code, etc.)
				implemented in OSLC
				OSLC shifts the emphasis from tools and their widely varying APIs to the lifecycle resources (the data) and the relationships between resources.
			Integration Services
				providing cross-cutting capability for any lifecycle tool (e.g., user admin, project admin, lifecycle query) to enable the "system" of tools to work well together
				Integration services are general purpose cross-tool capabilities that enable the whole (a set of Jazz products) to be greater than the sum of its parts.
				
				
				Jazz Team Server provides an implementation of Integration Services
					Normally in web application format
					
					Provided Services
						Manage License
						Manage Server
						Manage Users
						Manage Product(Application)
					
					Install & Setup:
						install
						start (server.startup.bat)
						setup
							URL: https://hostname.example.com:9443/jts/setup
							Credential: ADMIN/ADMIN
						manage License, Users via https://hostname.example.com:9443/jts/admin

		
	Products
		Normally in web application format
		Products Examples:
			Change and Configuration Management - /ccm
			Quality Management - /qm
			Requirements Management - /rm
			Manage Lifecycle Projects - /admin
				Lifecycle Project
					A set of linked Project Area in different Product

----------------------------------------------------------------------

	Deployment topologies
		Evaluation topology, Departmental topology, Enterprise topology
			One Platform for different Products
			Refer to JazzTopology_*.gif
			
		Independent topology
			Multiple Platform for different Products
			
***** jaydata
JayData - data access library
	attach() is a must before you change on the Entity, since it will give ${entity}.entityState init value

	Nav Property:
		Nav Property is only a link in OData, so there is no corresponding property in Entity Object.
		U can retrieve Nav Property refereed Entity via Method get_XXX()
			This method will fire a request to refereed resource with Where Expression
			The target resource need to have a refer key to source Entity
			
	Data Access Steps:
		Get $data.Queryable from $data.EntityContext
		Do query on $data.Queryable
			E.g.
				$data.Queryable.order(), $data.Queryable.filter()
		Retrieve Data from $data.Queryable
			E.g.
				$data.Queryable.first(), $data.Queryable.forEach(), $data.Queryable.length()

***** jboxx modules
JBoss Modules is a standalone implementation of a modular (non-hierarchical) class loading and execution environment for Java. 

	In other words, rather than a single class loader which loads all JARs into a flat class path, each library becomes a module which only links against the exact modules it depends on, and nothing more. 
	
	Consist of:
		class loader model
		module resolution system


***** JDO
JDO bytecode enhancement contract require it a must.

3 categories of classes(The Meta-Data defines which classes fit into these categories)
    PersistenceCapable
        JDO contract requires that all classes to be persisted must implement the PersistenceCapable
        interface, and for JPA they also implement the Detachable interface
    PersistenceAware
    normal classes

***** jekyll
A tool to generate static html from md file

***** jenkins
Jenkins
	Monitors executions of repeated jobs
	
	Current Jenkins focuses on the following two jobs:
		Building/testing software projects continuously
		Monitoring executions of externally-run jobs


***** modernizr
Modernizr - Tests which native CSS3 and HTML5 features are available in the current UA
	makes the results available to you in two ways:
		as properties on a global Modernizr object
		as classes on the <html> element
		
	Modernizr.load()
		a resource loader used to load polyfills
		Avalilable Polyfills: https://github.com/Modernizr/Modernizr/wiki/HTML5-Cross-Browser-Polyfills
		E.g.
			Modernizr.load({
			  test: Modernizr.geolocation,
			  yep : 'geo.js',
			  nope: 'geo-polyfill.js'
			});
							
	Modernizr.prefixed(str)
		detect css feature prefix
		E.g.
			Modernizr.prefixed('boxSizing')
	
	Modernizr.prefixed(str, obj[, scope])
		detect dom feature prefix
		E.g.
			Modernizr.prefixed('requestAnimationFrame', window) - retrun the property value
			Modernizr.prefixed('requestAnimationFrame', window, false) - retrun the property name
		
	Modernizr.mq(str)
		tests a given media query, live against the current state of the window
		E.g.
			Modernizr.mq('only screen and (max-width: 768px)')
	
	Modernizr.addTest(testName, testFunc)
		Test additional features currently not supported in Modernizr
		U can find official extended testers under modernizr/feature-detects
		
		
***** mozilla java plugin 
Link below "so" file to mozilla plugin folder
jre1.6.0_30/lib/i386/libnpjp2.so


***** mutation observer
MutationObserver
	Object be used to observe mutations to the tree of nodes

	[Constructor(MutationCallback callback)]
	interface MutationObserver {
	  void observe(Node target, MutationObserverInit options);
	  void disconnect();
	  sequence<MutationRecord> takeRecords();
	};

	callback MutationCallback = void (sequence<MutationRecord> mutations, MutationObserver observer);

	dictionary MutationObserverInit {
	  boolean childList = false;
	  boolean attributes = false;
	  boolean characterData = false;
	  boolean subtree = false;
	  boolean attributeOldValue = false;
	  boolean characterDataOldValue = false;
	  sequence<DOMString> attributeFilter;
	};
***** JMeter
JMeter
	Apache software to load test functional behavior and measure performance
	
	JMX
		XML File Format, JMeter test plan will store in JMX file
		
		Format
			jmeterTestPlan
				hashTree
					TestPlan
					hashTree
						ThreadGroup - Thread/Concurrency Config
						hashTree
							HTTPSamplerProxy - Http Config
						ConfigTestElement - Http Default Config
						ResultCollector - Result Checker

***** JMX
JMX - Java Management Extensions
	JMX technology provides a standard API for management and monitoring of resources
	
	Typical uses of the JMX technology include:
		Consulting and changing application configuration
		Accumulating statistics about application behavior and making them available
		Notifying of state changes and erroneous conditions
		
	
	Architecture
		Instrumentation - JSR 3
			Resources, such as applications, devices, or services, are instrumented using Java objects called Managed Beans (MBeans). 
			MBeans expose their management interfaces, composed of attributes and operations, through a JMX agent for remote management and monitoring.
		Agent - JSR 3
			directly control resources and make them available to remote management applications
			consists of:
			 	an MBean server
			 	a set of services for handling MBeans
		Remote Management - JSR 160
			Protocol adaptors and standard connectors make a JMX agent accessible from remote management applications

	
	Details:
		Instrumentation
			management interface of an MBean consists of:
				Named and typed attributes that can be read and/or written
				Named and typed operations that can be invoked
				Typed notifications that can be emitted by the MBean
				
			A dynamic MBean is an MBean that defines its management interface at runtime. For example, a configuration MBean could determine the names and types of the attributes it exposes by parsing an XML file.
			
			MXBean is a new type of MBean that provides a simple way to code an MBean that only references a pre-defined set of types.
			
			MBean ObjectName like LDAP Entity with slightly different (domainName:attribute1=xxx,attribute2=xxx,...)
				Some tool show MBean as a tree base on this
				
		
		Agent	
			Agent services are objects that can perform management operations on the MBeans registered in the MBean server
			
		Remote Management	
			A connector consists of a connector client and a connector server. 
			
			Connectors:
				RMI Connector
				Generic Connector
				
			Remove jmx command:
				java -Dcom.sun.management.jmxremote.port=9999 \
			     -Dcom.sun.management.jmxremote.authenticate=false \
			     -Dcom.sun.management.jmxremote.ssl=false \
			     com.example.Main

***** JNDI
Java Naming & Directory Interface
	Retrieve or bind object to server through serialize/unserialize object.


bind steps:
	1, client serialize object and send it to JNDI server.
	2, JNDI server will read the serialized stream and unserialize stream to object.
	3, Give the object a JNDI name.


ENC - environment naming context
	Start with: "java:/comp/env"
	A context refer to current application enveroment, so you need to define <resource-ref> in your application when you use it


Note:
unserialize do not need to invoke constructor.

***** Jolokia
Jolokia
	A JMX-HTTP bridge
	Giving an alternative to JSR-160 connectors

***** JDPA
Java Platform Debugger Architecture

     interfaces
	Java Virtual Machine Tool Interface
	Java Debug Interface
	      JDI is a remote view in the debugger process of a virtual machine in the debuggee process
	
     protocol
	Java Debug Wire Protocol
	     describes the format of debugging information and requests between a debuggee and a debugger
	

     software components
        jdb ?
	javadt ?

***** jshint
Check js coding style
	.jshintrc - define the check rules

***** js-import-maven-plugin
Use antlr3 (with template: ECMAScriptLexer.tokens) to parse JS file
Find out defined & required variables, so that it can analysis dependency tree.

***** jslint
Used to verify js grammar

***** JTA
JPA - Java Transaction API
	interfaces between:
		a transaction manager (Refer to DTP.txt)
		the parties involved in a distributed transaction system: 
			the application
			the resource manager (Refer to DTP.txt)
			the application server

	Refer to: JPA.png, JPASequence.pdf
	
	TxType - indicates whether a bean method is to be executed within a transaction context
		REQUIRED
		REQUIRES_NEW
		MANDATORY
		SUPPORTS
		NOT_SUPPORTED
		NEVER
		
	Note:
		When a Transaction opened, not all works performed after the opening belongs to it, only those performed by Resource Manager belongs to it.

***** JVM
Memory Model
	Three types of memory: heap(data), stack(data), method area(commond)
	
	heap - Data area used to maintain Object data
	Only one heap shared by all threads.
	
	stack - Data area used to maitain Object reference, primary data
	Each thread have its private stack.
	When a method be invoked, a Frame will be pushed into Stack. 
	A frame contains method's parameter & local variable & temp data used by this method during the execution.
	
	method area - A area used to maintain Class method commond
	Only one method area shared by all threads. It contains: Class method , Class Static Variable
	
	
	PermGen - Permanent Generation
		 area of the heap where class and method objects are stored
		
		Interned java.lang.String objects are also stored in the permanent generation
		
		Config:
			-XX:PermSize=64M
			-XX:MaxPermSize=256m
			
	
	Heap size
		Young Generation + Tenured Generation
		
	
	Generation
		Memory Group which is base on memory age
		
		Typical Generations:
			Young Generation
				Most objects are initially allocated in the Young Generation
				
				consists of:
					Eden
						Most objects are initially allocated in Eden
					2 Survivor Spaces
						Hold objects that have survived at least one young generation collection
			
			Old Generation
				Contains objects that have survived some number of Young Generation collections, as well as some large objects that may be allocated directly in the old generation
			
			Permanent Generation
				Holds objects that the JVM finds convenient to have the garbage collector manage, such as objects describing classes and methods, as well as the classes and methods themselves
	
	
	Generational Collection
		Collection is on Generation basis

		Different algorithms can be used to perform garbage collection in the different generations, each algorithm optimized based on commonly observed characteristics for that particular generation.
		old generation collections are infrequent, but take significantly longer to complete

		Collectors
			Serial Collector
				Collections are done serially (using a single CPU) in a stop-the-world fashion. 
				That is, application execution is halted while collection is taking place
				Choice for most applications that are run on client-style machines and that do not have a requirement for low pause times
				
				Young Generation Collection Using the Serial Collector
					The live objects in Eden are copied to the initially empty Survivor Space
						Except for ones that are too large to fit comfortably in the Survivor Space. Such objects are directly copied to the Old Generation
					The live objects in the occupied Survivor Space that are still relatively young are also copied to the other survivor space, while objects that are relatively old are copied to the Old Generation
					Any objects remaining in Eden or the From space after live objects have been copied are, by definition, not live, and they do not need to be examined.
					Survivor Space swap roles
				
				Old Generation Collection Using the Serial Collector
					Old Generation & Permanent Generation are collected via a mark-sweep-compact collection algorithm				
						mark phase
							the collector identifies which objects are still live				
						sweep phase
							"sweeps" over the generations, identifying garbage
						compact phase
							sliding the live objects towards the beginning of the generation space
							
							This allows any future allocations into the old or permanent generation to use the fast, bump-the-pointer technique
							
			Parallel Collector
				also known as the throughput collector
				developed in order to take advantage of available CPUs rather than leaving most of them idle while only one does garbage collection work
				
				Young Generation Collection Using the Parallel Collector
					uses a parallel version of the young generation collection algorithm utilized by the serial collector
					performing the young generation collection in parallel
					
				Old Generation Collection Using the Parallel Collector
					Same as Serial Collector
					
					
			Parallel Compacting Collector
				The difference between it and the parallel collector is that it uses a new algorithm for old generation garbage collection
				Eventually, the parallel compacting collector will replace the parallel collector
				
				Young Generation Collection Using the Parallel Compacting Collector
					Same as Parallel Collector
				
				Old Generation Collection Using the Parallel Compacting Collector
					generations are collected in a stop-the-world, mostly parallel fashion with sliding compaction
					
					First, each generation is logically divided into fixed-sized regions
					
					marking phase
						the initial set of live objects directly reachable from the application code is divided among garbage collection threads
						all live objects are marked in parallel
							As an object is identified as live, the data for the region it is in is updated with information about the size and location of the object
					
					summary phase
						operates on regions
						examine the density of the regions
							starting with the leftmost one, until it reaches a point where the space that could be recovered from a region and those to the right of it is worth the cost of compacting those regions
							The regions to the left of that point are referred to as the dense prefix, and no objects are moved in those regions
							The regions to the right of that point will be compacted, eliminating all dead space
						calculates and stores the new location of the first byte of live data for each need to be compacted region					
					
					compaction phase
						the garbage collection threads use the summary data to identify regions that need to be filled
						the threads can independently copy data into the regions
			
			
			Concurrent Mark-Sweep (CMS) Collector
				also known as the low-latency collector
				
				Young Generation Collection Using the CMS Collector
					Same as Parallel Collector
					
				Old Generation Collection Using the CMS Collector
					done concurrently with the execution of the application
					The CMS collector is the only collector that is non-compacting
					
					mark phase
						starts with a short pause, called the initial mark
							identifies the initial set of live objects directly reachable from the application code
						concurrent marking phase
							marks all live objects that are transitively reachable from this set						
							Because the application is running and updating reference fields while the marking phase is taking place, not all live objects are guaranteed to be marked at the end of the concurrent marking phase
						stops again for a second pause, called remark
							finalizes marking by revisiting any objects that were modified during the concurrent marking phase
							Because the remark pause is more substantial than the initial mark, multiple threads are run in parallel to increase its efficiency
					
					sweep phase
						concurrent reclaims all the garbage that has been identified
						
						

JIT - Just In Time
	Convert Java bytecode into native machine code.
	ACC_MACHINE_COMPILED to indicator whether code been converted.
	For JIT converted code, u will see "Compiled Code" instead of line numbers in stack trace.
	This tech already deprecated, replaced by HotSpot

	-Djava.compiler
		Specify JIT library.
	
	

IBM JVM Args
	-Xshareclasses - Share classes across mutiple JVM process
	-Xscmx50M - Share classes cache size

	-Xquickstart
	-Xverify:none


JVM TI
JVM Tool Interface
	a VM interface for the full breadth of tools that need access to VM state, including but not limited to: profiling, debugging, monitoring, thread analysis, and coverage analysis tools. 
	
	
	
Agent: 
	A client of JVM TI, hereafter called an agent, can be notified of interesting occurrences through events.

	-agentlib:<agent-lib-name>=<options>
	    The name following -agentlib: is the name of the library to load. Lookup of the library, both its full name and location, proceeds in a platform-specific manner. Typically, the <agent-lib-name> is expanded to an operating system specific file name. The <options> will be passed to the agent on start-up. For example, if the option -agentlib:foo=opt1,opt2 is specified, the VM will attempt to load the shared library foo.dll from the system PATH under WindowsTM or libfoo.so from the LD_LIBRARY_PATH under the SolarisTM operating environment. 
	-agentpath:<path-to-agent>=<options>
	    The path following -agentpath: is the absolute path from which to load the library. No library name expansion will occur. The <options> will be passed to the agent on start-up. For example, if the option -agentpath:c:\myLibs\foo.dll=opt1,opt2 is specified, the VM will attempt to load the shared library c:\myLibs\foo.dll. 
	    

	Step by Step:
		1, Evn variable setup: 
			JVMTI_AGENT=C:\Shark\app_private\tptp\eclipse\plugins\org.eclipse.tptp.platform.jvmti.runtime_4.6.3.v201102041710\agent_files\win_ia32
			PATH=%PATH%;%JVMTI_AGENT%
		2 Run:
			java -agentlib:JPIBootLoader=JPIAgent:server=enabled;CGProf:execdetails=true HellowWorld
			

JVM Thread
 java.lang.OutOfMemoryError: Unable to create new native thread
 	Steps:
		A new Java thread is requested by an application running inside the JVM
		JVM native code proxies the request to create a new native thread to the OS
		OS tries to create a new native thread which requires memory to be allocated to the thread
		The OS will refuse native memory allocation either because the 32-bit Java process size has depleted its memory address space – e.g. (2-4) GB process size limit has been hit – or the virtual memory of the OS has been fully depleted
		The java.lang.OutOfMemoryError: Unable to create new native thread error is thrown.
	
	native thread limit is platform-dependent
		

JVM Memory
Memory Model:
	pc Register
	Java Virtual Machine Stacks
		Frames
			Local Variables
			Operand Stacks
			Dynamic Linking
	Heap
	Method Area
		Run-Time Constant Pool
	Native Method Stacks

JVM Classloader
2 Kinds of Class Loader:
	Parent-First
		JDK inside class loader is this kind. 
		
	Child-First
		Has the advantage of helping to improve isolation between container and application.
		Not allowing replacement of java.* or javax.* classes
		

Types(also named Class) will MUST be find/defined from InitialClassloader/DefineClassloader when:
		Types be used. Include: Declare Type's var, New Type's instance, Invoke Type's method
		Class.forName()

Type's InitialClassloader is the DefineClassloader of the class which included the type


Context ClassLoader
	This classloader is accessed by the getContextClassLoader  method on Thread.
	If the context classloader is not set then it will default to the system classloader.


ClassLoader Memory Leak
	Root cause it due to 1 single JVM used to load different WAR. 
	Classes loaded by System Class Loader & Extend Class Loader will shared by all WARs. 
	Those classes' static fields will retain, even after u stop the WAR. 


Unload Class Method
	Class method memory will be unloaded from method area if & only if its class loader is unreachable. 
	The bootstrap class loader is always reachable. 
	
	Ex:
	When WAR be shut down, class method will be unloaded. 
		A new class loader which will be created & used to load WAR classes when WAR start up. 
		Get a pooled thread & set its current class loader ref to this new class loader & go ahead to start & run WAR. 
		Set the thread's current class loader ref to NULL, after shut down the WAR. 
		At this stage no refer to this new class loader, so that the class method also will be unloaded. 
		





引导类加载器:(无实例，加载rt.jar)
扩展类加载器:(加载lib/ext/*.jar)
系统类加载器:(加载 -classpath 指定的类)


ClassLoader一个经常出现又让很多人望而却步的词，本文将试图以最浅显易懂的方式来讲解 ClassLoader，希望能对不了解该机制的朋友起到一点点作用。

要深入了解ClassLoader，首先就要知道ClassLoader是用来干什么的，顾名思义，它就是用来加载Class文件到JVM，以供程序使用的。我们知道，java程序可以动态加载类定义，而这个动态加载的机制就是通过ClassLoader来实现的，所以可想而知ClassLoader的重要性如何。

看到这里，可能有的朋友会想到一个问题，那就是既然ClassLoader是用来加载类到JVM中的，那么ClassLoader又是如何被加载呢？难道它不是java的类？

没有错，在这里确实有一个ClassLoader不是用java语言所编写的，而是JVM实现的一部分，这个ClassLoader就是 bootstrap classloader（启动类加载器），这个ClassLoader在JVM运行的时候加载java核心的API以满足java程序最基本的需求，其中就包括用户定义的ClassLoader，这里所谓的用户定义是指通过java程序实现的ClassLoader，一个是ExtClassLoader，这个ClassLoader是用来加载java的扩展API的，也就是/lib/ext中的类，一个是AppClassLoader，这个 ClassLoader是用来加载用户机器上CLASSPATH设置目录中的Class的，通常在没有指定ClassLoader的情况下，程序员自定义的类就由该ClassLoader进行加载。

当运行一个程序的时候，JVM启动，运行bootstrap classloader，该ClassLoader加载java核心API（ExtClassLoader和AppClassLoader也在此时被加载），然后调用ExtClassLoader加载扩展API，最后AppClassLoader加载CLASSPATH目录下定义的Class，这就是一个程序最基本的加载流程。

上面大概讲解了一下ClassLoader的作用以及一个最基本的加载流程，接下来将讲解一下ClassLoader加载的方式，这里就不得不讲一下ClassLoader在这里使用了双亲委托模式进行类加载。

每一个自定义ClassLoader都必须继承ClassLoader这个抽象类，而每个ClassLoader都会有一个parent ClassLoader，我们可以看一下ClassLoader这个抽象类中有一个getParent()方法，这个方法用来返回当前 ClassLoader的parent，注意，这个parent不是指的被继承的类，而是在实例化该ClassLoader时指定的一个 ClassLoader，如果这个parent为null，那么就默认该ClassLoader的parent是bootstrap classloader，这个parent有什么用呢？

我们可以考虑这样一种情况，假设我们自定义了一个ClientDefClassLoader，我们使用这个自定义的ClassLoader加载 java.lang.String，那么这里String是否会被这个ClassLoader加载呢？事实上java.lang.String这个类并不是被这个ClientDefClassLoader加载，而是由bootstrap classloader进行加载，为什么会这样？实际上这就是双亲委托模式的原因，因为在任何一个自定义ClassLoader加载一个类之前，它都会先委托它的父亲ClassLoader进行加载，只有当父亲ClassLoader无法加载成功后，才会由自己加载，在上面这个例子里，因为 java.lang.String是属于java核心API的一个类，所以当使用ClientDefClassLoader加载它的时候，该 ClassLoader会先委托它的父亲ClassLoader进行加载，上面讲过，当ClassLoader的parent为null 时，ClassLoader的parent就是bootstrap classloader，所以在ClassLoader的最顶层就是bootstrap classloader，因此最终委托到bootstrap classloader的时候，bootstrap classloader就会返回String的Class。

我们来看一下ClassLoader中的一段源代码：
Java代码 复制代码

   1.    protected synchronized Class loadClass(String name, boolean resolve)  
   2. throws ClassNotFoundException  
   3.    {  
   4. // 首先检查该name指定的class是否有被加载  
   5. Class c = findLoadedClass(name);  
   6. if (c == null) {  
   7.     try {  
   8.     if (parent != null) {  
   9.         //如果parent不为null，则调用parent的loadClass进行加载  
  10.  = parent.loadClass(name, false);  
  11.     } else {  
  12.         //parent为null，则调用BootstrapClassLoader进行加载  
  13.         c = findBootstrapClass0(name);  
  14.     }  
  15.     } catch (ClassNotFoundException e) {  
  16.         //如果仍然无法加载成功，则调用自身的findClass进行加载              
  17.         c = findClass(name);  
  18.     }  
  19. }  
  20. if (resolve) {  
  21.     resolveClass(c);  
  22. }  
  23. return c;  
  24.    }  

    protected synchronized Class loadClass(String name, boolean resolve)
	throws ClassNotFoundException
    {
	// 首先检查该name指定的class是否有被加载
	Class c = findLoadedClass(name);
	if (c == null) {
	    try {
		if (parent != null) {
		    //如果parent不为null，则调用parent的loadClass进行加载
c = parent.loadClass(name, false);
		} else {
			//parent为null，则调用BootstrapClassLoader进行加载
		    c = findBootstrapClass0(name);
		}
	    } catch (ClassNotFoundException e) {
	        //如果仍然无法加载成功，则调用自身的findClass进行加载			
	        c = findClass(name);
	    }
	}
	if (resolve) {
	    resolveClass(c);
	}
	return c;
    }



从上面一段代码中，我们可以看出一个类加载的大概过程与之前我所举的例子是一样的，而我们要实现一个自定义类的时候，只需要实现findClass方法即可。

为什么要使用这种双亲委托模式呢？

第一个原因就是因为这样可以避免重复加载，当父亲已经加载了该类的时候，就没有必要子ClassLoader再加载一次。

第二个原因就是考虑到安全因素，我们试想一下，如果不使用这种委托模式，那我们就可以随时使用自定义的String来动态替代java核心api中定义类型，这样会存在非常大的安全隐患，而双亲委托的方式，就可以避免这种情况，因为String已经在启动时被加载，所以用户自定义类是无法加载一个自定义的 ClassLoader。

上面对ClassLoader的加载机制进行了大概的介绍，接下来不得不在此讲解一下另外一个和ClassLoader相关的类，那就是Class类，每个被ClassLoader加载的class文件，最终都会以Class类的实例被程序员引用，我们可以把Class类当作是普通类的一个模板，JVM根据这个模板生成对应的实例，最终被程序员所使用。

我们看到在Class类中有个静态方法forName，这个方法和ClassLoader中的loadClass方法的目的一样，都是用来加载class的，但是两者在作用上却有所区别。
Class<?> loadClass(String name)
Class<?> loadClass(String name, boolean resolve)
我们看到上面两个方法声明，第二个方法的第二个参数是用于设置加载类的时候是否连接该类，true就连接，否则就不连接。

说到连接，不得不在此做一下解释，在JVM加载类的时候，需要经过三个步骤，装载、连接、初始化。装载就是找到相应的class文件，读入JVM，初始化就不用说了，最主要就说说连接。

连接分三步，第一步是验证class是否符合规格，第二步是准备，就是为类变量分配内存同时设置默认初始值，第三步就是解释，而这步就是可选的，根据上面loadClass方法的第二个参数来判定是否需要解释，所谓的解释根据《深入JVM》这本书的定义就是根据类中的符号引用查找相应的实体，再把符号引用替换成一个直接引用的过程。有点深奥吧，呵呵，在此就不多做解释了，想具体了解就翻翻《深入JVM吧》，呵呵，再这样一步步解释下去，那就不知道什么时候才能解释得完了。

我们再来看看那个两个参数的loadClass方法，在JAVA API 文档中，该方法的定义是protected，那也就是说该方法是被保护的，而用户真正应该使用的方法是一个参数的那个，一个参数的loadclass方法实际上就是调用了两个参数的方法，而第二个参数默认为false，因此在这里可以看出通过loadClass加载类实际上就是加载的时候并不对该类进行解释，因此也不会初始化该类。而Class类的forName方法则是相反，使用forName加载的时候就会将Class进行解释和初始化，forName也有另外一个版本的方法，可以设置是否初始化以及设置ClassLoader，在此就不多讲了。

不知道上面对这两种加载方式的解释是否足够清楚，就在此举个例子吧，例如JDBC DRIVER的加载，我们在加载JDBC驱动的时候都是使用的forName而非是ClassLoader的loadClass方法呢？我们知道，JDBC驱动是通过DriverManager，必须在DriverManager中注册，如果驱动类没有被初始化，则不能注册到 DriverManager中，因此必须使用forName而不能用loadClass。

通过ClassLoader我们可以自定义类加载器，定制自己所需要的加载方式，例如从网络加载，从其他格式的文件加载等等都可以，其实 ClassLoader还有很多地方没有讲到，例如ClassLoader内部的一些实现等等，本来希望能够讲得简单易懂一点，可是结果自己看回头好像感觉并不怎么样，郁闷，看来自己的文笔还是差太多了，希望能够给一些有需要的朋友一点帮助吧。
***** httpd
Apache web server
    httpd.conf
        Define SRVROOT "C:/apps/Apache24" - Specify the software path


	Install as a service
		httpd.exe -k install

    Uninstall service
        httpd.exe -k uninstall

    Start server service:
        httpd.exe -k start -n "MyServiceName"

    Stop server service:
        httpd.exe -k stop -n "MyServiceName"
        httpd.exe -k shutdown -n "MyServiceName"

    Restart server service:
        httpd.exe -k restart -n "MyServiceName"



	Run as console application:
		httpd.exe


***** infinispan
Runtimes
	Java SE, started by your application
	an application server which provides Infinispan as a service
	bundled as a library in your application, deployed to an application server, and started on by your application
	

Modes
	Local 
		entries are stored on the local node only
	Invalidation 
		entries are stored into a cache store (such as a database) only, and invalidated from all nodes
		When a node needs the entry it will load it from a cache store. In this mode Infinispan is operating as a distributed cache, backed by a canonical data store such as a database
	Replication 
		entries are replicated to all nodes
		operating as a data grid NO increased heap space
	Distribution 
		entries are distributed to a subset of the nodes only
		operating as a data grid providing an increased heap space
	

Access patterns:
	Embedded 
	As a Remote server accessed by a client
	

Configuration 
	configuration approach
		declarative 
			 in a form of XML
			 behind the scenes, invokes programmatic configuration API
			 Code Example:
			 	EmbeddedCacheManager manager = new DefaultCacheManager("my-config-file.xml");
		programmatic
			Code Example:
				GlobalConfiguration globalConfig = new GlobalConfigurationBuilder().transport()
			        .defaultTransport()
			        .clusterName("qa-cluster")
			        .addProperty("configurationFile", "jgroups-tcp.xml")
			        .machineId("qa-machine").rackId("qa-rack")
			      .build();
			      
				Configuration c = new ConfigurationBuilder().clustering().cacheMode(CacheMode.REPL_SYNC).build();
				String newCacheName = "repl";
				manager.defineConfiguration(newCacheName, c);
	configuration abstractions
		global 
			cache manager level
			global settings shared among all cache instances created by a single CacheManager
		default 			 
			cache level
			specific to actual caching domain itself


	Clustered Configuration
		Infinispan uses JGroups for network communications when in clustered mode
		Infinispan shiped JGroups files
			default-jgroups-udp.xml
			default-jgroups-tcp.xml
			default-jgroups-ec2.xml


API
	Asynchronous API
		processes actually happen(in order of cost)
			network calls
			marshalling
			writing to a cache store (optional)
			locking
	
	Invocation Flags
		per-invocation flags in order to provide specific behaviour to each particular cache call. 
		DecoratedCache
			allows you to reuse flags
	
	Tree API
		The aim of this API is to store information in a hierarchical way
		The hierarchy is defined using paths represented as FQN or fully qualified names , for example: /this/is/a/fqn/path or /another/path
		For your application to use the tree API, you need to import infinispan-tree.jar
		Create TreeCache Code Example:
			Configuration config = new Configuration();
			config.setInvocationBatchingEnabled(true);
			Cache cache = new DefaultCacheManager(config).getCache();
			TreeCache treeCache = TreeCacheFactory.createTreeCache(cache);
		Manipulate Code Example:
			//Basic
			treeCache.put("/persons/john", "surname", "Smith");
			//Fqn
			Fqn johnFqn = Fqn.fromString("persons/john");
			Calendar calendar = Calendar.getInstance();
			calendar.set(1980, 5, 2);
			treeCache.put(johnFqn, "birthdate", calendar.getTime()));
			// Node
			TreeCache treeCache = ...
			Fqn johnFqn = Fqn.fromElements("persons", "john");
			Node<String, Object> john = treeCache.getRoot().addChild(johnFqn);
			john.put("surname", "Smith");
		Locking in the Tree API
			happens on a per node basis
				if you’re putting or updating a key/value under a particular node, a write lock is acquired for that node. In such case, no write locks are acquired for parent node of the node being modified, and no locks are acquired for children nodes.
			when a node is moved
				node that’s been moved and any of its children are locked, but also the target node and the new location of the moved node and its children


Eviction
	typically used in conjunction with a cache store, so that entries are not permanently lost when evicted, since eviction only removes entries from memory and not from cache stores or the rest of the cluster.
	Unlike eviction, expired entries are removed globally - from memory, cache stores, and cluster-wide. 
	The purpose of the EvictionManager is to drive the eviction/expiration thread which periodically purges items from the DataContainer.
	
	
Persistence
	If you don’t use eviction, what’s in the persistent store is basically a copy of what’s in memory. 
	If you do use eviction, what’s in the persistent store is basically a superset of what’s in memory (i.e. it includes entries that have been evicted from memory). 
	
	When passivation is enabled, there is a direct relationship between eviction and the cache loader. 
	Writes to the persistent store via the cache loader only occur as part of the eviction process. 
	Data is deleted from the persistent store when the application reads it back into memory. 
	In this case, what’s in memory and what’s in the persistent store are two subsets of the total information set, with no intersection between the subsets.
	
	When a cache is transactional and a cache loader is present, the cache loader won’t be enlisted in the transaction in which the cache is part. 
	That means that it is possible to have inconsistencies at cache loader level: the transaction to succeed applying the in-memory state but (partially) fail applying the changes to the store. Manual recovery would not work with caches stores.


Transactions
	On every cache operation Infinispan does the following:
		Retrieves the current Transaction associated with the thread
		If not already done, registers XAResource with the transaction manager to be notified when a transaction commits or is rolled back.
	the cache has to be provided with a reference to the environment’s TransactionManager . This is usually done by configuring the cache with the class name of an implementation of the TransactionManagerLookup interface.
	
	Transaction modes
		Optimistic 
		Pessimistic 
		
	Enlisting Synchronizations
		Synchronizations have the advantage that they allow TransactionManager to optimize 2PC with a 1PC where only one other resource is enlisted with that transaction ( last resource commit optimization )
			 if Infinispan registers itself with the TransactionManager as an XAResource than at commit time, the TransactionManager sees two XAResource (cache and database) and does not make this optimization. Having to coordinate between two resources it needs to write the tx log to disk. 
			 On the other hand, registering Infinispan as a Synchronisation makes the TransactionManager skip writing the log to the disk (performance improvement).
		used as a 2nd level cache in Hibernate:
			not required to be a participant in the transaction, but only to be notified by its lifecycle (prepare, complete)
		enable it just use NON_XA transaction mode

	Batching
		Batching allows atomicity and some characteristics of a transaction, but not full-blown JTA or XA capabilities.
		Generally speaking, one should use batching API whenever the only participant in the transaction is an Infinispan cluster.
			E.g.
				 transferring money from one bank account to the other. 
				 	If both accounts are stored within Infinispan, then batching can be used. 
				 	If one account is in a database and the other is Infinispan, then distributed transactions are required.
		Code Example:
			Enable:
				<transaction mode="BATCH"/>
			Use:
				cache.startBatch();
				cache.put("k1", "value");
				cache.put("k2", "value");
				cache.put("k2", "value");
				cache.endBatch(true);
		Behind the scenes, the batching functionality use very simple (e.g. no recovery) internal TransactionManager implementation
	
	Transaction recovery
		Recovery cache
			In order to track in-doubt transactions and be able to reply them Infinispan caches all transaction state for future use. 
			This state is held only for in-doubt transaction, being removed for successfully completed transactions after the commit/rollback phase completed.
		Reconciliation
			Via JMX: Cache/RecoveryAdmin
		

Locking and Concurrency
	Infinispan makes use of MVCC (refer to MVCC.txt)
	How it works in clustered caches
		In clustered caches, each key has a node responsible to lock the key. This node is called primary owner.
		Non Transactional caches
			The write operation is sent to the primary owner of the key.
			The primary owner tries to lock the key.
				If it succeeds, it forwards the operation to the other owners;
				Otherwise, an exception is thrown.
		Pessimistic transactional cache (the locks are acquired during write/lock operations)
			A lock request is sent to the primary owner (can be an explicit lock request or an operation)
			The primary owner tries to acquire the lock:
				If it succeed, it sends back a positive reply;
				Otherwise, a negative reply is sent and the transaction is rollback.
		Optimistic transactional cache(locks are acquired during transaction prepare time)
			The prepare is sent to all the owners.
			The primary owners try to acquire the locks needed:
				If locking succeeds, it performs the write skew check.
				If the write skew check succeeds (or is disabled), send a positive reply.
				Otherwise, a negative reply is sent and the transaction is rolled back.
	Isolation levels
		Infinispan offers two isolation levels - READ_COMMITTED (the default) and REPEATABLE_READ
		These isolation levels determine when readers see a concurrent write
		LockManager
			responsible for locking an entry for writing
			makes use of a LockContainer to locate/hold/create locks
		LockContainer
			come in two broad flavours, with support for lock striping and with support for one lock per entry
	Data Versioning
		three forms of data versioning
			Simple versioning
			Partition-aware versioning
			External versioning
			
			
Config as Hibernate L2 Cache Provider
	If the Infinispan CacheManager instance happens to be bound to JNDI select JndiInfinispanRegionFactory as the cacheregion factory and add the cache manager’s JNDI name:
		<property name="hibernate.cache.region.factory_class" value="org.hibernate.cache.infinispan.JndiInfinispanRegionFactory" />
		<property name="hibernate.cache.infinispan.cachemanager" value="java:CacheManager/entity" />
		
		Note:
			JBoss Application Server 6 and 7 deploy a shared Infinispan cache manager that can be used by all services, so when trying to configure applications with Infinispan second level cache, you should use the JNDI name for the cache manager responsible for the second level cache. 
			By default, this is "java:CacheManager/entity". In any other application server, you can deploy your own cache manager and bind the CacheManager to JNDI, but in this cases it's generally preferred that the following method is used.
			
			
	If running JPA/Hibernate and Infinispan standalone or within third party Application Server, select the InfinispanRegionFactory as the cache region factory:
		<property name="hibernate.cache.region.factory_class" value="org.hibernate.cache.infinispan.InfinispanRegionFactory"/>
		
	
	Infinispan is transactional cache so transaction manager is required
	
	
Cache Detail:	
	Defaults for Entity/Collection Caching
		It's only cached locally in order to reduce intra-cluster traffic. This option cannot be changed.
		Use a synchronous invalidation as clustering mode
			This means that when an entity is updated, the updated cache will send a message to the other members of the cluster telling them that the entity has been modified. 
			Upon receipt of this message, the other nodes will remove this data from their local cache, if it was stored there.
			This option can be changed to use replication by configuring entities or collections to use "replicated-entity" cache but it’s generally not a recommended choice
		Initial state transfer disabled since there’s no need for it. It’s not recommended that this is enabled.
		READ_COMMITTED as cache isolation level
			If you really need to use REPEATABLE_READ, you can simply configure entities or collections to use "entity-repeatable" cache.
		eviction settings:
			Eviction wake up interval is 5 seconds
			Max number of entries are 10,000
			Max idle time before expiration is 100 seconds
		lazy deserialization
			helps deserialization when entities or collections are stored in isolated deployments. If you’re sure you'l never deploy your entities or collections in classloader isolated deployment archives, you can disable this setting.
			
	
	Defaults for Query Caching
		queries are only cached locally
			can configure query caching to use replication by selecting the "replicated-query" as query cache name.
			replication for query cache only makes sense if, and only if, all of this conditions are true:
				Performing the query is quite expensive
				The same query is very likely to be repeatedly executed on different cluster nodes
				The query is unlikely to be invalidated out of the cache
					Note: 
						Hibernate must aggressively invalidate query results from the cache any time any instance of one of the entity types targeted by the query
						All such query results are invalidated, even if the change made to the specific entity instance would not have affected the query result
		uses the same cache isolation levels and eviction/expiration settings as for entities/collections.
		query cache has initial state transfer disabled . It is not recommended that this is enabled.
		
	
	Defaults for Timestamps Cache
		configured with asynchronous replication as clustering mode.
			Local or invalidated cluster modes are not allowed, since all cluster nodes must store all timestamps. 
			As a result, no eviction/expiration is allowed for timestamp caches either .
		timestamps cache is configured with a cluster cache loader
		
		
Add data to 2LC:
	Entity
		Add via: 
			javax.persistence.sharedCache.mode=ENABLE_SELECTIVE
			@Cacheable	
	Query
 		Add via: 
 			hibernate.cache.use_query_cache=true
 			Query.setCacheable(true)
 		Note:
 			The query cache does not cache the state of the actual entities in the cache. It caches identifier values and results of value type. 
 			Therefore, always use the query cache in conjunction with the second-level cache for those entities which should be cached as part of a query result cache.
 			If Query corresponding Entity cache be removed, the data will be reloaded by identifier one by one

		
JTA Transactions Configuration
	It is highly recommended that Hibernate is configured with JTA transactions so that both Hibernate and Infinispan cooperate within the same transaction and the interaction works as expected.
		Otherwise
			if Hibernate is configured for example with JDBC transactions, Hibernate will create a Transaction instance via java.sql.Connection and Infinispan will create a transaction via whatever TransactionManager returned by hibernate.transaction.manager_lookup_class
			If hibernate.transaction.manager_lookup_class has not been populated, it will default on the dummy transaction manager
			any work on the 2nd level cache will be done under a different transaction to the one used to commit the stuff to the database via Hibernate. 
			your operations on the database and the 2LC are not treated as a single unit
			Risks here include failures to update the 2LC leaving it with stale data while the database committed data correctly.
			It has also been observed that under some circumstances where JTA was not used, commit/rollbacks are not propagated to Infinispan.
	
	Config:
		Unless your application uses JPA, you need to select the correct Hibernate transaction factory via the property hibernate.transaction.factory_class :
			If you’re running within an application server, it’s recommended that you use:
				<property name="hibernate.transaction.factory_class" value="org.hibernate.transaction.CMTTransactionFactory"/>
			If you’re running in a standalone environment and you wanna enable JTA transaction factory, use:
				<property name="hibernate.transaction.factory_class" value="org.hibernate.transaction.JTATransactionFactory"/>
			The reason why JPA does not require a transaction factory class to be set up is because the entity manager already sets it to a variant of CMTTransactionFactory.
		Select the correct Hibernate transaction manager lookup:
			If you’re running within an application server, select the appropriate lookup class according to "JTA Transaction Managers" table
				E.g
					<property name="hibernate.transaction.manager_lookup_class" value="org.hibernate.transaction.JBossTransactionManagerLookup"/>
			If you are running standalone and you want to add a JTA transaction manager lookup
				Due to a current limitation, Hibernate does not support injecting a JTA TransactionManager or JTA UserTransaction that are not bound to JNDI. 
				if you want to use JTA, Hibernate expects your TransactionManager to be bound to JNDI and it also expects that UserTransaction instances are retrieved from JNDI.
				This means that in a standalone environment, you need to add some code that binds your TransactionManager and UserTransaction to JNDI.
				Once you have the code in place, it’s just a matter of selecting the correct Hibernate transaction manager lookup class, based on the JNDI names given. If you take JBossStandaloneJtaExample as an example, you simply have to add:
					<property name="hibernate.transaction.manager_lookup_class" value="org.hibernate.transaction.JBossTransactionManagerLookup"/>

	there wasn’t a single mention of the need to configure Infinispan’s transaction manager lookup and there’s a good reason for that. 
	Basically, the code within Infinispan cache provider takes the transaction manager that has been configured at the Hibernate level and uses that. 
	Otherwise, if no Hibernate transaction manager lookup class has been defined, Infinispan uses a default dummy transaction manager.
	
	Since Hibernate 4.0, the way Infinispan hooks into the transaction manager can be configured
		By default, since 4.0, Infinispan interacts with the transaction manager as a JTA synchronization
		if desired, users can configure Infinispan to act as an XA resource (just like it did in 3.6 and earlier) by disabling the use of the synchronization. For example:
			<property name="hibernate.cache.infinispan.use_synchronization"  value="false"/>
			
			
Advanced Configuration
	exposing statistics via JMX
		<property name="hibernate.cache.infinispan.statistics" value="true"/>
		
	Infinispan cache provider jar file contains an Infinispan configuration file, which is the one used by default when configuring the Infinispan standalone cache region factory. 
	This file contains default cache configurations for all Hibernate data types that should suit the majority of use cases. 
	However, if you want to use a different configuration file, you can configure it via the following property:
		<property name="hibernate.cache.infinispan.cfg" value="/home/infinispan/cacheprovider-configs.xml"/>
	
	For each Hibernate cache data types, Infinispan cache region factory has defined a default cache name to look up
		You can change these cache names using the following properties:
			<property name="hibernate.cache.infinispan.entity.cfg" value="custom-entity"/>
			<property name="hibernate.cache.infinispan.collection.cfg"  value="custom-collection"/>
			<property name="hibernate.cache.infinispan.query.cfg" value="custom-collection"/>
			<property name="hibernate.cache.infinispan.timestamp.cfg" value="custom-timestamp"/>
		On top of that, this finer grained cache definition enables users to define cache settings on a per entity/collection basis. For example:
			<property name="hibernate.cache.infinispan.com.acme.Person.cfg" value="person-entity"/>
			<property name="hibernate.cache.infinispan.com.acme.Person.addresses.cfg" value="addresses-collection"/>
			
			Note:
				if you are running within JBoss Application Server, JBoss EAP, or Widlfly, providing just the entity name is not enough. 
				You need to add unit name and deployment name as well to each property in the following format: hibernate.cache.infinispan.<warname>.<unitname>.<FQN of entity>.....
				
	you can configure eviction/expiration this way:
		<property name="hibernate.cache.infinispan.entity.eviction.strategy" value= "LRU"/>
		<property name="hibernate.cache.infinispan.entity.eviction.wake_up_interval" value= "2000"/>
		<property name="hibernate.cache.infinispan.entity.eviction.max_entries" value= "5000"/>
		<property name="hibernate.cache.infinispan.entity.expiration.lifespan" value= "60000"/>
		<property name="hibernate.cache.infinispan.entity.expiration.max_idle" value= "30000"/>
		
	You can also override eviction/expiration settings on a per entity/collection type basis:
		<property name="hibernate.cache.infinispan.com.acme.Person.eviction.strategy" value= "FIFO"/>
		<property name="hibernate.cache.infinispan.com.acme.Person.eviction.wake_up_interval" value= "2500"/>
		<property name="hibernate.cache.infinispan.com.acme.Person.eviction.max_entries" value= "5500"/>
		<property name="hibernate.cache.infinispan.com.acme.Person.expiration.lifespan" value= "65000"/>
		<property name="hibernate.cache.infinispan.com.acme.Person.expiration.max_idle" value= "35000"/>
		
		
	Please note that query/timestamp caches work the same way they did with JBoss Cache based cache providers. 
	In other words, there’s a query cache instance and timestamp cache instance shared by all. 
	It’s worth noting that eviction/expiration settings are allowed for query cache but not for timestamp cache. 
	So configuring an eviction strategy other than NONE for timestamp cache would result in a failure to start up.
		
		
	queries with specific cache region names are stored under matching cache instances
		Query query = session.createQuery("select account.branch from Account as account where account.holder = ?");
		query.setCacheable(true);
		query.setCacheRegion("AccountRegion");
		
		The query would be stored under "AccountRegion" cache instance and users could control settings in similar fashion to what was done with entities and collections. 
		for example, you could define specific eviction settings for this particular query region doing something like this:
			<property name="hibernate.cache.infinispan.AccountRegion.eviction.strategy" value= "FIFO"/>
			<property name="hibernate.cache.infinispan.AccountRegion.eviction.wake_up_interval" value= "10000"/>


Handling custom identifiers types
	When custom identifier types are used in Hibernate/JPA entities, specially in the case of composite identifiers, the resulting cache keys can end up holding references to SessionFactory instances. 
	Serializing those properly in a clustered environment depends on being able to resolve the proper SessionFactory reference on deserialization, which can happen based on UUID (same JVM) or name (across JVMs).
	When the resolution does not succeed, it’s common to see errors similar to this:
		java.io.InvalidObjectException: Could not find a SessionFactory [uuid=0d0cdf26-dfe6-4285-9725-dfaa4821ecba,name=null]
	    at org.hibernate.internal.SessionFactoryImpl.locateSessionFactoryOnDeserialization(SessionFactoryImpl.java:1781)
	    at org.hibernate.internal.SessionFactoryImpl.readResolve(SessionFactoryImpl.java:1761)		
	The way to get around these error is by locking down the name of the SessionFactory across JVMs. This can be done by adding the following properties in the clustered application’s configuration:
		hibernate.session_factory_name = MySessionFactory
		hibernate.session_factory_name_is_jndi = false
	Note:
		These properties are not necessary if deploying in JBoss Application Server, Wildfly or EAP containers, 
		since the integration code already populates session factory name based on deployment unit information.


Using Infinispan as remote Second Level Cache
	set up second level cache in this way is generally not a good idea for the following reasons:
		part of the aim of the second level cache is to have data accessible locally rather than having to go to the database to retrieve it everytime this is needed. 
			Hence, if you decide to set the second level cache to be remote as well, you’re losing one of the key advantages of the second level cache: the fact that the cache is local to the code that requires it.
		Setting a remote second level cache can have a negative impact in the overall performance of your application
			cache misses require accessing a remote location to verify whether a particular entity/collection/query is cached. 
			With a local second level cache however, these misses are resolved locally and so they are much faster to execute than with a remote second level cache.
	
	There are however some edge cases where it might make sense to have a remote second level cache, for example:
		You are having memory issues in the JVM where JPA/Hibernate code and the second level cache is running. 
			Off loading the second level cache to remote Hot Rod servers could be an interesting way to separate systems and allow you find the culprit of the memory issues more easily.
		Your application layer cannot be clustered but you still want to run multiple application layer nodes
		Rather than having the second level cache in a remote server, you want to simply keep the cache in a separate VM still within the same machine. 
		Size the cache separate from the application, since the cache and the application server have very different memory profiles.
		
***** hibernate
Hibernate
	ORM(Object/Relational Mapping) solution for Java environments
	
	ORM refer to ODM.txt
	
	Details:
		<property name="date" type="timestamp" column="EVENT_DATE"/>
			types are called Hibernate mapping types, converters which can translate from Java to SQL data types and vice versa.
			Hibernate will try to determine the correct conversion and mapping type itself if the type attribute is not present in the mapping. 
			In some cases this automatic detection using Reflection on the Java class might not have the default you expect or need. This is the case with the date property. Hibernate cannot know if the property, which is of java.util.Date, should map to a SQL date, timestamp, or time column.
			
		A org.hibernate.Session represents a single-threaded unit of work. 
		The org.hibernate.SessionFactory is a thread-safe global object that is instantiated once.
		org.hibernate.Session is designed to represent a single unit of work (a single atomic piece of work to be performed)
		
		use the Hibernate org.hibernate.Transaction API. In this particular case we are using JDBC-based transactional semantics, but it could also run with JTA.
		The getCurrentSession() method always returns the "current" unit of work.
		the configuration option for this mechanism to "thread" in our src/main/resources/hibernate.cfg.xml? Due to that setting, the context of a current unit of work is bound to the current Java thread that executes the application.
		
		Hibernate offers three methods of current session tracking. The "thread" based method is not intended for production use; it is merely useful for prototyping and tutorials such as this one.
		
		A org.hibernate.Session begins when the first call to getCurrentSession() is made for the current thread.
		
		It is then bound by Hibernate to the current thread. When the transaction ends, either through commit or rollback, Hibernate automatically unbinds the org.hibernate.Session from the thread and closes it for you. If you call getCurrentSession() again, you get a new org.hibernate.Session and can start a new unit of work.
		
		2LC refer to Infinispan.txt

		Inheritance strategy
			Single table per class (default strategy)
				 all classes in the hierarchy are mapped to a single table in the database. This table has a discriminator column containing a value that identifies the subclass to which the instance represented by the row belongs.
			Joined subclass
				 fields or properties that are specific to a subclass are mapped to a different table than the fields or properties that are common to the parent class
				 the root of the class hierarchy is represented by a single table, and each subclass has a separate table that contains only those fields specific to that subclass. That is, the subclass table does not contain columns for inherited fields or properties. 
			Table per concrete class (Support for this strategy is optional and may not be supported by all Java Persistence API providers.)
				one table per concrete class and subclass is present and each table persist the properties of the class and its superclasses
		
		Mapped Superclasses
			Entities may inherit from superclasses that contain persistent state and mapping information but are not entities.
			Mapped superclasses cannot be queried and can’t be used in EntityManager or Query operations.
			Mapped superclasses do not have any corresponding tables in the underlying datastore.
			
			
Envers
Envers is to provide historical versioning of your application's entity data
	Much like source control management tools such as Subversion or Git
	Hibernate Envers manages a notion of revisions if your application data through the use of audit tables
	Each transaction relates to one global revision number which can be used to identify groups of changes
	As the revisions are global, having a revision number, you can query for various entities at that revision, retrieving a (partial) view of the database at that revision.
	You can find a revision number having a date, and the other way round, you can get the date at which a revision was committed.
***** ERP
	Enterprise resource planning
***** datomic
Setup:
    install client jar to local maven repo:
        mvn install:install-file -DgroupId=com.datomic -DartifactId=datomic-pro -Dfile=datomic-pro-0.9.5359.jar -DpomFile=pom.xml
    add client dependency:
        [com.datomic/datomic-pro "0.9.5350"]


Datalog - datomic query language
    :find
    :in
    :where

    data clause
        [?entity ?attribute ?value]

        Note: this means do pattern match with the datums:
            datoms' entity = ?entity
            datoms' attribute = ?attribute
            datoms' value = ?value
            Note: datoms' entity is an id
                pattern match means: [?entity ?attribute ?value] match some data in db when ?entity = xxx ?attribute = xxx ?value = xxx
                The pattern have some fixed shape & some variable shape(variables part)
                    As pattern have some fixed shape, it can match only some datum(both in db or not)
                    If the variable part limited in a scope, it can match less(normally we only need to part in db)
                attribute key & value can be entity also

    expression clause
        [(function input-arg*) output-binding]

    d/entity will returns an object that implements datomic.Entity, a Map-like interface



Datomic - save whole data (data's past parts and current part)
Traditional DB - save part of data (data's current part)
***** AMQP
Internet Protocol for Business Messaging
***** flyway
Flyway
	database migration tool
	
	6 basic commands: Migrate, Clean, Info, Validate, Baseline and Repair.
	
	Migrate
		Flyway updates the database from one version to the next using migrations
***** git
git remote set-url origin https://xfcjscn:Shark1011@github.com/xfcjscn/apps.git

revert operate on indexed/commited stuff, but the result will put into work tree

discard operate on work tree, of courae the result will in work tree
***** github
models of collaborative development
	Fork & Pull
		Fork an existing repository and push changes to their personal fork without requiring access be granted to the source repository.
		The changes must then be pulled into the source repository by the project maintainer.
	Shared Repository Model
		Everyone is granted push access to a single shared repository
***** putty
Key location & name:
	Private Key:
		*.ppk
	Public Key:
		*.pub


Key format:
	Private Key(also contains public key):
		PuTTY-User-Key-File-2: ssh-rsa
		Encryption: none
		Comment: ${any text can be here}
		Public-Lines: 6
		${public key string}
		Private-Lines: 14
		${private key string}
		Private-MAC: f64f10e8a562f83a1b402464ab3e55afca2c9349
		
	Public Key:
		---- BEGIN SSH2 PUBLIC KEY ----
		Comment: "${any text can be here}"
		${public key string}
		---- END SSH2 PUBLIC KEY ----
***** Go
Go is a tool to support CD (Refer to CD.txt)
	Go will capture snapshot of system env variables when start
		
	Pipeline Dependency
		Fan-in
		Fan-out
		
		
	build cloud
		reason:
			Run your tests on several different platforms
			promote builds from one environment to the next
			
	Concepts:
		material
		Resources are simple text tags which you associate with each agent
		
	Go will deliver runable artifact to PRD, not repo
	
	Stage Context:
		Material
		Artifact
	
	Start multiple agent in one machine:
		cd /var/lib/go-agent*/
		(java -jar /usr/share/go-agent/agent-bootstrapper.jar 127.0.0.1 &)
	
	Authorization
		Administrators 
			is a special role that allows its members to perform any action in Go. 
			Specifying administrators is optional -- without it, all users are automatically made administrators.
			only they can perform the following actions:
				Access the "administration" tab
				Add/Edit Pipeline Templates
				Enable agents
				Add / remove agent resources
			Users can be made administrators from the "User Summary" tab in the "Admin" section
		permissions for pipeline groups
			view
			operate
			admin
		authorization
			can apply to pipeline group & stage approval & template 
			If no authorization is defined for a pipeline group, all Go users will have view and operate permissions to that group.
			
			
	Architecture
		Go Server
			Display artifacts in tab
				Config: tabs/tab/name & tabs/tab/path
		Go Agent
			Runs the jobs given to it by the Go Server
			Publish output to Go Server
				output can be artifact, test
				Config: artifacts/artifact/src & artifacts/artifact/dest
							artifacts/test/src
			comprises of 3 parts:
				Agent Bootstrapper
					requires a manual upgrade, therefore its code is kept to a bare minimum to avoid this manual upgrade.
					A new installation of an agent has only the agent-bootstrapper.jar
					Todo:
						Start Agent Launcher, if not available create a temporary one
					starts the agent-bootstrapper.jar, which does the following:
						Facilitate the automatic upgrade of the agent-launcher.
						Launches the agent-launcher.
							Steps:
								Creates a temporary launcher jar, with the format [UUID]agent-launcher.jar, by copying over the agent-launcher.jar
								Reads the values of specific keys from MANIFEST.MF of the agent-launcher.jar. This is done to determine which class needs to be launched from the Launcher.
								Gets the AgentLauncher class.
								Launches the launcher by calling the launch method on the AgentLauncher class.
						If at any point the launcher process is killed, the bootstrapper re-launches it
				Agent Launcher
					Todo:
						Check for Update & Update itself
						Update & Run Agent
					Steps:
						Creates a lockfile. The purpose of the lockfile is to prevent multiple instances of the bootstrapper from being launched using the same agent-bootstrapper.jar
						Checks to see if a new version of the agent-launcher.jar is available. This is done by comparing the md5 checksum of the agent-launcher.jar present locally with the agent-launcher.jar on the Go Server. If the launcher is upgrades itself, it returns and it is then restarted by the bootstrapper.
						Downloads the agent.jar from the Go server if required. It then starts the agent by determining the starting point of the agent, AgentProcessParentImpl, by reading specific keys from MANIFEST.MF of the agent.jar and starting it.
				Agent
					The agent is responsible for running a job given to it by the server.
					Todo:
						Check for Update itself
						...
					An agent has 3 threads running as part of it:
						Ping Thread - runs every 5 seconds, to inform the server that the agent is alive. It also informs the server of the agents runtime information.
						Loop/Worker Thread - The first time an agent comes up, the loop thread, which runs every 10 seconds, registers it with the server. Once this is done, it checks for agent upgrade and also retrieves work from the server.
						Instruction Execution Thread - which runs every 10 seconds to check if the server has issued a job cancel instruction. A separate thread is maintained as a job cancel instruction is an asynchronous action, it might occur at any time and hence, it has to be monitored constantly.
						


e2e for linux:
<?xml version="1.0" encoding="utf-8"?>
<cruise xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="cruise-config.xsd" schemaVersion="72">
	<templates>
		<pipeline name="appServerDeploy">
			<stage name="buildAndUnitTest">
				<jobs>
					<job name="buildAndUnitTest">
						<tasks>
							<exec command="mvn">
								<arg>-P</arg>
								<arg>runtime.appsvr.wildfly.domain,test.integration</arg>
								<arg>clean</arg>
								<arg>install</arg>
								<arg>-Druntime.appsvr.configuration.management.hostname=#{sit.wildfly.hostname}</arg>
								<arg>-Druntime.appsvr.configuration.management.port=#{sit.wildfly.port}</arg>
								<arg>-Druntime.appsvr.configuration.management.username=#{sit.wildfly.username}</arg>
								<arg>-Druntime.appsvr.configuration.management.password=#{sit.wildfly.password}</arg>
								<arg>-Druntime.appsvr.configuration.domain.server-group=#{sit.wildfly.server-group}</arg>
								<arg>-Dwildfly.deployment.name=#{sit.wildfly.deployment.name}</arg>
							</exec>
						</tasks>
						<artifacts>
							<artifact src="target" />
						</artifacts>
					</job>
				</jobs>
			</stage>
			<stage name="deployToSIT">
				<jobs>
					<job name="deployToSIT">
						<tasks>
							<fetchartifact pipeline="" stage="buildAndUnitTest" job="buildAndUnitTest" srcdir="target">
								<runif status="passed" />
							</fetchartifact>
							<exec command="mvn">
								<arg>-P</arg>
								<arg>runtime.appsvr.wildfly.domain</arg>
								<arg>wildfly:deploy-only</arg>
								<arg>-Druntime.appsvr.configuration.management.hostname=#{sit.wildfly.hostname}</arg>
								<arg>-Druntime.appsvr.configuration.management.port=#{sit.wildfly.port}</arg>
								<arg>-Druntime.appsvr.configuration.management.username=#{sit.wildfly.username}</arg>
								<arg>-Druntime.appsvr.configuration.management.password=#{sit.wildfly.password}</arg>
								<arg>-Druntime.appsvr.configuration.domain.server-group=#{sit.wildfly.server-group}</arg>
								<arg>-Dwildfly.deployment.name=#{sit.wildfly.deployment.name}</arg>
								<runif status="passed" />
							</exec>
						</tasks>
					</job>
				</jobs>
			</stage>
			<stage name="deployToUAT">
				<approval type="manual" />
				<jobs>
					<job name="deployToUAT">
						<tasks>
							<fetchartifact pipeline="" stage="buildAndUnitTest" job="buildAndUnitTest" srcdir="target">
								<runif status="passed" />
							</fetchartifact>
							<exec command="mvn">
								<arg>-P</arg>
								<arg>runtime.appsvr.wildfly.domain</arg>
								<arg>wildfly:deploy-only</arg>
								<arg>-Druntime.appsvr.configuration.management.hostname=#{uat.wildfly.hostname}</arg>
								<arg>-Druntime.appsvr.configuration.management.port=#{uat.wildfly.port}</arg>
								<arg>-Druntime.appsvr.configuration.management.username=#{uat.wildfly.username}</arg>
								<arg>-Druntime.appsvr.configuration.management.password=#{uat.wildfly.password}</arg>
								<arg>-Druntime.appsvr.configuration.domain.server-group=#{uat.wildfly.server-group}</arg>
								<arg>-Dwildfly.deployment.name=#{uat.wildfly.deployment.name}</arg>
								<runif status="passed" />
							</exec>
						</tasks>
					</job>
				</jobs>
			</stage>
			<stage name="deployToPRD">
				<approval type="manual" />
				<jobs>
					<job name="deployToPRD">
						<tasks>
							<fetchartifact pipeline="" stage="buildAndUnitTest" job="buildAndUnitTest" srcdir="target">
								<runif status="passed" />
							</fetchartifact>
							<exec command="mvn">
								<arg>-P</arg>
								<arg>runtime.appsvr.wildfly.domain</arg>
								<arg>wildfly:deploy-only</arg>
								<arg>-Druntime.appsvr.configuration.management.hostname=#{prd.wildfly.hostname}</arg>
								<arg>-Druntime.appsvr.configuration.management.port=#{prd.wildfly.port}</arg>
								<arg>-Druntime.appsvr.configuration.management.username=#{prd.wildfly.username}</arg>
								<arg>-Druntime.appsvr.configuration.management.password=#{prd.wildfly.password}</arg>
								<arg>-Druntime.appsvr.configuration.domain.server-group=#{prd.wildfly.server-group}</arg>
								<arg>-Dwildfly.deployment.name=#{prd.wildfly.deployment.name}</arg>
								<runif status="passed" />
							</exec>
						</tasks>
					</job>
				</jobs>
			</stage>
		</pipeline>
		<pipeline name="webServerDeploy">
			<stage name="buildAndUnitTest">
				<jobs>
					<job name="buildAndUnitTest">
						<tasks>
							<exec command="npm">
								<arg>install</arg>
							</exec>
							<exec command="bower">
								<arg>install</arg>
								<runif status="passed" />
							</exec>
							<exec command="grunt">
								<arg>build</arg>
								<runif status="passed" />
							</exec>
						</tasks>
						<artifacts>
							<artifact src="dist" />
						</artifacts>
					</job>
				</jobs>
			</stage>
			<stage name="deployToSIT">
				<jobs>
					<job name="deployToSIT">
						<tasks>
							<fetchartifact pipeline="" stage="buildAndUnitTest" job="buildAndUnitTest" srcdir="dist">
								<runif status="passed" />
							</fetchartifact>
							<exec command="scp">
								<arg>-Br</arg>
								<arg>dist/public</arg>
								<arg>#{sit.webserver.username}@#{sit.webserver.hostname}:#{sit.webserver.path}</arg>
								<runif status="passed" />
							</exec>
						</tasks>
					</job>
				</jobs>
			</stage>
			<stage name="deployToUAT">
				<approval type="manual" />
				<jobs>
					<job name="deployToUAT">
						<tasks>
							<fetchartifact pipeline="" stage="buildAndUnitTest" job="buildAndUnitTest" srcdir="dist">
								<runif status="passed" />
							</fetchartifact>
							<exec command="scp">
								<arg>-Br</arg>
								<arg>dist/public</arg>
								<arg>#{uat.webserver.username}@#{uat.webserver.hostname}:#{uat.webserver.path}</arg>
								<runif status="passed" />
							</exec>
						</tasks>
					</job>
				</jobs>
			</stage>
			<stage name="deployToPRD">
				<approval type="manual" />
				<jobs>
					<job name="deployToPRD">
						<tasks>
							<fetchartifact pipeline="" stage="buildAndUnitTest" job="buildAndUnitTest" srcdir="dist">
								<runif status="passed" />
							</fetchartifact>
							<exec command="scp">
								<arg>-Br</arg>
								<arg>dist/public</arg>
								<arg>#{prd.webserver.username}@#{prd.webserver.hostname}:#{prd.webserver.path}</arg>
								<runif status="passed" />
							</exec>
						</tasks>
					</job>
				</jobs>
			</stage>
		</pipeline>
		<pipeline name="DSRDeploy">
			<stage name="build">
				<jobs>
					<job name="build">
						<tasks>
							<exec command="mvn">
								<arg>-Druntime.websvr.hostname=#{build.websvr.hostname}</arg>
								<arg>-Druntime.websvr.port=#{build.websvr.port}</arg>
								<arg>clean</arg>
								<arg>package</arg>
							</exec>
						</tasks>
						<artifacts>
							<artifact src="target" />
						</artifacts>
					</job>
				</jobs>
			</stage>
			<stage name="sit">
				<jobs>
					<job name="sit">
						<tasks>
							<fetchartifact pipeline="" stage="build" job="build" srcdir="target">
								<runif status="passed" />
							</fetchartifact>
							<exec command="scp">
								<arg>-Br</arg>
								<arg>target/#{artifact.name}</arg>
								<arg>go@#{sit.appsvr.hostname}:#{sit.appsvr.path}</arg>
							</exec>
							<exec command="ssh">
								<arg>go@#{sit.appsvr.hostname}</arg>
								<arg>supervisorctl</arg>
								<arg>restart</arg>
								<arg>#{sit.appsvr.processname}</arg>
							</exec>
						</tasks>
					</job>
				</jobs>
			</stage>
			<stage name="uat">
				<approval type="manual" />
				<jobs>
					<job name="uat">
						<tasks>
							<fetchartifact pipeline="" stage="build" job="build" srcdir="target">
								<runif status="passed" />
							</fetchartifact>
							<exec command="scp">
								<arg>-Br</arg>
								<arg>target/#{artifact.name}</arg>
								<arg>go@#{uat.appsvr.hostname}:#{uat.appsvr.path}</arg>
							</exec>
							<exec command="ssh">
								<arg>go@#{uat.appsvr.hostname}</arg>
								<arg>supervisorctl</arg>
								<arg>restart</arg>
								<arg>#{uat.appsvr.processname}</arg>
							</exec>
						</tasks>
					</job>
				</jobs>
			</stage>
			<stage name="prd">
				<approval type="manual" />
				<jobs>
					<job name="prd">
						<tasks>
							<fetchartifact pipeline="" stage="build" job="build" srcdir="target">
								<runif status="passed" />
							</fetchartifact>
							<exec command="scp">
								<arg>-Br</arg>
								<arg>target/#{artifact.name}</arg>
								<arg>go@#{prd.appsvr.hostname}:#{prd.appsvr.path}</arg>
							</exec>
							<exec command="ssh">
								<arg>go@#{prd.appsvr.hostname}</arg>
								<arg>supervisorctl</arg>
								<arg>restart</arg>
								<arg>#{prd.appsvr.processname}</arg>
							</exec>
						</tasks>
					</job>
				</jobs>
			</stage>
		</pipeline>
		<pipeline name="NginxConfig">
			<stage name="sit">
				<jobs>
					<job name="sit">
						<tasks>
							<exec command="scp">
								<arg>-Br</arg>
								<arg>nginx.sit.conf</arg>
								<arg>go@#{sit.websvr.hostname}:#{sit.websvr.config.path}</arg>
							</exec>
							<exec command="ssh">
								<arg>go@#{sit.websvr.hostname}</arg>
								<arg>nginx</arg>
								<arg>-s</arg>
								<arg>reload</arg>
							</exec>
						</tasks>
					</job>
				</jobs>
			</stage>
			<stage name="uat">
				<approval type="manual" />
				<jobs>
					<job name="uat">
						<tasks>
							<exec command="scp">
								<arg>-Br</arg>
								<arg>nginx.uat.conf</arg>
								<arg>go@#{uat.websvr.hostname}:#{uat.websvr.config.path}</arg>
							</exec>
							<exec command="ssh">
								<arg>go@#{uat.websvr.hostname}</arg>
								<arg>nginx</arg>
								<arg>-s</arg>
								<arg>reload</arg>
							</exec>
						</tasks>
					</job>
				</jobs>
			</stage>
			<stage name="prd">
				<approval type="manual" />
				<jobs>
					<job name="prd">
						<tasks>
							<exec command="scp">
								<arg>-Br</arg>
								<arg>nginx.prd.conf</arg>
								<arg>go@#{prd.websvr.hostname}:#{prd.websvr.config.path}</arg>
							</exec>
							<exec command="ssh">
								<arg>go@#{prd.websvr.hostname}</arg>
								<arg>nginx</arg>
								<arg>-s</arg>
								<arg>reload</arg>
							</exec>
						</tasks>
					</job>
				</jobs>
			</stage>
		</pipeline>
	</templates>

</cruise>
***** GPG
GPG
	keyring file
		for pub keyring
			pub
				keyid
			uid
			sub - sub key
				some tool use sub key to signing
			
		for private/secret keyring
			sec
				keyid
			uid
			ssb - secret sub key?
	
	
	Commands:
		gpg --gen-key
			generate a key pair
			
		gpg2 -ab temp.java
			create a file like temp.java.asc , which is the signature of temp.java
			
		gpg2 --verify temp.java.asc
			verify the main file
		
		gpg2 --keyserver hkp://pool.sks-keyservers.net --send-keys E8D5D8F3
			distribute key to pub server
		
		gpg2 --keyserver hkp://pool.sks-keyservers.net --recv-keys E8D5D8F3
			receive key
	
		gpg2 --edit-key E8D5D8F3
			edit key
***** gradle
Plugin
	An extension to Gradle

	configures your project in some way, typically by adding some pre-configured tasks which together do something useful

	Gradle ships with a number of plugins

	Apply Plugin:
		apply plugin: 'java'


Gradle Wrapper
	Used to install, if not available, gradle and run gradle with given arguments

	Wrapper Files:
		gradlew
		gradle/wrapper/gradle-wrapper.jar
		gradle/wrapper/gradle-wrapper.properties

	Install the Wrapper into project
		gradle wrapper


Gradle Daemon
	a long-lived background process that executes your builds much more quickly than would otherwise be the case
	We accomplish this by avoiding the expensive bootstrapping process as well as leveraging caching, by keeping data about your project in memory.

	Enabling the Daemon
		add 'org.gradle.daemon=true' to «USER_HOME»/.gradle/gradle.properties


Continuous build
	Gradle will keep satisfying the initial build request (until instructed to stop) by executing the build when it is detected that the result of the previous build is now out of date.

	Enable:
		Add argument '--continuous' in the command
***** grunt
Task manage tool run in Node.js
	Task may have multiple Targets
		Target is the execution of Task
		
		
	Core config file: Gruntfile.js
		grunt.initConfig() - init configs which will be used by tasks
			Parameter Example:
				concat: {	// Task
				    options: {	// Options for Task
				      // Task-level options may go here, overriding task defaults.
				    },
				    foo: {	// Target
				      options: {
				        // "foo" target options may go here, overriding task-level options.
				      }
				    },
				    bar: {	// Target
				      // No options specified; this target will use task-level options.
				    }
				  }
		grunt.registerTask() - register task


	Files:
		Format:
			Compact
				e.g.
					src: ['src/bb.js', 'src/bbb.js'],
					dest: 'dest/b.js'

			Files Array
				e.g.
					files: [
						{src: ['src/aa.js', 'src/aaa.js'], dest: 'dest/a.js'},
						{src: ['src/aa1.js', 'src/aaa1.js'], dest: 'dest/a1.js'}
					]

			Files Object
				e.g.
					files: {
						'dest/b.js': ['src/bb.js', 'src/bbb.js'],
						'dest/b1.js': ['src/bb1.js', 'src/bbb1.js']
					}


		Config Properties:
			files
				src
				dest

				#### for "Compact" and "Files Array" Format:
				filter
				nonull
				dot
				matchBase
				expand - Process a dynamic src-dest file mapping

				#### for expand dynamic src-dest file mapping:
				cwd
				ext
				flatten
				rename



	build for generate-webapp process:
	    clean:dist - clean dist & .tmp
	    useminPrepare - parse index.html to generate config:
	        concat:generated
	        uglify:generated
	        cssmin:generated


	    concurrent:dist
	        compass - compile sass(app/styles) to css (.tmp/styles)
	        copy:styles - copy css(app/styles) to .tmp/styles/
	        imagemin - minify image(app/images) to dist
	        svgmin - minify svg(app/images) to dist


	    autoprefixer - add vendor-prefixed css property for css (.tmp/styles)

	    Below steps base on useminPrepare result:
	        concat - Concatenate JS & CSS from app or .tmp to .tmp/concat
	        cssmin - Minify Concatenated CSS from .tmp/concat to dist
	        uglify - Uglify Concatenated JS from .tmp/concat to dist

	    modernizr - generate customized modernizr
	    copy:dist - copy some files from app to dist
	    rev - revision files under dist
	    usemin - update all html & css under dist to refer to concat/min/revved files
	    htmlmin - minify html(dist/*.html) to dist


	    Note:
	        The build will only parse html to find linked/related/refered files.
	        This approach will miss indirections (files refered by refered files)
	        E.g. .img, .png, .woff, .tff files refered by css




	grunt-usemin:
		Replaces references to non-optimized scripts or stylesheets into a set of HTML files (or any templates/views).
		2 tasks:
			useminPrepare - prepares the configuration to transform specific construction (blocks) in the scrutinized file into a single line, targeting an optimized version of the files (e.g concatenated, uglifyjs-ed ...)
				the task parses your HTML markup to find each of these blocks, and initializes the corresponding Grunt config for the concat / uglify tasks when type=js, the concat / cssmin tasks when type=css.

				Default Transformation flow (configed by parameter: flow):
					{
                    	steps: {
                    		'js': ['concat', 'uglifyjs'],
                    		'css': ['concat', 'cssmin']
                    	},
                    	post: {}
                    }

				non-vendor script & css may need to be processed & stored in .tmp, so need to config alternate search path
					E.g.
						<!-- build:css(.tmp) styles/main.css -->, <!-- build:js({app,.tmp}) scripts/main.js -->


			usemin - replaces the blocks by the file they reference, and replaces all references to assets by their revisioned version if it is found on the disk. This target modifies the files it is working on.
				First it replaces all the blocks with a single "summary" line, pointing to a file creating by the transformation flow.
                Then it looks for references to assets (i.e. images, scripts, ...), and tries to replace them with their revved version if it can find one on disk


	grunt-bower-install:
		Check dependencies in bower.json & inject corresponding script & link tag into html (between <!-- bower:js --><!-- endbower --> & <!-- bower:css --><!-- endbower -->)
***** HA proxy

HAProxy
	offering high availability, load balancing, and proxying for TCP and HTTP-based applications.
		
***** configer
Config
	Configurer (Contains Instruction Data) read ConfigInfo to init Object/Value which will be used in later runtime.
	
	ConfigInfo
		Non-Instruction Data

***** avast
Sandbox
Process will run in a virtual env (sandbox folder, changes will store here). 
So changes will only done in the sandbox folder, not real files. 

***** eclipse
Eclipse - 
	Workbench - Work window
		Perspective(s) - A group of views & editors
	Workspace - Dir where work will stored. 


eclipse search
When search method, field:

If u search
com.hishark.ModelHelper.toString()  - No toString() in com.hishark.ModelHelper
It will automaticly identify which method to search (It should be Object.toString())
Then search

Means Eclipse will do:
1, Identify what exactly need to search (if u typed method not in the Type itsself, it will find it in its parent)
2, Perform fuzzy search (Parent Type may refer to sub Type)
		

***** eclipselink
EclipseLink - A JPA provider, adopted by sun as reference implementation
	Contains JPA-RS(a comp to expose JPA entity as RESTful web services)
		JPA-RS URI syntax: /persistence/{unit-name}/entity/{type}/{id}
			E.g. http://localhost:8080/persistence/ExamplePU/entity/Foo/1

***** axis
Elements info under xs:schema used to generte JAXB/xmlBeans objects
Other elements info will generate to Stub

***** cargo
Cargo
	
	2 set of config:
		container - container config
			type: embedded, installed, remote
		
		configuration - instance config
			type : standalone, existing, runtime

***** bitronix
Bitronix
	JTA impl
	
	Details:
		Bitronix use PoolingDataSource to encapsulate JDBC vendor's XADataSource (E.g. MysqlXADataSource)
			JDBC vendor's XADataSource is a mandatory, as XAConnection is there
			JDBC vendor's DataSource is a not mandatory, as Connection can retrieved via Driver directly
				
			This encapsulation provide: 
				pooling
				TransactionManager integration ?
				
		BitronixTransactionManager.resume(Transaction transaction)
			XAResourceManager.resume();
			ThreadContext ctx = new ThreadContext();
            ctx.setTransaction(transaction);
            setCurrentContext(ctx);
			

***** cxf
Servlet Config Without Spring: org.apache.cxf.jaxrs.servlet.CXFNonSpringJaxrsServlet
***** atomikos
AtomikosDataSourceBean
	extends DataSource
	encapsulate real XA datasource
		E.g.
			com.mysql.jdbc.jdbc2.optional.MysqlXADataSource

***** twitter bootstrap
Front-end UI component lib
	Different form other UI component, bootstrap UI components are responsive(change base on device)
	
	navbar:
		navbar-header, navbar-nav element will float to left in big screen , but will not float(take hole line) in small screen
		navbar-toggle will only show in small screen
		navbar-collapse will only overwrite collapse in big screen
		
***** cordova
Cordova - Wrap Web App into mobile Native App

	Implement:
		CordovaActivity
			onCreate() - create Layout: LinearLayoutSoftKeyboardDetect
			loadUrl()
				init()
					create WebView & add to Layout
					setContentView on Layout
				WebView.loadUrl()
	
	
	Embed WebView into existing page:
		Cordova Setup:
			1, Add cordova-3.4.0.jar to lib folder
			
			2, Add cordova config(config.xml) to res/xml
				<?xml version='1.0' encoding='utf-8'?>
				<widget id="net.gplatform.questionnaire" version="0.0.1" xmlns="http://www.w3.org/ns/widgets" xmlns:cdv="http://cordova.apache.org/ns/1.0">
				    <name>Questionnaire</name>
				    <description>
				        A sample Apache Cordova application that responds to the deviceready event.
				    </description>
				    <author email="dev@cordova.apache.org" href="http://cordova.io">
				        Apache Cordova Team
				    </author>
				    <content src="index.html" />
				    <access origin="*" />
				</widget>
		
		
		Setup Page to embed WebView:
			Default Page:
				CordovaActivity will programmatically create default page to embed WebWiew
			Existing Page:
				Add WebView into new/existing Layout config file
					<org.apache.cordova.CordovaWebView xmlns:android="http://schemas.android.com/apk/res/android"
					    android:id="@+id/questionnaireView"
					    android:layout_width="match_parent"
					    android:layout_height="match_parent" />
		
		
		Setup Activity to start WebView:
			Default Page:
				Create Activity extend CordovaActivity
					Activity Code:
						public class Questionnaire extends CordovaActivity {
							@Override
							public void onCreate(Bundle savedInstanceState) {
								super.onCreate(savedInstanceState);
								Log.i("Questionnaire onCreate", getIntent() + "");
								super.loadUrl(Config.getStartUrl());
							}
						}

			Existing Page:		
				Edit exist Activity to start WebView
						private void startView() {
							setContentView(R.layout.questionnaire);
							appView = (CordovaWebView) findViewById(R.id.questionnaireView);
							// load config.xml
							Config.init(this);
							appView.loadUrl(Config.getStartUrl());
						}
					
			Register Activity in AndroidManifest.xml
				<activity android:launchMode="singleTask" android:configChanges="orientation|keyboardHidden|keyboard|screenSize|locale" android:label="@string/app_name" android:name="net.gplatform.questionnaire.Questionnaire" android:theme="@android:style/Theme.Black.NoTitleBar">
				</activity>
***** bower
A package manager for the web
	Config:
		.bowerrc - bower command config
			directory - path to install dependency pkgs
			json -  bower package config (bower.json) path

			"bower xxx" will load ".bowerrc" in the script execute folder
			"bower install" will load dependencies recursively to the folder specified in.bowerrc


		bower.json - bower package config

	
	Commands: 
		bower install - install dependencies
		bower search jquery - search pkg
		bower update jquery - update pkg
		bower list - list dependencies
		

***** browser

	Request & Present web resource
	
	Main components
		UI
		Browser Engine
		Rendering Engine
		Networking
		UI backend
		JavaScript interpreter
		Data storage
	
	
	Flow
		Data:
			HTML -> DOM Tree													|		
			CSS(merged with style info in HTML) -> Style Rule Tree	| -> Render Tree
			
				Render Tree - Rectangle with visual attributes like: color, dimension
					Render Object (Renderer)
						Know how to layout & paint itself
						Represents a rectangular area usually corresponding to a node's CSS box
						The box type is affected by the "display" value of the style attribute that is relevant to the node
						The Renderers correspond to DOM elements, but the relation is not one to one. 
							Non-visual DOM elements will not be inserted in the render tree. 
								 An example is the "head" element. 
								 Also elements whose display value was assigned to "none" will not appear in the tree
							There are DOM elements which correspond to several visual objects
								For example, the "select" element has three renderers: one for the display area, one for the drop down list box and one for the button
								Also when text is broken into multiple lines because the width is not sufficient for one line, the new lines will be added as extra renderers. 
							Some render objects correspond to a DOM node but not in the same place in the tree
								Floats and absolutely positioned elements are out of flow, placed in a different part of the tree, and mapped to the real frame. A placeholder frame is where they should have been.
			
			
					Style Context Tree
						Maintain processed style info used by Render Tree
						
						Style Context is created from Style Rule Tree
						Style Context Tree is created from DOM Tree
						
						Style Context
							Contains end values
							The values are computed by applying all the matching rules in the correct order and performing manipulations that transform them from logical to concrete values
							The style contexts are divided into structs
							It can be shared by multiple Renderer
							
							Struct
								Contains processed style info for a certain category
									E.g. color, border
								All the properties in a struct are either inherited or non inherited
			
			
				Style Rule Tree
					Maintain raw style info
					Bottom node with high precedence
					This only in Gecko 
					
					
				
		
		Show:
			Layout -> Painting
			
			Layout - Give coordinate
			Painting - Paint element via UI backend





浏览器内核常驻线程大致包含以下：
    浏览器GUI渲染线程
    JavaScript引擎线程
    浏览器定时触发器线程
    浏览器事件触发线程
    浏览器http异步请求线程

GUI渲染线程和JavaScript引擎线程是互斥的，JavaScript执行时GUI渲染线程是挂起，页面将停止一切的解析和渲染行为。


浏览器模式
	控制浏览器发出的UserAgent，表示以哪个版本的浏览器发出请求
文档模式
	浏览器显示网页HTML的方式，在接到返回的HTML文件后，决定以哪个IE版本的文档模式解析该页面

***** bugzilla
Bugzilla is server software designed to help you manage software development.

***** dojo
<script src="http://ajax.googleapis.com/ajax/libs/dojo/1.7.1/dojo/dojo.js"
        data-dojo-config="async:true, parseOnLoad:true">
</script>

As show above data-dojo-config="async: true" is new introduced in DOJO1.7. 
If async:true, dojo will run in Baseless model, which means that all DOJO model not loaded except function : require. 
U can load any model (include base model) via this function. 
------------------------------------
dojoConfig:
	paths vs packages
		packages are similar to paths, In most scenarios, you should use packages. When creating a custom Dojo build to optimize your application, you will find additional options such as renaming packages on the fly and defining alternative destination locations for a package.
		The paths and aliases properties do allow for some powerful changes on the fly, and can be used to create some interesting loader configuration, especially in testing and debugging. However, really, the better option in newer versions of Dojo is the map property, which we¡¯ll cover in the next FAQ!

------------------------------------
Widget Creation:
	Programmatically - Create JS object
	Declaratively - Create "data-" attribute html element, and enable parseOnLoad
						data-dojo-type - Widget corresponding JS Type name
						data-dojo-props - Parameters for corresponding JS Type construction
						Ex: <xxx data-dojo-type="dojox.grid.DataGrid" data-dojo-props="store:myjsonRestStore1">
						
Widget is defined in a module, a return object of declare. 


	
	
------------------------------------
dojo.store.Observable
	Add Store.notify(objectUpdated, existingId)
		Invoke queryUpdaters with param objectUpdated & existingId.
		
	Enhance Store.query() to:
		Execute original query() to get "Query Result".
		Define observe() and attach to "Query Result".
			observe():
				Define queryUpdater(), which is used to invoke observer when objectUpdated match "Query Result"s query condition. 
		
	
	Enhance Store.put(), Store.add(), Store.remove() to invoke Store.notify() when method finished 
		



AMD impl:
require - create & execute Module
	(signature is (moduleId))
	getModule

	(signature is (requestList [,callback]))
	Generate syntheticMid ("require*" + uid())
	getModule for deps
	create module	& add into modules
	injectDependencies
	execModule


define - push args to defQ


getModule - create Module (not injected)
	getModuleInfo
		getModuleInfo_
			makeModuleInfo
				{pid:pid, mid:mid, pack:pack, url:url, executed:0, def:0, isXd:xd, isAmd:!!(xd || (packs[pid] && packs[pid].isAmd))}
	add ModuleInfo into modules
	

injectDependencies
	foreach injectModule
	

injectModule - injected Module
	injectUrl
		create script tag (execute define)
		onLoadCallback
			runDefQ
				injectDependencies
			mix nonModuleProps
			checkComplete
				execModule

		
execModule - execute Module
	execModule on deps
	runFactory
	finishExec


dbBuild
Used to merge AMD Loader, Dependent Modules into Target File(layer)


Script Command:
util\buildscripts\build.bat --profile shark [--release --layerOptimize closure --optimize shrinksafe]
	parameters also can declared in Profile Define.


Application build Profile:
	util\buildscripts\profiles\${profileName}.profile.js
		dependencies.layers - build result. in format of a single JavaScript file that contain several modules
		dependencies.layers.name - Target File, all Dependent Modules will merge to.
		dependencies.layers.dependencies - Dependent Modules, which will merge to Target File as define({cache:function(){.....}}). 
		dependencies.layers.customBase - remove legacy support, without this param the legacy support will generated to the Target File
		
		dependencies.optimize - optimize non-layer code
		dependencies.layerOptimize - optimize layer code
		dependencies.action - what to do
		dependencies.cssOptimize
		dependencies.releaseName
	

Package build Profile:
	package.json - used to find ${package}.profile.js
	${package}.profile.js - package build directives
		resourceTags - give resource categroy info
	
	


dijit._TemplatedMixin
Mix in data into template, which provided by sub-class via attribute "templateString". 

Usage:
	you need to do is add dijit/_TemplatedMixin as the second or subsequent argument in the array of class declarations for your widget
	Dijit adhere to a standard of creating a separate directory called templates at the same level as the JavaScript declaration
	
Template Grammar:
	data-dojo-attach-point : set the value of that attribute as a property of your widget to be a reference to the DOM element created
	${} : place holder
	data-dojo-attach-event : attach its dom's events to handlers(class's property)

Attach point containerNode:
	This class will put child elements inside this attach point refered node. 



dijit._WidgetBase
A class to provide widgets lifecycle management & basic attributes

lifecycle 

	instantiation: 
		constructor (common to all prototypes, called when instantiated)
		postscript (common to all prototypes built using declare)
			create
				postMixInProperties
				buildRendering
				postCreate - document fragment representing the widget is created¡ªbut before the fragment itself is added to the main document
		startup - after fragments have been actually added to the document
	
	destruction:
		destroyRecursive
			destroyDescendants
			destroy
				uninitialize
				destroyRendering
				
				
Property:
	domNode - a reference to the overall parent node of the widget itself
	containerNode - a reference to a child node in a widget that may contain content or widgets defined outside of your widget definition
	Getters and Setters
	own() - 
	id - a unique string identifying the widget
	lang - a rarely-used string that can override the default Dojo locale
	dir - useful for bi-directional support
	class - the HTML class attribute for the widget's domNode
	style - the HTML style attribute for the widget's domNode
	title - most commonly, the HTML title attribute for native tooltips
	baseClass - the root CSS class of the widget
	srcNodeRef - the original DOM node that existed before it was "widgetified", if one was provided. Note that depending on the type of widget (e.g. templated widgets), this may be unset following postCreate, as the original node is discarded.



dojo.declare
declare(className, superclass, props)
	Create simpleConstructor/chainedConstructor
	prototype - refer to dojo.declare.jpg



store vs statefu model
StatefulModel - Data Model (An interface to access data.)
		Application can only talk to Data Model, Data Model talk to raw data. 
		
		
Store - A List to store data
		Application directly talk to raw data retrieved from List. 

	
	
***** ansible
Ansible
	Ansible is an IT automation tool
	
	most Ansible modules usually do not work like simple scripts. 
	They make the remote system look like you state, and run the commands necessary to get it there. 
	This is commonly referred to as ‘idempotence’, and is a core design goal of Ansible. 
	However, we also recognize that running arbitrary commands is equally important, so Ansible easily supports both.

	Install
        Apt:
            $ sudo apt-get install software-properties-common
            $ sudo apt-add-repository ppa:ansible/ansible
            $ sudo apt-get update
            $ sudo apt-get install ansible
        Yum:
            $ sudo yum install ansible
	    Details Refer to: http://docs.ansible.com/ansible/intro_installation.html


	Configuration (ansible.cfg)
		
		
	playbook
		Each playbook is composed of one or more ‘plays’ in a list.
		The goal of a play is to map a group of hosts to some well defined roles, represented by things ansible calls tasks. 
		At a basic level, a task is nothing more than a call to an ansible module
		It is the purpose of a play to map a selection of hosts to tasks.
		Modules are ‘idempotent’, meaning if you run them again, they will make only the changes they must in order to bring the system to the desired state. 
		The command and shell modules will typically rerun the same command again, which is totally ok if the command is something like ‘chmod’ or ‘setsebool’, etc. Though there is a ‘creates’ flag available which can be used to make these modules also idempotent.
		Tasks can be declared using the legacy “action: module options” format, but it is recommended that you use the more conventional “module: options” format. 
		The command and shell modules are the only modules that just take a list of arguments and don’t use the key=value form. 
		modules are written to be ‘idempotent’ and can relay when they have made a change on the remote system. 
		These ‘notify’ actions are triggered at the end of each block of tasks in a playbook, and will only be triggered once even if notified by multiple different tasks.
		Regardless of how many things notify a handler, it will run only once, after all of the tasks complete in a particular play.
		Handlers are best used to restart services and trigger reboots. You probably won’t need them for much else.
		 goal of a play in a playbook is to map a group of systems into multiple roles. 
		 Roles are ways of automatically loading certain vars_files, tasks, and handlers based on a known file structure. 
		 Roles are just automation around ‘include’ directives as described above, and really don’t contain much additional magic beyond some improvements to search path handling for referenced files.
		 Role dependencies can also be installed from source control repos or tar files
		
	
	Modules:
		ansible all -i  hosts -u root -k -m authorized_key -a "user=root key=https://raw.githubusercontent.com/xfcjscn/ZhongYong/master/3ZW/%E4%BF%AE%E9%81%93%E4%B9%8B%E8%B0%93%E6%95%99/EECS/MyPublicKey/id_rsa.pub"

      localhost:
              ansible localhost -m ping


    control windows server:
      connection options: ssh(prefered), winrm
      1, in windows erver: enable sshd & add pub key to authorized_keys(if user under admin group administrator_authorized_key, file permission incorrect also cause error!)
           copy id_rsa.pub C:\ProgramData\ssh\administrators_authorized_keys # as Match Group administrators in c:\programdata\ssh\sshd_config
           icacls administrators_authorized_keys /inheritance:r
           make sure owner: administrators in permission list
         Note: use "sshd -ddd" to debug
      2, in host invertory: config remote server's shell base on target server's configuration(refer to ssh section): ansible_shell_type=powershell

      software installation(https://docs.ansible.com/ansible/latest/user_guide/windows_usage.html):
        win_chocolatey(recommend)
        win_package
        win_command or win_shell








		
		
***** apache ds
ApacheDS
	LDAP server
	
	Configuration is stored under the ou=config partition
	
	Configuration:
		All configuration are under: ou=config & ou=system
		
		Changing the server port
			ou=transports,ads-serverId=ldapServer,ou=servers,ads-directoryServiceId=default,ou=config
		Changing the admin password, admin entry already in directory with default password "secret":
			uid=admin,ou=system
			
	Partition
		entries are stored in partition
		Each partition contains a complete entry tree, also referred to as a DIT
		Multiple partitions may exist and the entry trees they contain are disconnected from each other
		The entries in a particular partition are stored below some naming context called the partition suffix
		The default implementation of partitions is based on JDBM B+Trees
		ApacheDS default configuration contains a a data partition with the suffix "dc=example,dc=com"
		The schema subsystem and ApacheDS itself store their information in special partitions, "ou=schema", "ou=config" and "ou=system" respectively.
		
		
			

***** angularjs 1
Tech Stack to Support MVC (loose coupling and high cohesion):
	M

	V
		template
		directive
			Just a function which executes when the compiler encounters it in the DOM.
			ng-model - bi-direction bind, if not available create
			{{ expression | filter }} - sole-direction bind
			ng-src - Used to replace src attribute to prevents the browser from making an http request to an invalid location
			ng-click - bind the on click event with method in current scope
			ng-app - load the module associated with the directive
			Declare Example:
				angular.module('phonecatServices', [ ]).directive('directiveName', function factory(injectables) {
				  var directiveDefinitionObject = {
				    link: function postLink(scope, iElement, iAttrs) { ... }
				  };
				  return directiveDefinitionObject;
				  // or
				  // return function postLink(scope, iElement, iAttrs) { ... }
				});
		filter
			Declare Example:
				angular.module('phonecatFilters', []).filter('checkmark', function() {
				  return function(input) {
				    return input ? '\u2713' : '\u2718';
				  };
				});
			
			Usage Example:
				{{phone.connectivity.infrared | checkmark}}

		
	C
		Controller
			Get Model and expose to View(via $scope)
			There should be NO view related code(DOM content/listener manipulation) here




Initialization Steps:
	0, Browser insert & parse html to DOM
	1, Load module associated with the directive(ng-app)
	2, Create Injector
	3, Compile DOM inside ng-app
		Directive Execution:
			ng-controller:
				Create new $scope and execute controller
				Go ahead to compile
			
			form
				Create instance of 	FormController and put it into current scope with name value as key
				Go ahead to compile



Injector
	Inject Service
	framework Injector do DI base on the Controller's parameter name
	$XXX is framework reserved DI parameter naming pattern
	
	
	
Service
	Service Provider -> Service Factory -> Service
		Service Provider - Constructor functions
		Service Factory - Instance of Service Provider, contains $get method
		Service - Singleton object created by Service Factory's $get method
		
		Register Service Provider:
			$provide.provider()
			
			Below are syntax sugar:
				$provide.value()
				$provide.factory()
				$provide.service()
				$provide.constant()
			
			Note: these method also available in Module


	Useful Services
		$watch
			Maintain binding info. One binding map to one $watch. Generated in linking stage
		
		$digest
			Iterate & Check all $watch to see any changes available
		
		$apply
			Enter angular context (execute $rootScope.$digest)
			
			
			
Module - Support modulization(Group components)
	A module is a collection of configuration and run blocks which get applied to the application during the bootstrap process.
	
	Configuration blocks
		Configuration Service Provider
		
		Convenience methods:
			value('a', 123).
			factory('a', function() { return 123; }).
			directive('directiveName', ...).
			filter('filterName', ...);
			
			// same to:
			
			config(function($provide, $compileProvider, $filterProvider) {
				$provide.value('a', 123);
				$provide.factory('a', function() { return 123; });
				$compileProvider.directive('directiveName', ...);
				$filterProvider.register('filterName', ...);
			});

	Run blocks
		Create Service
		
***** open cooperative web framework
An operation/collaborative engine consist of coweb server(java servlet) & coweb client(js) used to publish/subscribe notification of changes via ajax

Install:
	mvn archetype:generate -DarchetypeGroupId=org.opencoweb -DarchetypeArtifactId=coweb-archetype -DarchetypeVersion=0.8.3.1
	mvn clean package
	mvn jetty:run-war

Code Example:
	Create cooperative session:	
		var sess = coweb.initSession();
		//connect to ./admin
		sess.prepare();
	
	Collaborate:
		collab = coweb.initCollab({
			id : "shoppinglist"
		});
		//subscribe topic
		collab.subscribeSync("change", this, "onRemoteChange");
		//send info to topic
		collab.sendSync("change", value, "update", pos);


***** open id
OpenID
	Not a SSO solution, a solution for Single Credential Multiple Sign On

OpenID (OID) is an open standard and decentralized protocol by the non-profit OpenID Foundation that 
allows users to be authenticated by certain co-operating sites (known as Relying Parties or RP) using a third party service. 
This eliminates the need for webmasters to provide their own ad hoc systems and allowing users to consolidate their digital identities.[1] In other words, users can log into multiple unrelated websites without having to register with their information over and over again; 
The OpenID standard provides a framework for the communication that must take place between the identity provider and the OpenID acceptor (the "relying party").

The OpenID protocol does not rely on a central authority to authenticate a user's identity. Moreover, neither services nor the OpenID standard may mandate a specific means by which to authenticate users, allowing for approaches ranging from the common (such as passwords) to the novel (such as smart cards or biometrics).

The term OpenID may also refer to an identifier as specified in the OpenID standard; these identifiers take the form of a unique Uniform Resource Identifier (URI), and are managed by some 'OpenID provider' that handles authentication.[1]

An end-user is the entity that wants to assert a particular identity

A relying party (RP) is a web site or application that wants to verify the end-user's identifier. Other terms for this party include "service provider" or the now obsolete "consumer". 

An identity provider, or OpenID provider (OP) is a service that specializes in registering OpenID URLs or XRIs. 

OpenID enables an end-user to communicate with a relying party. This communication is done through the exchange of an identifier or OpenID, which is the URL or XRI chosen by the end-user to name the end-user's identity. An Identity provider provides the OpenID authentication (and possibly other identity services). The exchange is enabled by a User-agent, which is the program (such as a browser) used by the end-user to communicate with the relying party and OpenID provider.

Logging in
an end-user typically has previously registered an OpenID (e.g. alice.openid.example.org) with an OpenID provider (e.g. openid.example.org)

end-user interacts with a relying party (such as a website) that provides an option to specify an OpenID for the purposes of authentication;

The relying party typically transforms the OpenID into a canonical URL form (e.g. http://alice.openid.example.org/).

With OpenID 1.0, the relying party then requests the HTML resource identified by the URL and reads an HTML link tag to discover the OpenID provider's URL (e.g. http://openid.example.org/openid-auth.php). The relying party also discovers whether to use a delegated identity (see below).

With OpenID 2.0, the relying party discovers the OpenID provider URL by requesting the XRDS document (also called the Yadis document) with the content type application/xrds+xml; this document may be available at the target URL and is always available for a target XRI.

There are two modes in which the relying party may communicate with the OpenID provider:

checkid_immediate, in which the relying party requests that the OpenID provider not interact with the end-user. All communication is relayed through the end-user's user-agent without explicitly notifying the end-user.
checkid_setup, in which the end-user communicates with the OpenID provider via the same user-agent used to access the relying party.
The checkid_immediate mode can fall back to the checkid_setup mode if the operation cannot be automated.

First, the relying party and the OpenID provider (optionally) establish a shared secret, referenced by an associate handle, which the relying party then stores. If using the checkid_setup mode, the relying party redirects the end-user's user-agent to the OpenID provider so the end-user can authenticate directly with the OpenID provider.

The method of authentication may vary, but typically, an OpenID provider prompts the end-user for a password or some cryptographic token, and then asks whether the end-user trusts the relying party to receive the necessary identity details.

If the end-user declines the OpenID provider's request to trust the relying party, then the user-agent is redirected back to the relying party with a message indicating that authentication was rejected; the relying party in turn refuses to authenticate the end-user.

If the end-user accepts the OpenID provider's request to trust the relying party, then the user-agent is redirected back to the relying party along with the end-user's credentials. That relying party must then confirm that the credentials really came from the OpenID provider. If the relying party and OpenID provider had previously established a shared secret, then the relying party can validate the identity of the OpenID provider by comparing its copy of the shared secret against the one received along with the end-user's credentials; such a relying party is called stateful because it stores the shared secret between sessions. In contrast, a stateless or dumb relying party must make one more background request (check_authentication) to ensure that the data indeed came from the OpenID provider.

After the OpenID has been verified, authentication is considered successful and the end-user is considered logged in to the relying party under the identity specified by the given OpenID (e.g. alice.openid.example.org). The relying party typically then stores the end-user's OpenID along with the end-user's other session information.



***** open JPA
openJPA - A JPA provider, just as eclipselink
	Contains JEST (a comp to expose JPA entity as RESTful web services)
		JEST URI syntax : http://{host}[:port]/{context}/{action}[/qualifier]* [?argument] [&argument]*
			E.g.  http://www.example.com:8080/jest/find/format=json?type=Person&1234

***** openshift
A PaaS Provider, provide Server Runtime(Tomcat...), Version Control(Git), Project Manage(Maven), Continuous Integration(Jenkin)
	.openshift folder is mandatory, since some server configs are here
	
	Application Folder Structure
		.openshift/markers/hot_deploy	-> enable hot deploy
		.openshift/markers/java7			-> run in java7 env
		.openshift/action_hooks/build
		.openshift/action_hooks/deploy
		.openshift/action_hooks/post_deploy

		${deployments} is different for different server, for tomcat 7 it's webapps
		${deployments}/example.war.dodeploy	-> A mark to indicate the action to be taken(only need for unziped war)
		${deployments}/example.war			->	Application to be deployed
		
	Remember to set aliase if you want to use your own domain name
	
	Only Gear initialized processes can have bind address permission
	
	It will give error "EACCES" if there is no privilege to perform the action
	
	

Build Process
The default life cycle consists of a build phase and a deploy phase
	Build Phase
		1.  OpenShift Online stops the application by running the gear stop command.
		2.  OpenShift Online runs the control pre-receive command for the primary cartridge.
		3.  OpenShift Online copies the new application source code to $OPENSHIFT_REPO_DIR. This is the only point in the build life cycle when OpenShift Online copies the application source code.
		4.  OpenShift Online runs the control update-configuration command for the primary cartridge.
		5.  OpenShift Online runs the control pre-build command for the primary cartridge.
		6.  OpenShift Online runs the pre-build user action hook, if present.
		7.  OpenShift Online runs the control build command for the primary cartridge.
		8.  OpenShift Online runs the build user action hook, if present.
		
	Deploy Phase
		1.  OpenShift Online starts all secondary cartridges in the application.
		2.  OpenShift Online runs the control deploy command for the primary cartridge.
		3.  OpenShift Online runs the deploy user action hook, if present.
		4.  OpenShift Online starts the primary cartridge using the gear start command.
		5.  OpenShift Online runs the control post-deploy command for the primary cartridge.
		6.  OpenShift Online runs the post-deploy user action hook, if present.

oc
oc new-app xfcjscn/apps

rhc
Red Hat Client, used to operate OpenShift service
	Command:
		rhc account
		rhc logout
		rhc setup
		rhc authorization add --scopes session --note My_token
		rhc authorization
		rhc authorization delete token_1, token_2
		rhc authorization delete-all
		rhc domain create automobile
		rhc apps
		rhc app delete ApplicationName
		rhc domain update Old_namespace New_namespace
		rhc domain delete namespace
		rhc alias add racer fast.cars.com
		rhc alias remove racer fast.cars.com
		rhc alias update-cert racer fast.cars.com --certificate cert.pem --private-key key.pem 
		rhc alias delete-cert racer fast.cars.com
		rhc cartridge list
		git clone ssh://a261d0fc2932413694456e3473fdc972@crossword-gametime.example.com/~/git/crossword.git/
		rhc app show forumweb
		rhc cartridge scale php -a hybrid --min 1 --max 10
		rhc cartridge scale php -a hybrid --min 1 --max 1
		rhc cartridge add CartType -a AppName
		rhc cartridge add postgresql -a racer
		rhc app ssh racer
		rhc app create App01 php --enable-jenkins
		rhc tail jenkins
		rhc tail App01
		rhc cartridge storage --help
		rhc cartridge storage --show -a forumweb
		rhc cartridge storage php-5.3 -a myapp --add 3gb
		rhc app tidy ApplicationName

***** machine learning
Square Error Cost Function

J(theta0, theta1)



line regression
  all points on the function line as many as possible

classify
  positive group points above the function line as many as possible
  negtive group points under the function line as many as possible
  
  x -> y -> round(y)
  no function line to map x to y, which is to map different values to only 2 value, the shape is some horizontal lines




Regression Model:
theta[] -> hyposethis-func
x[], hyposethis-func -> estimated-y[]
estimated-y[], y[] -> error[]
estimated-y[], y[] -> error[], cost-func -> cost[]


theta[], mean(cost[]) -> 


***** bootstrap
A program to create Execution of other program
  read bootstrap info -> prepare Enveroment & Executor -> start Execution


E.g.
  boot:
    build.boot -> Enveroment: Clojure Runtime ExecutionContext(namespace name binding, class name binding) + Class Path + Asset Path + Services & Executor: Clojure Runtime thread(all in one JVM process) -> Invoke Target Function
  lein:
    project.clj -> Same as boot but: Clojure Runtime thread(all in different JVM process) -> Invoke Target Function
  maven:
    pom.xml -> Enveroment: Java Runtime ExecutionContext(class name binding, 'this' binding i.e. method invoke target) + Class Path + Asset Path + Services & Executor: Java Runtime thread(all in different JVM process) -> Invoke Target Method

****** boot
A bootstrap program for clojure
Follow explicit over implicit
One JVM instance for multiple Clojure runtime

Cons:
files duplicated each time boot executed, this make too much disk IO & take too much disk space
******* Runtime structure of Classes

                           
| *Load Location* | start up                           | start up                         | Boot.main()                                 | ClojureRuntimeShim.newRuntime()                      | Compiler.eval()                                        |
|                 |                                    |                                  |                                             |                                                      | Compiler.load()                                        |
|                 |                                    |                                  |                                             |                                                      | Compiler.compile1()                                    |
|-----------------+------------------------------------+----------------------------------+---------------------------------------------+------------------------------------------------------+--------------------------------------------------------|
| *Class Loader*  | boot strap class loader            | sun.misc.Launcher$AppClassLoader | boot.bin.ParentClassLoader                  | boot.AddableClassloader                              | clojure.lang.DynamicClassLoader                        |
|                 | & sun.misc.Launcher$ExtClassLoader |                                  |                                             |                                                      |                                                        |
|-----------------+------------------------------------+----------------------------------+---------------------------------------------+------------------------------------------------------+--------------------------------------------------------|
| *Classes*       | java.* (Java Runtime, JVM)         | Boot                             | boot.App                                    | org.projectodd.shimdandy.impl.ClojureRuntimeShimImpl | clj compiled classes                                   |
|                 |                                    | boot.bin.ParentClassLoader       | boot.AddableClassloader                     | clojure.lang.RT                                      |                                                        |
|                 |                                    |                                  | org.projectodd.shimdandy.ClojureRuntimeShim | clojure.lang.IFn                                     | Note: each function have a DynamicClassloader instance |
|                 |                                    |                                  |                                             | clojure.lang.Symbol                                  |                                                        |
|                 |                                    |                                  |                                             | clojure.lang.Var                                     |                                                        |
|                 |                                    |                                  |                                             | clojure.lang.Compiler                                |                                                        |
|                 |                                    |                                  |                                             | clojure.lang.DynamicClassLoader                      |                                                        |
|                 |                                    |                                  |                                             | ...                                                  |                                                        |
|-----------------+------------------------------------+----------------------------------+---------------------------------------------+------------------------------------------------------+--------------------------------------------------------|
|                 |                                    |                                  |                                             | org.projectodd.shimdandy.impl.ClojureRuntimeShimImpl | clj compiled classes                                   |
|                 |                                    |                                  |                                             | clojure.lang.RT                                      |                                                        |
|                 |                                    |                                  |                                             | clojure.lang.IFn                                     | Note: each function have a DynamicClassloader instance |
|                 |                                    |                                  |                                             | clojure.lang.Symbol                                  |                                                        |
|                 |                                    |                                  |                                             | clojure.lang.Var                                     |                                                        |
|                 |                                    |                                  |                                             | clojure.lang.Compiler                                |                                                        |
|                 |                                    |                                  |                                             | clojure.lang.DynamicClassLoader                      |                                                        |
|                 |                                    |                                  |                                             | ...                                                  |                                                        |
|-----------------+------------------------------------+----------------------------------+---------------------------------------------+------------------------------------------------------+--------------------------------------------------------|
|                 |                                    |                                  |                                             | org.projectodd.shimdandy.impl.ClojureRuntimeShimImpl | clj compiled classes                                   |
|                 |                                    |                                  |                                             | clojure.lang.RT                                      |                                                        |
|                 |                                    |                                  |                                             | clojure.lang.IFn                                     | Note: each function have a DynamicClassloader instance |
|                 |                                    |                                  |                                             | clojure.lang.Symbol                                  |                                                        |
|                 |                                    |                                  |                                             | clojure.lang.Var                                     |                                                        |
|                 |                                    |                                  |                                             | clojure.lang.Compiler                                |                                                        |
|                 |                                    |                                  |                                             | clojure.lang.DynamicClassLoader                      |                                                        |
|                 |                                    |                                  |                                             | ...                                                  |                                                        |
|-----------------+------------------------------------+----------------------------------+---------------------------------------------+------------------------------------------------------+--------------------------------------------------------|
|                 |                                    |                                  |                                             | .                                                    | .                                                      |
|                 |                                    |                                  |                                             | .                                                    | .                                                      |
|                 |                                    |                                  |                                             | .                                                    | .                                                      |

******* aether shim
only aether.uber.jar, contains clojure ...,  in shim classpath to use boot.aether to resolve deps
******* Startup code
boot.bin.ParentClassLoader extend URLClassLoader
Boot
  import java.*
  import boot.bin.ParentClassLoader
  loader = new ParentClassLoader(Boot.class.getClassLoader())
  main()
    loader add URL: boot jar file
    loader set as thread context class loader
    loader load boot.App
    invoke boot.App.main
******* fileset
a map of: file relative path -> TmpFile (file info: folder, path, hash, time...)
different folders base on dimention: user(files in project, not generated by build task), input(on class path), output(in target folder)
benifie: fast search 
boot.core/tmp-dir! - create a new tmp empty dir
boot.core/add-resource - update fileset to add target folder's files as non-user role
boot.core/commit! - sync fileset to disk(add/remove files form disk), all changes should done via modify fileset then commmit!


	  
******* Don't know
Why all boot Tasks, both required and not required, created via clojure.lang.AFunction.withMeta() with class: clojure.lang.AFunction$1? Because deftask used with meta?

Why AddableClassLoader set to clojure.lang.Compiler.LOADER?

****** leiningen
plugin

simply function named $TASK in ns: leiningen.$TASK

***** mocha
Mocha
	JavaScript test framework running on node.js and the browser
	
	API:
		describe - test suit
		it - test case
	
	Normally test framework rely on assertion lib like: should, chai...
	
	
		
***** dommy & enfocus
Enfocus VS Dommy
Both are clojure idiomatic. 
Enfocus - use at, from, defaction which seems implicit over explicit
Dommy - use append seems explicit over implicit, latest version removed templating features, can use hipo instead.

***** cljs html generate
hiccup in cljs
hiccups - generate string
crate - generate node
hipo - generate node, also support reconciliate, interceptor, attribute handler, namespace

***** docker
## Use case
Can NOT remove, even hide, OS layer. So may not suitable for small team.

## Docker Engine
consists of:

 * a daemon, a server process that manages all the containers
 * a client, which acts as a remote control for the daemon
	
## Docker image
image file of Docker container

## Docker container
a process in a box  
The box contains everything the process might need, so it has the filesystem, system libraries, shell and such, but by default none of these are running. 


## Benefits:
Encapsulate artifact and runtime of program and its dependency, so that u can:

 * isolate different program
 * easily copy, move, remove installed program
 * have uniform operate interface(startup, shutdown...)
            
        
## Command Example

### Odoo:  

  	docker run -d -e POSTGRES_USER=odoo -e POSTGRES_PASSWORD=odoo --name db postgres
	  docker run -p 8069:8069 --name odoo --link db:db -t odoo

### MySql:  

  	docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql
  	docker run --name some-app --link some-mysql:mysql -d application-that-uses-mysql
	  docker run -it --link some-mysql:mysql --rm mysql sh -c 'exec mysql -h"$MYSQL_PORT_3306_TCP_ADDR" -P"$MYSQL_PORT_3306_TCP_PORT" -uroot -p"$MYSQL_ENV_MYSQL_ROOT_PASSWORD"'

### Nginx:  

	  docker run --name nginx --link odoo:odoo --link cms:cms -v /home/shark/nginx-config:/etc/nginx/conf.d:ro -d -p 80:80 -p 443:443 nginx
	
	
### Clojure:  

  	docker run -p 3000:3000 -d --name cms -v /home/shark/git-repo/cms:/usr/src/app -w /usr/src/app clojure lein ring server-headless
	
	
### Build, Tag, Push:  

    docker build -t xfcjscn/cms .
    docker push xfcjscn/cms


### cms:

    docker run --name cms -p 5555:5555 -v /home/shark/.m2:/root/.m2 xfcjscn/cms:1.3
    

### add user to docker group to have docker permission

    sudo usermod -g docker shark





***** kubernetes
# Use case
Manage containers. 

# Architecture:

Cluster
	Master
	Nodes
		Kubelet - communication between Master & Node
		Container rt - e.g. docker
		*Pod - atomic unit, a group of container & shared: volumes, networking, info about how to run container
		
	Service - logical set of Pods & access policy(expose Pods to outside), hide Pods die & replicate

	Deployment - seems: Pods* + Service



# Software:

Minikube
	lightweight Kubernetes impl
	install: curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 && chmod +x minikube && sudo mv minikube /usr/local/bin/

Kubectl
	Kubernetes CLI, use Kubernetes API to interact with cluster
	install: curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
	config:
		chmod +x ./kubectl
		mv ./kubectl ~/bin
	

# Commands:
minikube start ;; start cluster

kubectl version
kubectl cluster-info
kubectl get nodes
kubectl run my-first-deployment --image=docker.io/xfcjscn/apps --port=8080 ;; create deployment
kubectl get deployments

kubectl proxy ;; open proxy route request to cluster

kubectl get pods
kubectl describe pods
kubectl logs $POD_NAME


export POD_NAME=$(kubectl get pods -o go-template --template '{{range .items}}{{.metadata.name}}{{"\n"}}{{end}}')        ;; get pod name

kubectl exec $POD_NAME env ;; execute command in container, only one container in pod so ignore container name
kubectl exec -ti $POD_NAME bash

kubectl get services

kubectl expose  deployment/my-first-deployment --type="NodePort" --port 8080   ;; create service
kubectl describe services/my-first-deployment

export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template='{{(index .spec.ports 0).nodePort}}')

;; check info (label)
kubectl describe deployment
;; qeury by label
kubectl get pods -l run=kubernetes-bootcamp
kubectl get services -l run=kubernetes-bootcamp

;; add new label
kubectl label pod $POD_NAME app=v1

kubectl get pods -l app=v1


kubectl delete service -l run=kubernetes-bootcamp

kubectl scale deployments/kubernetes-bootcamp --replicas=4 ;; scale service via repilate pods

kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=jocatalin/kubernetes-bootcamp:v2 ;; update

kubectl rollout status deployments/kubernetes-bootcamp ;; check update status

kubectl rollout undo deployments/kubernetes-bootcamp ;; rollback update




**** Type System:
1, Type(subdivision) is base on type object(link to several constructor)
	E.g. Haskell
2, Type(subdivision) is base on Constructor
	E.g. Most OO language

**** Category:
imperative
declarative
	Expresses the logic of a computation without describing its control flow
functional
	Treats computation as the evaluation of mathematical functions and avoids state and mutable data
object-oriented
	OO is a approach/style, take everything as object.
	OO can used in:
		OOP, OOD


object-oriented programming
	The idea of object-oriented software originated in Norway in the mid 1960s with Simula, an extension to the Algol programming language
	Kay saw that the concept of objects had potential as a cognitive tool: they correspond well to the way people think about the world

	Objects were originally conceived as being 'behaviourally- complete'
		That term is not meant to imply that an object provides every conceivable behaviour that could be required of it in any context. 
		Rather, the term simply implies that within the context of a given application, all the functionality associated with a given entity is encapsulated in that entity, rather than being provided in the form of external functional procedures that act upon the entities.
	
		However, much of the business functionality required for the application is typically implemented in procedures or 'controllers' that sit on top of these entity objects. 
			Firesmith describes this pattern as:
				'dumb entity objects controlled by a number of controller objects'
			Firesmith suggests that this separation of procedure and data in object-oriented designs results in:
				'excessive coupling, and an inadequate distribution of the intelligence of the application between the classes'
	
	Traditional Programming VS OOP
		from Traditional Programming to OOP is just Taxology evolve
		
		Conversional Programming
			Explicitly separated software into procedure and data
				The assumption underlying this separation was that a computer system repeatedly applies the same procedure to different data
		

	OOP
		Group logic into classes
		Typical implementations:
			Class OO
				Use class extends to maintain Object relationship
			Prototype OO (refer to Cognize/Prototype.txt)
				Use prototype to maintain Object relationship

		Features:
			encapsulate (from Object internal view)
				Object can encapsulate attribute & behavior
			inheritance (from Object relationship view)
				Object can inherit from another Object, meanwhile have features from extended Object
			polymorphism (from Object external view)
				All sub-types can provide qualified behavior defined in parent type. So for specify behavior, there can be many different implementations.
				
				
	Method - A procedure/function associated with Object
		Class Method(Static Method) - have NO access to corresponding instance object
		Instance Method - have access to corresponding instance object
					
				
	Object Template - Constructor, this Constructor only used to create Object
		Category:
			class - Most OO language
			trait - In Scala
			function - In prototype language like JS
	
		Keywords To Create Constructor:
			class
			trait - In Scala
			object - In Scala, to create Constructor for singleton Object
			Int => Int - In Scala, shorthand for "Function1[Int, Int]"
	
			### Below keywords will implicitly create Constructor:
			def - In Scala, create function Object of anonymous Constructor
			new - In most langulages, when it used on abstract Constructor, it will create Object of anonymous Constructor
			(x:Int) => x+1 - In Scala, means: new Function1[Int, Int]{
											def apply(x:Int):Int = x + 1
										}
**** Application Level:
Platform (refer to Platform/Platform.txt)
Domain


Library VS Framework
	both are logics maintained in different format(different language, method or function)
		Library 
			usually be use by custom-written logic
			normally library is low level logic
                      focus on specific functionality implementation
                      E.g. Jquery, Dojo 


library
	A collection of implementations of behavior, provided for reuse by multiple independent programs
	
	static library
	dynamic library


		Framework
			usually use custom-written logic
			normally framework is high level logic
                      focus on code structure
       		Normally framework contains some library, so that application can structure their code on it.
	        	E.g. Angular.js, Ember.js

Architecture
	Exchange (refer to Exchange.txt)
		BS
		CS
	
Resource
	Resource
	Represent

Modularization & Layering
	Base on HCLC, if you can divide system into Modules in 2 approaches, the one have less Coupling is better.
		E.g. Vertical Division vs Horizontal Division
	
	Decompose system into to Components/Layers base on logic category
		Concrete level depends on abstract level
			When concrete level invoke abstract level, concrete level specific info will be removed
	Loose Relationships of Components/Layers
		Relationships Can be:
			Function Dependency - Rely on other component's functionality
			Code Dependency - Not only rely on other component's functionality, but also have API reference
		If we can remove relationship, pls remove.
		If we can not remove relationship, try to avoid Code Dependency.


Unix Kernel-Shell Architecture
	Shell take user interaction responsibility(user can be any object)
	Kernel take other responsibility


Separated Presentation(Refer to ITSystem.txt):
	Derived from unix kernel-shell architecture?
	Its name not as good as kernel-shell, since there should be a comp to handle input?
	Separation:
		Domain Model
		Presentation(UI?)
			Presentation Model (Application Model in Visual Works Smalltalk)
				Presentation state and behavior
			View
				Project the state of the Presentation Model onto the glass
				Hand these user gestures events off to the Presentation Model
	Data flow:
		Input -> View -> Presentation Model -> Domain Model
		Output -> Domain Model -> Presentation Model ->View

Direct-Manipulation
	you want the objects on the screen to be the objects in the program
	Prior to the proposal of the MVC pattern, objects were seen as having the responsibility to display themselves.
	did not encourage the separation of data and procedure


MVC:
	Derived from Separated Presentation? I like Separated Presentation as the concept is more reasonable.
	Software architectural pattern for implementing user interfaces.
	mvc group structure is following hardware group structure
	
	Data flow:
		Input -> Controller -> Domain Model
		Assume:
			Output -> Domain Model ->View
		In practice:
			Output -> Domain Model -> View Model ->View
	
  	M - Model
  			Domain Model in Separated Presentation
  				
  	V - Visualize M
  			Map to Separated Presentation/Presentation/View
  			But Assumes that all the state of the View can be derived from the state of the Model
  			But in practice, View is bind to ViewModel (Separated Presentation/Presentation/Presentation Model)
  			
  	C - Accept Input & Invoke M & C
  			Map to Separated Presentation/Presentation/Presentation Model
  			Input will router to Controller then to DomainModel
  			Types:
	  			Front Controller
	  			Controller

	All framework & liberary should matrix under infra layer, nothing to do with MVC, because these logic is not application specific.
	Some logic/code seems in specific application but in fact nothing to do with specific application(E.g. set coding logic in online shopping application) should not group by this instead we can think it's infra application's logic (infra application support this specific application)
	Model is nothing to do with View, since View is only to visualize Model, Model is still there even there is no View.
		If the Info should still there after View be removed, it should part of Model.
		HTML is a tech to ship View Info, don't mix Model Info into it.
	Controller should be a very thin layer:
		All dynamics in view should belong to View, Controller is only to invoke/trigger View start.
		Router should part of Model, since there is corresponding real stuff map to it, Controller can rely on it to do forward.
	Particular MVC architectures can vary significantly from the traditional description.

	principal intent of the MVC pattern is the separation of concerns
	The Model-View-Controller paradigm extends the power of the user interface at the expense of increased demands on the user's mental model.
	the user object maintains multiple simultaneous views of the model at once
	the factoring into user, model, view, and controller allows one to support that
	original motivations for the models, views and controller idea was to be able to automatically produce a default graphical interface for any object
	extract-data-then-shove-it-elsewhere approach requires you to know too much about how the model-level objects are implemented
	A system based on that approach cannot be called object-oriented: there's too much data flowing around for the system to be maintainable.
	encourages the extraction of certain behaviours of an entity object(i.e. those concerned with representing itself to the user) and placing them in separate structures.
	encourages the extraction of other behaviours from the entity (Model) objects
	Controllers were originally defined (see above) as being concerned solely with managing input
**** program target domain
Original Problem/Domain Problem
***** problem specification
Normally Problem Specification use a "what is" style to describe the Problem

For example, The problem: I want to find the max length of "abc" and "de", in the specification:

The executor know something for example: length of string

Actions can be generated if required information provided

Problem Specification can be Function

U tell me what u want? I will find the actions to get it & perform them.

FP
    specify stuff relationships in source.
    Solution Generator can generate Action to find the other end with relation & one end
    Or we can say describe answer's link to question

Declarative (E.g. html)
    Specify result's attribute & structure


Specify target's attribute, structure, relations to others
    E.g.
        target's
        target is XXX's parent
Solution Generator will generate actions to get it.






**** Network 
IP addr = net addr + host addr 
network mask - used to indicate which part is net addr & which part is host addr
direct broadcast address - net addr + 255
limited broadcast address - special net addr(255.255.255) + 255, this special net addr means current local net
gateway address - address of server in a local net which will connect to out net

DHCP - Dynamic Host Configuration Protocal



**** Clojure React Interfaces
***** om - rely on reify
***** reagent - rely on self defined atom to maintain state, this is to register components who dereference data so that auto re-render is possible
***** rum - rely on self defined defc to create component
***** brutha - rely on reify, br/component, dom/p
***** quiescent - reply on self defined defcomponent

**** UI framework
***** material-ui
Only available as React components
Official reagent have related exmaples
reagent integration:
cljs-react-material-ui (componnet naming follow clojure)
reagent-material-ui (component naming follow js)
Theme customization in runtime(CSS-in-JS solution: JSS)

***** semantic-ui-react
reagent integration: soda-ash (component naming follow JS)
Theme customization in compile time(less variable)



**** eval
The presence of eval blurs the line between runtime and compilation time requiring that everything available in the latter be present in the former

**** aleph
NIO vs IO:
About how to perform IO(here IO mainly from/to Socket)
Block Style:
Thread --read/wirte-- Socket
Thread --read/wirte-- Socket
Thread --read/wirte-- Socket

Non Block Style:
Thread --use-- Selector -- Socket
                        -- Socket
                        -- Socket

NIO lib(netty), can be used by client & server, one top of it provided impl of HTTP...









**** clojure core.async
I think this is not FP
I prefer all Values coms from: Symbol, Literal, Function Application
Use parking(thread pool pulling?) to:
1, remove callbacks
2, avoid too many threads blocking

**** programe language design
First formost, Semantic is the core.
Don't think from Data perspective, as its Semantic is Thing

So Vector can not be implemented as Function, as from Semnatic perspective Vector is not a Relation


**** emacs
TRAMP (included) used to access remote files
/ssh:shark@192.168.124.3:Desktop/kvm.txt

ztree-diff is a directory-diff tool for Emacs inspired by commercial tools like Beyond Compare or Araxis Merge. 

**** postgresql
install:
;; standard pkg
brew install postgresql
;; mac app pkg
brew cask install postgres

standard pkg config:
;; init Database Cluster(database storage area on disk, SQL standard term: catalog cluster, default created db: postgres, template1 - base db, copied for new db creation)
initdb -D DATA_DIRECTORY -EUTF-8 --locale=XX_XX.UTF-8
or via wrapper program pg_ctl:
pg_ctl -D /usr/local/pgsql/data initdb


;; start server
postgres -D /usr/local/pgsql/data
or via wrapper program pg_ctl:
pg_ctl start -D DATA_DIRECTORY -w -l DATA_DIRECTORY/postgres-server.log


connect to postgre with super user(unix-domain socket):
"/Applications/Postgres.app/Contents/Versions/11/bin/psql"
or specify db:
"/Applications/Postgres.app/Contents/Versions/11/bin/psql" -p5432 -d "fuchengxu"


;; create db
;; login & sql command:
create database name;
or via wrapper program createdb:
createdb USERNAME


;; auth(pg_hba.conf)


**** clojure configuration libs
cprop - support data, provide low level env access api, load-config need at least one edn file, use low level api in cprop.source instead
aero - explicit, use tags, but edn file is mandatory
environ - implicit, rely on build tool
immuconf - edn file mandatory
nomad - rely on defconfig
omniconf - predefined scheme, populate & get
schematic - rely on Component




**** clojure.java.jdbc
db-spec can be:
{:datasource ds}


**** hikari-cp
mandatory config options:
:adapter or :jdbc-url


**** clojure sql lib

***** yesql
put plain sql in seq file, and abstract it into a function


***** korma
clojure forms simulate plain sql

***** honeysql
clojure data format to sql

***** hugsql
like yesql

**** clojure web lib

***** luminus
a template, most libs are carefully selected
most of these selections same as my opinion

***** duct
like luminus, by author of ring
prefer component over mount



**** clojure ajax lib

***** cljs-http
bind with core.async

***** cljs-ajax
support clj & cljs, no core.async binding, used by luminus





**** clojure data formatters
ring-json
only support json, seems this is the oldest option

ring-middleware-format
support a lot of format

muuntaja
base on ring-middleware-format, but rewritten, & 30X faster

ring-transit
author recommend ring-middleware-format

clojure.data.json
only support json, without ring middle support


**** clojure state manage
component - reply on Record, OO like, deps tree manually constructed

mount - rely on namespace load sequence to mantain deps tree & restart state

**** clojure validation lib
bouncer
struct - base on similar ideas of bouncer, stars:<100 as 2019/3
schema - s/defn give up Tree Owner, similar to struct, stars:>1900 as 2019/3
clojure.spec - also give up Tree Owner

**** clojure rest lib
Compojure-api - rely on data type declaration, like static language


**** repl
It's a program. get input, evaluate, send output

Category:
| standard io repl | raw stream repl                |
|------------------+--------------------------------|
| socket io repl   | segmented stream(message) repl |

e.g.
most internal repls - standard io repl,  raw stream repl
clojure socket repl - socket io repl, raw stream repl
IJulia, IPython, clojure nrepl - socket io repl, segmented stream(message) repl

**** Mac OS X
homebrew
build package in /usr/local/Cellar
brew link will create symbol link under /usr/local/bin to expose these packaegs

**/opt/xxx - optional packages, invented to replace /usr/local? as /usr better to be read only

**/local/xxx - local developed packages



**** vmware unity
View perspective, overlay guest's windows(taskbar is also a window, so better to hidde it in unity mode) on top of host's screen.
Input perspective, as taskbar hidded, host will create some interface(same function as task bar buttons) to invoke guest's application via command.
  e.g. "show system tray" create "system tray" buttons to invoke guest's task-bar/system-tray's application
       "VMware Fusion Application Menu" create "start menu" buttons to invke guest's task-bar/start-menu's application



**** shell
shell have 2 mode:
repl mode - start directly, it will behavior like repl
one-time mode - like normally function, "command" passed to it as argument

**** IO
stand io - hold by process creater
socket io - many process hold 1 input & many output

they are stream based communication, while messages(e.g. http msg) are base on stream, but 1, stream is segmented. 2, follow a formatter definition.  


**** Computer Role
Thing in mind -> Thing in Computer -> Thing in other place

It help people to do these things which people know how but too lazy to do
e.g.
AI - people know how to find function's root, but lazy to do the numerical calculation
Web - people know how to draw a picture to share information, but lazy to draw & deliver to others
CAD - people know the object's structure, but lazy to draw on paper


**** jupyter
it contains 2 parts:
  kernels(socket io repl, segmented stream(message) repl exposed via ZeroMQ):
    IPython - Python program
    IJulia - Julia program
    IRkernel - R program
    Community maintained kernels:
      IHaskell
      IRuby
      ...
  interfaces:
    notebook - web application
    console - python application, no gui
    qt console - python application, with gui, support image show...
    Community maintained interfaces:
      emacs-jupyter
      ...

**** Julia
***** Prime(api)
****** Runtime Polymorphism
Normal functions support runtime polymorphism
(clojure only have defmulti support this)

****** module/package system 
module name is a symbol, resolve similar to other symbols


module name resolve:
Main/REPL resolve to root temp module instance
Others find module instance in its current module instance, if not available use root module instance

normal module instance contains uuid -> deps map
root temp module instance only contains deps map


normal module instance loaded from project.toml
root temp module instance loaded from active enviroment's project.toml/source tree & merged with other roots map in LOAD_PATH

****** limited operations:
inside():
:call, :quote, :$(only inside :quote), :string
outside():
retrive value of symbol/literal

****** macro
Hygiene
macro result to be processed:
variables with no global decaration is renamed via gensym
except expr inside :escape, which simply keep it verbatim & unwrap :escape

Symbol resolvation follow closure(resovle to value in the definition context)

****** Generated functions
Function's logic can divide into 2 parts: arguments' type determined, arguments' value determined. 
First part is same across values of same type (e.g. matrix dimention).

@generated: a macro to generate function & register to compiler?
body of this generated function is the first part, result is the second part

when use this generated function, also divided to 2 parts:
invoke body with type which is done when compile invoker, invoke result with value which is done when execute invoker.


***** Recursion
****** syntax
similar to mathematic

****** parametric type
A type only define a structure, this structure can ship any parametric data
This consistent with (Primes + Recursions)


